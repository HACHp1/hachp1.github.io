<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>Tensorflow2入门 | Math &amp; Sec ，HACHp1的个人博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Tensorflow2入门 前言  最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。 没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。 官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow2入门">
<meta property="og:url" content="https://hachp1.github.io/posts/机器学习/20191128-tf2_learning.html">
<meta property="og:site_name" content="Math &amp; Sec ，HACHp1的个人博客">
<meta property="og:description" content="Tensorflow2入门 前言  最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。 没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。 官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v">
<meta property="og:image" content="http://159.75.52.53/img/thumbnails/eggs.jpg">
<meta property="og:updated_time" content="2021-10-29T11:39:31.767Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow2入门">
<meta name="twitter:description" content="Tensorflow2入门 前言  最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。 没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。 官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v">
<meta name="twitter:image" content="http://159.75.52.53/img/thumbnails/eggs.jpg">
    

    

    
        <link rel="icon" href="/css/images/favicon.png" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
    
    
    


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Math &amp; Sec ，HACHp1的个人博客</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">主页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">目录</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/avatar.png" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">主页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">目录</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/avatar.png" />
            <h2 id="name">HACHp1</h2>
            <h3 id="title">生活少有按照行动而改变，那就抓住那几个少有的。</h3>
            <span id="location"><i class="fa fa-map-marker"></i>China</span>
            <a id="follow" target="_blank" href="https://github.com/hachp1">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                40
                <span>文章</span>
            </div>
            <div class="article-info-block">
                8
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/HACHp1" target="_blank" title="GitHub" class=tooltip>
                            <i class="fa fa-GitHub"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-Tensorflow2入门" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
    
        
            
	
		<img src="http://159.75.52.53/img/banner/ML.jpg" class="article-banner" />
	



        
        
        
        
        
        
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            Tensorflow2入门
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/posts/机器学习/20191128-tf2_learning.html">
            <time datetime="2019-11-28T13:45:08.000Z" itemprop="datePublished">2019-11-28</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/机器学习/">机器学习</a>
    </div>

                    </div>
                
            </header>
                
            
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
			<h1 id="tensorflow2入门">Tensorflow2入门</h1>
<h2 id="前言">前言</h2>
<ul>
<li>最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。</li>
<li>没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。</li>
<li>官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v1，并没有太大的作用。</li>
<li>由于我个人对keras的便捷、代码易读性比较喜欢，所以对新版本并不排斥。但是如果只用keras，底层的很多操作就不支持了，比如训练的单步进行。所以需要学习TF2或者keras中更底层的部分。</li>
</ul>
<a id="more"></a>
<h2 id="爬过的坑尝试直接将keras和tf底层结构拼接在一起">爬过的坑，尝试直接将keras和TF底层结构拼接在一起</h2>
<ul>
<li>由于keras被引入了，我有一个大胆的猜想：把keras高层API和TF底层代码直接接在一起：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bin_reg_model</span><span class="params">()</span>:</span></div><div class="line">    inputs = layers.Input(shape=(<span class="number">1</span>,), dtype=np.float32)</div><div class="line">    h1 = layers.Dense(<span class="number">1</span>, input_shape=(<span class="number">1</span>,))(inputs)</div><div class="line">    outputs = tf.multiply(w, h1) + b</div><div class="line">    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</div><div class="line">    model.summary()</div><div class="line">    <span class="keyword">return</span> model</div></pre></td></tr></table></figure>
<ul>
<li>运行的时候发现不可行，报错显示有参数不能被训练</li>
<li>查询资料的过程中发现已经有人提出了这些问题：主要矛盾：keras的layer与tf的底层不能结合，如果要使用keras模块，就只能用keras的compile，不能用TF代码来训练，很不方便。 <a href="https://github.com/tensorflow/tensorflow/issues/26844#issuecomment-516755626" class="uri" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/issues/26844#issuecomment-516755626</a></li>
<li>这条路就这么断了，目前来说TF的高层和底层API还是隔离开的，感觉keras强行弄进来没有什么太大的意义，希望TF以后可以做到高层底层API混合调用。</li>
</ul>
<h2 id="tf2-eager模式用以代替和改写原来的session静态图模式">TF2 eager模式（用以代替和改写原来的session静态图模式）</h2>
<ul>
<li>首先，回顾一下TF1的代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">cost = tf.reduce_mean((tf.square(predict - yh)) / <span class="number">2</span>)  <span class="comment"># 最小二乘法代价函数</span></div><div class="line">optimizer = tf.train.AdamOptimizer(<span class="number">0.01</span>)  <span class="comment"># 使用ADAM优化，学习率0.01</span></div><div class="line">train_step = optimizer.minimize(cost)  <span class="comment"># 一个训练步骤</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(init)  <span class="comment"># 初始化</span></div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(epoch):  <span class="comment"># 进行epoch次大循环</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):  <span class="comment"># 对每个数据点的遍历</span></div><div class="line">            sess.run(train_step, &#123;xh: x[i], yh: y[i]&#125;)  <span class="comment"># 塞入一个数据点</span></div></pre></td></tr></table></figure>
<ul>
<li>TF2直接采用动态图的方法，与TF1相比，不再需要提前构造静态的神经网络，再采用Session与静态图进行交互。Session作为TF的标志性操作之一，在TF2中被删去，这个变化有很多人不适应，TF似乎面目全非了。但是在eager模式下，原TF的代码也可以完全改写过来：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bin_reg_model</span><span class="params">(xh)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.multiply(w, xh * xh) + b  <span class="comment"># 预测值</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_object</span><span class="params">(predict, yh)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.reduce_mean((tf.square(predict - yh)) / <span class="number">2</span>)  <span class="comment"># 最小二乘法代价函数</span></div><div class="line"></div><div class="line">optimizer = tf.optimizers.Adam(<span class="number">1</span>)  <span class="comment"># 使用ADAM优化，学习率0.01</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(x_train, y_train)</span>:</span></div><div class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape: <span class="comment"># 在tape下才能进行反向传播求导</span></div><div class="line">        logits = bin_reg_model(x_train)  <span class="comment"># bin_reg_model输出模型的预测值</span></div><div class="line">        loss_value = loss_object(y_train, logits)  <span class="comment"># loss_object函数计算误差值</span></div><div class="line">    print(<span class="string">'[+] Loss'</span>, loss_value.numpy())</div><div class="line">    grads = tape.gradient(loss_value, [w, b])</div><div class="line">    optimizer.apply_gradients(zip(grads, [w, b]))  <span class="comment"># optimizer可以自定义，也可以使用内置的类</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(epoch):  <span class="comment"># 进行epoch次大循环</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):  <span class="comment"># 对每个数据点的遍历</span></div><div class="line">        train_step(x[i], y[i])  <span class="comment"># 塞入一个数据点</span></div></pre></td></tr></table></figure>
<ul>
<li>需要注意的是，在TF1中也有apply_gradients更新的操作，只不过为了简便，TF1中一般使用<code>optimizer.minimize(cost)</code>代替<code>gradient</code>和<code>optimizer.apply_gradients</code>两步，即<code>optimizer.minimize(cost)</code>整合了这两步。TF2也有<code>optimizer.minimize()</code>函数，但是在TF2中，minimize函数似乎没有TF1好用。</li>
<li>另外，由于TF2使用了eager模式，可以一边构造神经网络一边debug，还可以通过<code>a.shape</code>得到当前向量的尺寸，可以更方便地编写代码。</li>
</ul>
<h2 id="tf2-tensorboard">TF2 tensorboard</h2>
<ul>
<li>与TF1相比，TF2的TFB变得更加简洁： <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">log_dir = <span class="string">'tf2_log'</span></div><div class="line">writer = tf.summary.create_file_writer(log_dir)</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(epoch):  <span class="comment"># 进行epoch次大循环</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):  <span class="comment"># 对每个数据点的遍历</span></div><div class="line">        loss = train_step(x[i], y[i])  <span class="comment"># 塞入一个数据点</span></div><div class="line">        <span class="keyword">with</span> writer.as_default():  <span class="comment"># tensorboard记录</span></div><div class="line">            tf.summary.scalar(<span class="string">'loss'</span>, loss, step=j*epoch+i) <span class="comment"># 在任何位置都可以调用</span></div></pre></td></tr></table></figure></li>
</ul>
<h2 id="keras自定义层">keras自定义层</h2>
<ul>
<li>由于TF2主推keras，但是有的时候需要更加底层的操作修改，所以需要学习自定义层的编写。</li>
</ul>
<h3 id="注意事项">注意事项</h3>
<ul>
<li>尽量<strong>保证自定义层类属性和方法的完整性</strong>，不然模型储存过程中会出现各种问题（get_config、__init__中的name等）</li>
<li>自定义层调用时需要设置name，模型重载时需要设置对应的name字典</li>
</ul>
<h3 id="需要重写或可以重写的函数">需要重写（或可以重写）的函数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">## 必重写</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, position, d_model, name=<span class="string">"PositionEmbedding"</span>, **kwargs)</span>:</span> <span class="comment"># 申请、储存本层需要用到的属性、对象等</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x)</span>:</span> <span class="comment"># 调用该层时进行的运算</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span> <span class="comment"># 返回初始化变量，用于模型读取时使用</span></div><div class="line"></div><div class="line"><span class="comment">## 可重写</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 需要根据input_shape改变配置时要重写的函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 返回的矩阵大小</span></div></pre></td></tr></table></figure>
<h3 id="一些例子">一些例子</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line"><span class="string">keras层</span></div><div class="line"><span class="string">为input添加一个可训练权重 =&gt; input · weight</span></div><div class="line"><span class="string">'''</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Add_weight</span><span class="params">(layers.Layer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name=<span class="string">"Add_weight"</span>, **kwargs)</span>:</span> <span class="comment"># 申请、储存本层需要用到的属性、对象等</span></div><div class="line">        super().__init__(name=name, **kwargs)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 需要根据input_shape改变配置时要重写的函数</span></div><div class="line">        <span class="comment"># 添加的可训练的权重</span></div><div class="line"></div><div class="line">        self.weight_to_mut = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[input_shape[<span class="number">2</span>],input_shape[<span class="number">2</span>]]),trainable=<span class="keyword">True</span>)</div><div class="line">        super().build(input_shape)  <span class="comment"># 一定要在最后调用它</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x)</span>:</span> <span class="comment"># 调用该层时进行的运算</span></div><div class="line">        <span class="keyword">return</span> K.dot(x, self.weight_to_mut)  <span class="comment"># 点乘</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span> <span class="comment"># 返回初始化变量，用于模型读取时使用</span></div><div class="line">        config=super().get_config().copy()</div><div class="line">        <span class="keyword">return</span> config</div><div class="line">    </div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 返回的矩阵大小</span></div><div class="line">        <span class="keyword">return</span> (input_shape[<span class="number">2</span>], input_shape[<span class="number">2</span>])</div><div class="line"></div><div class="line">input_wq = Add_weight(name=<span class="string">'add_1'</span>)(inputs)</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line"><span class="string">attention is all you need 论文中的 position embedding层</span></div><div class="line"><span class="string">继承keras layer</span></div><div class="line"><span class="string">h2 = PositionEmbedding(time_step, embedding_size)(h1)</span></div><div class="line"><span class="string">'''</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionEmbedding</span><span class="params">(layers.Layer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, position, d_model, name=<span class="string">"PositionEmbedding"</span>, **kwargs)</span>:</span></div><div class="line">        super().__init__(name=name, **kwargs)</div><div class="line"></div><div class="line">        <span class="comment"># 储存用于恢复模型的init参数，用在get_config函数中</span></div><div class="line">        <span class="comment">#####</span></div><div class="line">        self.position = position</div><div class="line">        self.d_model = d_model</div><div class="line">        <span class="comment">#####</span></div><div class="line"></div><div class="line">        self.pos_encoding = self.positional_encoding(position, d_model)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_angles</span><span class="params">(self, position, i, d_model)</span>:</span></div><div class="line">        angles = <span class="number">1</span> / tf.pow(<span class="number">10000</span>, (<span class="number">2</span> * (i // <span class="number">2</span>)) /</div><div class="line">                            tf.cast(d_model, tf.float32))</div><div class="line">        <span class="keyword">return</span> position * angles</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">positional_encoding</span><span class="params">(self, position, d_model)</span>:</span></div><div class="line">        angle_rads = self.get_angles(</div><div class="line">            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],</div><div class="line">            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],</div><div class="line">            d_model=d_model)</div><div class="line">        <span class="comment"># apply sin to even index in the array</span></div><div class="line">        sines = tf.math.sin(angle_rads[:, <span class="number">0</span>::<span class="number">2</span>])</div><div class="line">        <span class="comment"># apply cos to odd index in the array</span></div><div class="line">        cosines = tf.math.cos(angle_rads[:, <span class="number">1</span>::<span class="number">2</span>])</div><div class="line"></div><div class="line">        pos_encoding = tf.concat([sines, cosines], axis=<span class="number">-1</span>)</div><div class="line">        pos_encoding = pos_encoding[tf.newaxis, ...]</div><div class="line">        <span class="keyword">return</span> tf.cast(pos_encoding, tf.float32)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></div><div class="line">        <span class="keyword">return</span> inputs + self.pos_encoding[:, :tf.shape(inputs)[<span class="number">1</span>], :]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span></div><div class="line"></div><div class="line">        config = super().get_config().copy()</div><div class="line">        config.update(&#123;</div><div class="line">            <span class="string">'position'</span>: self.position,</div><div class="line">            <span class="string">'d_model'</span>: self.d_model</div><div class="line">        &#125;)</div><div class="line">        <span class="keyword">return</span> config</div><div class="line"></div><div class="line"></div><div class="line">h2 = PositionEmbedding(time_step, embedding_size,</div><div class="line">                           name=<span class="string">"PositionEmbedding"</span>)(h1) <span class="comment"># 自定义层设置name</span></div></pre></td></tr></table></figure>
<h4 id="包含自定义层的模型重载">包含自定义层的模型重载</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">model = tf.keras.models.load_model(<span class="string">'model/attention.keras'</span>, custom_objects=&#123;</div><div class="line">            <span class="string">'PositionEmbedding'</span>: PositionEmbedding,</div><div class="line">            <span class="string">'add_1'</span>:Add_weight,</div><div class="line">            <span class="string">'add_2'</span>:Add_weight,</div><div class="line">            <span class="string">'add_3'</span>:Add_weight,</div><div class="line">        &#125;) <span class="comment"># 需要指定每个name对应的层的class</span></div></pre></td></tr></table></figure>
<h2 id="tf2-keras的坑keras本身的坑">TF2 keras的坑（keras本身的坑）</h2>
<h3 id="问题">问题</h3>
<ul>
<li>在学习完attention有一段时间后，我想使用attention也写一个模型来检测webshell，同时也想实践一下keras自定义层。于是写了以下代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line"><span class="string">attention is all you need 论文中的 position embedding层</span></div><div class="line"><span class="string">继承keras layer</span></div><div class="line"><span class="string">h2 = PositionEmbedding(time_step, embedding_size)(h1)</span></div><div class="line"><span class="string">'''</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionEmbedding</span><span class="params">(layers.Layer)</span>:</span></div><div class="line">    ...</div><div class="line"></div><div class="line"></div><div class="line"><span class="string">'''</span></div><div class="line"><span class="string">keras层</span></div><div class="line"><span class="string">为input添加一个可训练权重 =&gt; input · weight</span></div><div class="line"><span class="string">'''</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Add_weight</span><span class="params">(layers.Layer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name=<span class="string">"Add_weight"</span>, **kwargs)</span>:</span> <span class="comment"># 申请、储存本层需要用到的属性、对象等</span></div><div class="line">        super().__init__(name=name, **kwargs)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 需要根据input_shape改变配置时要重写的函数</span></div><div class="line">        <span class="comment"># 添加的可训练的权重</span></div><div class="line"></div><div class="line">        self.weight_to_mut = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[input_shape[<span class="number">2</span>],input_shape[<span class="number">2</span>]]),trainable=<span class="keyword">True</span>)</div><div class="line">        super().build(input_shape)  <span class="comment"># 一定要在最后调用它</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, x)</span>:</span> <span class="comment"># 调用该层时进行的运算</span></div><div class="line">        <span class="keyword">return</span> K.dot(x, self.weight_to_mut)  <span class="comment"># 点乘</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span><span class="params">(self)</span>:</span> <span class="comment"># 返回初始化变量，用于模型读取时使用</span></div><div class="line">        config=super().get_config().copy()</div><div class="line">        <span class="keyword">return</span> config</div><div class="line">    </div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span><span class="params">(self, input_shape)</span>:</span> <span class="comment"># 返回的矩阵大小</span></div><div class="line">        <span class="keyword">return</span> (input_shape[<span class="number">2</span>], input_shape[<span class="number">2</span>])</div><div class="line"></div><div class="line">    </div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></div><div class="line">    inputs = tf.keras.Input(shape=(n_steps, n_inputs,), batch_size=BATCH_SIZE)</div><div class="line"></div><div class="line">    <span class="comment"># weights</span></div><div class="line"></div><div class="line">    input_wq = Add_weight(name=<span class="string">'add_1'</span>)(inputs)</div><div class="line">    input_wv = Add_weight(name=<span class="string">'add_2'</span>)(inputs)</div><div class="line">    input_wk = Add_weight(name=<span class="string">'add_3'</span>)(inputs)</div><div class="line"></div><div class="line">    h1 = layers.Attention()([</div><div class="line">        input_wq,</div><div class="line">        input_wv,</div><div class="line">        input_wk</div><div class="line">    ])  <span class="comment"># self-attention [query,value,key]</span></div><div class="line"></div><div class="line">    <span class="comment"># h1 = inputs</span></div><div class="line"></div><div class="line">    h2 = PositionEmbedding(time_step, embedding_size,</div><div class="line">                           name=<span class="string">"PositionEmbedding"</span>)(h1) <span class="comment"># 自定义层设置name</span></div><div class="line"></div><div class="line">    h3 = layers.Flatten()(h2)  <span class="comment"># 展开后使用全连接</span></div><div class="line"></div><div class="line">    h4 = layers.Dense(n_classes, input_shape=(time_step, embedding_size))(h3)</div><div class="line"></div><div class="line">    outputs = layers.Activation(<span class="string">'softmax'</span>)(h4)</div><div class="line"></div><div class="line">    model = tf.keras.Model(inputs=inputs, outputs=outputs)</div><div class="line"></div><div class="line">    model.compile(optimizer=tf.keras.optimizers.Adam(),</div><div class="line">                  loss=tf.keras.losses.BinaryCrossentropy(),</div><div class="line">                  metrics=[<span class="string">'accuracy'</span>])</div><div class="line">    <span class="keyword">return</span> model</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line"></div><div class="line">    <span class="keyword">if</span> CONTINUE_TRAIN:</div><div class="line">        model = tf.keras.models.load_model(<span class="string">'model/attention.keras'</span>, custom_objects=&#123;</div><div class="line">            <span class="string">'PositionEmbedding'</span>: PositionEmbedding,</div><div class="line">            <span class="string">'add_1'</span>:Add_weight,</div><div class="line">            <span class="string">'add_2'</span>:Add_weight,</div><div class="line">            <span class="string">'add_3'</span>:Add_weight,</div><div class="line">        &#125;)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        model = build_model()</div><div class="line"></div><div class="line">    model.summary()</div><div class="line"></div><div class="line">    ...</div><div class="line"></div><div class="line">    model.fit(x_train, y_train, batch_size=BATCH_SIZE,</div><div class="line">              epochs=training_iters//x_train.shape[<span class="number">0</span>], validation_split=<span class="number">0.1</span>)</div><div class="line">    model.save(<span class="string">'model/attention.keras'</span>)</div></pre></td></tr></table></figure>
<ul>
<li>在save的时候报错，说是<code>get_config</code>函数未重写。仔细检查了代码，反复确定，<code>Add_weight</code>层与<code>PositionEmbedding</code>层都重写了该函数，但是由于其他地方调用的都是官方的层，让我一直怀疑是自己的代码不规范造成的。</li>
<li>最后只能直接debug。刚开始的时候，由于我使用了VSCODE，debug设置默认不会跟进库函数，加上对于官方库的信任，我直接没有管官方keras库。发现我自己写的<code>get_config</code>函数被调用了，调动之后直接就报错了，让我误认为还是自己的问题。直到最后我想继续跟下去的时候，准备跟进官方库文件看看。</li>
<li>修改VSCODE debug设置为：<code>&quot;justMyCode&quot;:false</code>，再次跟进：</li>
<li>发现<code>base_layer.py</code>代码抛出异常的位置，由于官方库并没有写具体的层信息，导致层错误的对象不明确，于是略加修改库代码。</li>
<li>在<code>base_layer.py</code>的572行开始，修改抛出异常的库代码:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> len(extra_args) &gt; <span class="number">1</span> <span class="keyword">and</span> hasattr(self.get_config, <span class="string">'_is_default'</span>):</div><div class="line">      <span class="keyword">raise</span> NotImplementedError(<span class="string">'Layers with arguments in `__init__` must '</span></div><div class="line">                                <span class="string">'override `get_config`.'</span>+<span class="string">'  name:  '</span>+config[<span class="string">'name'</span>])</div></pre></td></tr></table></figure>
<p>再次运行模型训练得到输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">NotImplementedError: Layers with arguments <span class="keyword">in</span> `__init__` must override `get_config`.  name:attention</div></pre></td></tr></table></figure>
<ul>
<li>问题终于找到了，是官方的<code>Attention</code>层没有重写<code>get_config</code>函数，真坑。。。</li>
</ul>
<h3 id="解决">解决</h3>
<ul>
<li>在网上也找到了这个问题的issue：<a href="https://github.com/tensorflow/tensorflow/issues/32662" class="uri" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/issues/32662</a>，原来别人早就发现了，可是不知道为啥我自己遇到的时候怎么搜都没有相关的，我找到问题了它也出来了:)</li>
<li>虽然github中说在新的版本中已解决该问题，但为了使代码更具通用性，我使用重载参数的方式储存，这样就不会因为<code>get_config</code>函数没有重写而报错。</li>
</ul>
<h2 id="后记">后记</h2>
<ul>
<li>TF2与TF1相比，使用eager模式，去掉了静态图模式，在调试上更快捷。同时也引入了keras高层API，但是keras和底层API之间不能混用。并且由于官方过于强调keras，在其例子中主要都是keras搭建神经网络，底层的使用比较少，这使其不太友好。</li>
<li>由于keras底层可以使用TF，所以TF和keras相辅相成，熟悉TF后就可以轻松地修改keras代码，并且keras提供了很多自定义的接口，这使keras框架用起来非常方便。</li>
<li>最后推荐苏剑林大佬的博客中有关keras的部分:<a href="https://spaces.ac.cn/search/keras/" class="uri" target="_blank" rel="external">https://spaces.ac.cn/search/keras/</a></li>
</ul>

        
        </div>
        
        
        
        
<div id="copyright-div">    

    <ul class="post-copyright">
      <li class="post-copyright-author">
          <strong>本文作者：<a href="https://github.com/HACHp1">HACHp1</a> </strong>
      </li>
      <li class="post-copyright-link">
        <strong>本文链接：</strong>
        <a href="/posts/机器学习/20191128-tf2_learning.html" title="Tensorflow2入门">https://hachp1.github.io/posts/机器学习/20191128-tf2_learning.html</a>
      </li>
      <li class="post-copyright-license">
        <strong>版权声明： </strong>
        本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。非商业转载请注明作者及出处。商业转载请联系作者本人。
      </li>
    </ul>
 
</div>


        
        
        
        <footer class="article-footer">
            <div class="share-container">



    <div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
<a class="a2a_button_wechat"></a>
<a class="a2a_button_qzone"></a>
<a class="a2a_button_sina_weibo"></a>
<a class="a2a_button_twitter"></a>
<a class="a2a_button_facebook"></a>
<a class="a2a_button_telegram"></a>
</div>
<script async src="https://static.addtoany.com/menu/page.js"></script>

<script type="text/javascript" src="//static.addtoany.com/menu/page.js"></script>
<style>
    .a2a_menu {
        border-radius: 4px;
    }
    .a2a_menu a {
        margin: 2px 0;
        font-size: 14px;
        line-height: 16px;
        border-radius: 4px;
        color: inherit !important;
        font-family: 'Microsoft Yahei';
    }
    #a2apage_dropdown {
        margin: 10px 0;
    }
    .a2a_mini_services {
        padding: 10px;
    }
    a.a2a_i,
    i.a2a_i {
        width: 122px;
        line-height: 16px;
    }
    a.a2a_i .a2a_svg,
    a.a2a_more .a2a_svg {
        width: 16px;
        height: 16px;
        line-height: 16px;
        vertical-align: top;
        background-size: 16px;
    }
    a.a2a_i {
        border: none !important;
    }
    a.a2a_menu_show_more_less {
        margin: 0;
        padding: 10px 0;
        line-height: 16px;
    }
    .a2a_mini_services:after{content:".";display:block;height:0;clear:both;visibility:hidden}
    .a2a_mini_services{*+height:1%;}
</style>

</div>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/posts/机器学习/20200207-GNN_0.html" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    GNN初探，The graph neural network model浅析
                
            </div>
        </a>
    
    
        <a href="/posts/机器学习/20191018-CPMPP.html" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">使用模型预测模型的准确率：Conformal Prediction (共型预测)与MPP</div>
        </a>
    
</nav>


    
    
    
</article>


    
    
        <section id="comments">
    <div id="valine-thread"></div>
</section>
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/Web安全/20210615-qwb2021.html" class="thumbnail">
    
    
        <span style="background-image:url(http://159.75.52.53/img/thumbnails/cat.jpg)" alt="强网杯2021 easyxss wp" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Web安全/">Web安全</a></p>
                            <p class="item-title"><a href="/posts/Web安全/20210615-qwb2021.html" class="title">强网杯2021 easyxss wp</a></p>
                            <p class="item-date"><time datetime="2021-06-15T06:09:42.000Z" itemprop="datePublished">2021-06-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/Web安全/20210607-open_redirect01.html" class="thumbnail">
    
    
        <span style="background-image:url(http://159.75.52.53/img/thumbnails/eggs.jpg)" alt="由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Web安全/">Web安全</a></p>
                            <p class="item-title"><a href="/posts/Web安全/20210607-open_redirect01.html" class="title">由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS</a></p>
                            <p class="item-date"><time datetime="2021-06-07T06:57:35.000Z" itemprop="datePublished">2021-06-07</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/Web安全/20210309-ant2021.html" class="thumbnail">
    
    
        <span style="background-image:url(http://159.75.52.53/img/thumbnails/cat.jpg)" alt="AntCTF2021 部分WP" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Web安全/">Web安全</a></p>
                            <p class="item-title"><a href="/posts/Web安全/20210309-ant2021.html" class="title">AntCTF2021 部分WP</a></p>
                            <p class="item-date"><time datetime="2021-03-09T11:04:04.000Z" itemprop="datePublished">2021-03-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/Web安全/20201126-wdbunfinish.html" class="thumbnail">
    
    
        <span style="background-image:url(http://159.75.52.53/img/thumbnails/eggs.jpg)" alt="[网鼎杯2018]Unfinish-二次注入和insert注入的一个误区" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Web安全/">Web安全</a></p>
                            <p class="item-title"><a href="/posts/Web安全/20201126-wdbunfinish.html" class="title">[网鼎杯2018]Unfinish-二次注入和insert注入的一个误区</a></p>
                            <p class="item-date"><time datetime="2020-11-26T08:47:27.000Z" itemprop="datePublished">2020-11-26</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/posts/Web安全/20201019-sw_safe.html" class="thumbnail">
    
    
        <span style="background-image:url(http://159.75.52.53/img/thumbnails/planet_red.png)" alt="从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Web安全/">Web安全</a></p>
                            <p class="item-title"><a href="/posts/Web安全/20201019-sw_safe.html" class="title">从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss</a></p>
                            <p class="item-date"><time datetime="2020-10-19T13:54:52.000Z" itemprop="datePublished">2020-10-19</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux日常/">Linux日常</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web安全/">Web安全</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/对抗样本/">对抗样本</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/心情随笔/">心情随笔</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习-算法/">机器学习-算法</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习初步/">机器学习初步</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/漏洞分析/">漏洞分析</a><span class="tag-list-count">6</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/Linux日常/" style="font-size: 11.67px;">Linux日常</a> <a href="/tags/Web安全/" style="font-size: 20px;">Web安全</a> <a href="/tags/对抗样本/" style="font-size: 10px;">对抗样本</a> <a href="/tags/心情随笔/" style="font-size: 10px;">心情随笔</a> <a href="/tags/机器学习/" style="font-size: 18.33px;">机器学习</a> <a href="/tags/机器学习-算法/" style="font-size: 15px;">机器学习-算法</a> <a href="/tags/机器学习初步/" style="font-size: 13.33px;">机器学习初步</a> <a href="/tags/漏洞分析/" style="font-size: 16.67px;">漏洞分析</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="https://redogwu.github.io">redogWu</a>
                    </li>
                
                    <li>
                        <a href="https://hpasserby.me">Hpasserby的pwn</a>
                    </li>
                
                    <li>
                        <a href="https://jygzyc.github.io">jygzyc</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2022 HACHp1<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    <script src="//unpkg.com/leancloud-storage@3.15.0/dist/av-min.js"></script>
    <script src="//cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script>
    <script>
        new Valine({
            el: '#valine-thread' ,
            notify:true,
            verify:true,
            app_id: 'GpqOpUBld8udMg3PSOCDbYr7-gzGzoHsz',
            app_key: 'k6nxcdbcy4MrjOq2DssFFljB',
            placeholder: '少侠，留下几句话，我们喝一壶啊 ヾﾉ≧∀≦)o （支持markdown语句，可插入图片）'
        });
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>